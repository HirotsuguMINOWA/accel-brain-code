{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Setting: Reversi.\n",
    "\n",
    "<a name=\"h1_1\"></a>\n",
    "\n",
    "This notebook demonstrates a Multi-agent Q-Learning to solve Reversi. Reversi is a board game for two players, played on an $8 \\times 8$ uncheckered board. First of all, the board must be generated. Here let's express it using `numpy.ndarray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  1, -1,  0,  0,  0],\n",
       "       [ 0,  0,  0, -1,  1,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "map_arr = np.zeros((8, 8)).astype(int)\n",
    "map_arr[3, 3] = 1\n",
    "map_arr[4, 4] = 1\n",
    "map_arr[3, 4] = -1\n",
    "map_arr[4, 3] = -1\n",
    "map_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if you use `matplotlib` and `seaborn`, you can draw images similar to Reversi's board as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x71afb7fe9cf8>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x71aff8257320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "fig = plt.figure(figsize=(8, 7))\n",
    "sns.heatmap(\n",
    "    map_arr, \n",
    "    linewidths=.5, \n",
    "    cmap=\"gist_earth\", \n",
    "    cbar=False, \n",
    "    linecolor=\"black\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this matrix, `+1` means white and `-1` means black."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem solution: Multi-agent epsilon greedy Q-Learning.\n",
    "\n",
    "I implemented `ReversiGreedyQLearning` which is-a `GreedyQLearning` by a rush. In this object, an agent observes the board as own state. The agent's action can be selected by this state.\n",
    "\n",
    "`ReversiGreedyQLearning` has a `evaluate_map_list`. This value means a score matrix when placing a stone at each coordinate. When agents observe reward, Q-Learning algorithm evaluates reward points by this matrix. The reward function is as following:\n",
    "\n",
    "$$r^{(t)} = \\frac{\\sum_{x=0}^{7}\\sum_{y=0}^{7} M^{t}_{(x, y)}}{\\sum_{x=0}^{7}\\sum_{y=0}^{7} M^{(t-1)}_{(x, y)}} (t = 1, 2, 3, ..., T)$$\n",
    "\n",
    "where $t$ is a Monte Carlo step or time step. $M^{t}_{(x, y)}$ is a score in $x$ and $y$ coordinates at time $t$. So $r^{(t)}$ is a change rate of the score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although Reversi is two players game, a behavior of `ReversiGreedyQLearning` can be corresponded to one agent. Then you have to instantiate two objects of `ReversiGreedyQLearning`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from devsample.reversi_greedy_q_learning import ReversiGreedyQLearning\n",
    "\n",
    "white_player = ReversiGreedyQLearning(color=1)\n",
    "black_player = ReversiGreedyQLearning(color=-1)\n",
    "\n",
    "white_player.epsilon_greedy_rate = 0.7\n",
    "black_player.epsilon_greedy_rate = 0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then, I implemented `AlternatedMultiAgent` which is-a `MultiAgentQLearning` by a rush. `MultiAgentQLearning` is a template method to implement a controller for the Multi-Agent Q-Learning. `AlternatedMultiAgent` is a concrete class for an alternating learning, which can be described that each agent searchs optimal policy observing the enemy player's action. In other words, each agent's state can be transitioned to next state that corresponding to enemy player's action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/bin/.pyenv/versions/anaconda3-5.1.0/lib/python3.6/site-packages/pandas/core/algorithms.py:410: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  f = lambda x, y: htable.ismember_object(x, values)\n"
     ]
    }
   ],
   "source": [
    "from pyqlearning.multiagentqlearning.alternated_multi_agent import AlternatedMultiAgent\n",
    "\n",
    "multi_agent_q_learning = AlternatedMultiAgent(\n",
    "    q_learning_list=[white_player, black_player]\n",
    ")\n",
    "\n",
    "multi_agent_q_learning.learn(first_state_key=map_arr, limit=80, game_n=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visible the result of Multi-Agent learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "for i in range(80):\n",
    "    fig = plt.figure(figsize=(8, 7))\n",
    "    sns.heatmap(\n",
    "        multi_agent_q_learning.state_key_list[i], \n",
    "        linewidths=.5, \n",
    "        cmap=\"gist_earth\", \n",
    "        cbar=False, \n",
    "        linecolor=\"black\"\n",
    "    )\n",
    "    plt.savefig(\"/tmp/reversi_\" + str(i) + \".png\");plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_img = Image.open(\"/tmp/reversi_0.png\")\n",
    "img_list = []\n",
    "for i in range(1, 80):\n",
    "    img = Image.open(\"/tmp/reversi_\" + str(i) + \".png\")\n",
    "    img_list.append(img)\n",
    "    \n",
    "first_img.save(\n",
    "    'reversi.gif', \n",
    "    save_all=True, \n",
    "    append_images=img_list,\n",
    "    optimized=True, \n",
    "    duration=40, \n",
    "    loop=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.open(\"reversi.gif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_player_2 = ReversiGreedyQLearning(color=1)\n",
    "black_player_2 = ReversiGreedyQLearning(color=-1)\n",
    "\n",
    "black_player_2.r_df = multi_agent_q_learning.q_learning_list[0].r_df\n",
    "white_player_2.r_df = multi_agent_q_learning.q_learning_list[1].r_df\n",
    "black_player_2.q_df = multi_agent_q_learning.q_learning_list[0].q_df\n",
    "white_player_2.q_df = multi_agent_q_learning.q_learning_list[1].q_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_agent_q_learning_2 = MultiAgentQLearning(\n",
    "    q_learning_list=[white_player_2, black_player_2]\n",
    ")\n",
    "multi_agent_q_learning_2.state_key_list = []\n",
    "multi_agent_q_learning_2.learn(first_state_key=map_arr, limit=40, game_n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "\n",
    "for i in range(80):\n",
    "    fig = plt.figure(figsize=(8, 7))\n",
    "    sns.heatmap(\n",
    "        multi_agent_q_learning_2.state_key_list[i], \n",
    "        linewidths=.5, \n",
    "        cmap=\"gist_earth\", \n",
    "        cbar=False, \n",
    "        linecolor=\"black\"\n",
    "    )\n",
    "    plt.savefig(\"/tmp/reversi_t_\" + str(i) + \".png\");plt.close()\n",
    "\n",
    "first_img = Image.open(\"/tmp/reversi_t_0.png\")\n",
    "img_list = []\n",
    "for i in range(1, 100):\n",
    "    img = Image.open(\"/tmp/reversi_t_\" + str(i) + \".png\")\n",
    "    img_list.append(img)\n",
    "    \n",
    "first_img.save(\n",
    "    'reversi_t.gif', \n",
    "    save_all=True, \n",
    "    append_images=img_list,\n",
    "    optimized=True, \n",
    "    duration=40, \n",
    "    loop=0\n",
    ")\n",
    "Image.open(\"reversi_t.gif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
