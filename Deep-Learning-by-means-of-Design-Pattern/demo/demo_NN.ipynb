{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydbm.nn.neural_network import NeuralNetwork\n",
    "from pydbm.nn.nn_layer import NNLayer as NNLayer1\n",
    "from pydbm.nn.nn_layer import NNLayer as NNLayer2\n",
    "from pydbm.nn.nn_layer import NNLayer as NNLayer3\n",
    "from pydbm.nn.nn_layer import NNLayer as NNLayer4\n",
    "from pydbm.nn.nn_layer import NNLayer as NNLayer5\n",
    "from pydbm.nn.nn_layer import NNLayer as NNLayer6\n",
    "from pydbm.nn.nn_layer import NNLayer as NNLayer7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydbm.activation.relu_function import ReLuFunction\n",
    "from pydbm.activation.tanh_function import TanhFunction\n",
    "from pydbm.activation.logistic_function import LogisticFunction\n",
    "from pydbm.loss.mean_squared_error import MeanSquaredError\n",
    "from pydbm.optimization.optparams.adam import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydbm.synapse.nn_graph import NNGraph as NNGraph1\n",
    "from pydbm.synapse.nn_graph import NNGraph as NNGraph2\n",
    "from pydbm.synapse.nn_graph import NNGraph as NNGraph3\n",
    "from pydbm.synapse.nn_graph import NNGraph as NNGraph4\n",
    "from pydbm.synapse.nn_graph import NNGraph as NNGraph5\n",
    "from pydbm.synapse.nn_graph import NNGraph as NNGraph6\n",
    "from pydbm.synapse.nn_graph import NNGraph as NNGraph7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydbm.verification.verificate_function_approximation import VerificateFunctionApproximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logging import getLogger, StreamHandler, NullHandler, DEBUG, ERROR\n",
    "\n",
    "logger = getLogger(\"pydbm\")\n",
    "handler = StreamHandler()\n",
    "handler.setLevel(DEBUG)\n",
    "logger.setLevel(DEBUG)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 100\n",
    "dimension = 100\n",
    "dimension2 = 500\n",
    "scale = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setup NN layers and the parameters.\n"
     ]
    }
   ],
   "source": [
    "nn_layer1 = NNLayer1(\n",
    "    NNGraph1(\n",
    "        activation_function=LogisticFunction(),\n",
    "        hidden_neuron_count=dimension,\n",
    "        output_neuron_count=dimension,\n",
    "        scale=scale,\n",
    "    )\n",
    ")\n",
    "nn_layer2 = NNLayer2(\n",
    "    NNGraph2(\n",
    "        activation_function=LogisticFunction(),\n",
    "        hidden_neuron_count=dimension2,\n",
    "        output_neuron_count=dimension,\n",
    "        scale=scale,\n",
    "    )\n",
    ")\n",
    "nn_layer3 = NNLayer3(\n",
    "    NNGraph3(\n",
    "        activation_function=LogisticFunction(),\n",
    "        hidden_neuron_count=dimension,\n",
    "        output_neuron_count=dimension,\n",
    "        scale=scale,\n",
    "    )\n",
    ")\n",
    "nn_layer4 = NNLayer4(\n",
    "    NNGraph4(\n",
    "        activation_function=LogisticFunction(),\n",
    "        hidden_neuron_count=dimension,\n",
    "        output_neuron_count=dimension,\n",
    "        scale=scale,\n",
    "    )\n",
    ")\n",
    "nn_layer5 = NNLayer5(\n",
    "    NNGraph5(\n",
    "        activation_function=LogisticFunction(),\n",
    "        hidden_neuron_count=dimension,\n",
    "        output_neuron_count=dimension,\n",
    "        scale=scale,\n",
    "    )\n",
    ")\n",
    "nn_layer6 = NNLayer6(\n",
    "    NNGraph6(\n",
    "        activation_function=LogisticFunction(),\n",
    "        hidden_neuron_count=dimension,\n",
    "        output_neuron_count=dimension,\n",
    "        scale=scale,\n",
    "    )\n",
    ")\n",
    "\n",
    "nn_layer7 = NNLayer7(\n",
    "    NNGraph7(\n",
    "        activation_function=LogisticFunction(),\n",
    "        hidden_neuron_count=dimension,\n",
    "        output_neuron_count=dimension,\n",
    "        scale=scale,\n",
    "    )\n",
    ")\n",
    "\n",
    "opt_params = Adam()\n",
    "opt_params.weight_limit = 0.5\n",
    "opt_params.dropout_rate = 0.0\n",
    "\n",
    "nn = NeuralNetwork(\n",
    "    nn_layer_list=[\n",
    "        nn_layer1, \n",
    "    ],\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=1e-15,\n",
    "    learning_attenuate_rate=0.1,\n",
    "    attenuate_epoch=50,\n",
    "    computable_loss=MeanSquaredError(grad_clip_threshold=10.0),\n",
    "    opt_params=opt_params,\n",
    "    verificatable_result=VerificateFunctionApproximation(),\n",
    "    test_size_rate=0.3,\n",
    "    tol=1e-15\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_arr = np.random.normal(loc=0.0, scale=1.0, size=(1000, dimension))\n",
    "observed_arr = (observed_arr - observed_arr.min()) / (observed_arr.max() - observed_arr.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN starts learning.\n",
      "Best params are updated.\n",
      "Epoch: 1\n",
      "Loss: \n",
      "Training: 4.490551252648391e-06 Test: 4.426635095269675e-06\n",
      "Epoch: 2\n",
      "Loss: \n",
      "Training: 4.677986964112271e-06 Test: 4.362709729973079e-06\n",
      "Best params are updated.\n",
      "Epoch: 3\n",
      "Loss: \n",
      "Training: 4.441482398228462e-06 Test: 4.463023259741073e-06\n",
      "Epoch: 4\n",
      "Loss: \n",
      "Training: 4.511144999435682e-06 Test: 4.322607153596078e-06\n",
      "Best params are updated.\n",
      "Epoch: 5\n",
      "Loss: \n",
      "Training: 4.431879966078373e-06 Test: 4.411916749446522e-06\n",
      "Epoch: 6\n",
      "Loss: \n",
      "Training: 4.520064743596e-06 Test: 4.600078506735519e-06\n",
      "Best params are updated.\n",
      "Epoch: 7\n",
      "Loss: \n",
      "Training: 4.4092931783165446e-06 Test: 4.3703654338645386e-06\n",
      "Epoch: 8\n",
      "Loss: \n",
      "Training: 4.474088995545358e-06 Test: 4.377600695717998e-06\n",
      "Epoch: 9\n",
      "Loss: \n",
      "Training: 4.4552591637550245e-06 Test: 4.698293620702107e-06\n",
      "Epoch: 10\n",
      "Loss: \n",
      "Training: 4.471301914232039e-06 Test: 4.499927437293216e-06\n",
      "Best params are updated.\n",
      "Epoch: 11\n",
      "Loss: \n",
      "Training: 4.399262789527298e-06 Test: 4.568687684160578e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.488305357594814e-06 Test: 4.45331576823398e-06\n",
      "Epoch: 12\n",
      "Loss: \n",
      "Training: 4.489683533849175e-06 Test: 4.335551970228308e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.479176511282705e-06 Test: 4.467521027123071e-06\n",
      "Best params are updated.\n",
      "Epoch: 13\n",
      "Loss: \n",
      "Training: 4.397415424799596e-06 Test: 4.3148420135415535e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.460346168256395e-06 Test: 4.464805251148593e-06\n",
      "Epoch: 14\n",
      "Loss: \n",
      "Training: 4.449250658097416e-06 Test: 4.648985399495298e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.455939470913508e-06 Test: 4.4499871265286424e-06\n",
      "Epoch: 15\n",
      "Loss: \n",
      "Training: 4.409281953754158e-06 Test: 4.727841555837982e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4497500367796826e-06 Test: 4.482624951118563e-06\n",
      "Epoch: 16\n",
      "Loss: \n",
      "Training: 4.441265465202389e-06 Test: 4.654481172369532e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.447490235547261e-06 Test: 4.514217431757709e-06\n",
      "Best params are updated.\n",
      "Epoch: 17\n",
      "Loss: \n",
      "Training: 4.337582164732466e-06 Test: 4.378151256027757e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4396103077079e-06 Test: 4.519657698321112e-06\n",
      "Epoch: 18\n",
      "Loss: \n",
      "Training: 4.470788197432989e-06 Test: 4.563214504277057e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.432439206349492e-06 Test: 4.520436280537433e-06\n",
      "Epoch: 19\n",
      "Loss: \n",
      "Training: 4.472146260996196e-06 Test: 4.381128581100728e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.432109126538255e-06 Test: 4.538997661393338e-06\n",
      "Best params are updated.\n",
      "Epoch: 20\n",
      "Loss: \n",
      "Training: 4.3098151114276696e-06 Test: 4.574640890750184e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.433797836262373e-06 Test: 4.507281157433202e-06\n",
      "Epoch: 21\n",
      "Loss: \n",
      "Training: 4.6115513760278986e-06 Test: 4.3324760264259e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.417649155981935e-06 Test: 4.514752502778898e-06\n",
      "Epoch: 22\n",
      "Loss: \n",
      "Training: 4.495366717880127e-06 Test: 4.477450653142874e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.438878014631995e-06 Test: 4.49113133700543e-06\n",
      "Epoch: 23\n",
      "Loss: \n",
      "Training: 4.446891397557198e-06 Test: 4.707603204969965e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4394463330350905e-06 Test: 4.505321205296886e-06\n",
      "Epoch: 24\n",
      "Loss: \n",
      "Training: 4.446924404078663e-06 Test: 4.706753001435053e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.444393930310851e-06 Test: 4.5445973244397275e-06\n",
      "Epoch: 25\n",
      "Loss: \n",
      "Training: 4.506377285881461e-06 Test: 4.633673115562196e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.444161304908976e-06 Test: 4.550374084633703e-06\n",
      "Epoch: 26\n",
      "Loss: \n",
      "Training: 4.415854230479113e-06 Test: 4.570113890585096e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.453870838121706e-06 Test: 4.540957240606125e-06\n",
      "Epoch: 27\n",
      "Loss: \n",
      "Training: 4.479469803106588e-06 Test: 4.4955912784649666e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.451329714649378e-06 Test: 4.5325205124276814e-06\n",
      "Epoch: 28\n",
      "Loss: \n",
      "Training: 4.584163245327699e-06 Test: 4.407696298021398e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.465518478486791e-06 Test: 4.544264514671403e-06\n",
      "Epoch: 29\n",
      "Loss: \n",
      "Training: 4.491846567168008e-06 Test: 4.37412411209768e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.476855983276262e-06 Test: 4.528712694045836e-06\n",
      "Epoch: 30\n",
      "Loss: \n",
      "Training: 4.359403617935313e-06 Test: 4.5209963573807166e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.478826013893442e-06 Test: 4.528012247145531e-06\n",
      "Epoch: 31\n",
      "Loss: \n",
      "Training: 4.406718147864202e-06 Test: 4.45452969198822e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.483784864544206e-06 Test: 4.522647793808584e-06\n",
      "Epoch: 32\n",
      "Loss: \n",
      "Training: 4.506435017399169e-06 Test: 4.520750434680876e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4633015417278364e-06 Test: 4.534853160364817e-06\n",
      "Best params are updated.\n",
      "Epoch: 33\n",
      "Loss: \n",
      "Training: 4.28275209076385e-06 Test: 4.4608457402097915e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.464408371679741e-06 Test: 4.539183138518618e-06\n",
      "Epoch: 34\n",
      "Loss: \n",
      "Training: 4.44783416662445e-06 Test: 4.319522591359283e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.447994441000407e-06 Test: 4.514507392042599e-06\n",
      "Epoch: 35\n",
      "Loss: \n",
      "Training: 4.573317511719631e-06 Test: 4.474120641250081e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4480854172549855e-06 Test: 4.475784351035022e-06\n",
      "Epoch: 36\n",
      "Loss: \n",
      "Training: 4.469318172117884e-06 Test: 4.393687545728587e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.454779439838803e-06 Test: 4.459829103603811e-06\n",
      "Epoch: 37\n",
      "Loss: \n",
      "Training: 4.7013819459168366e-06 Test: 4.468154847347656e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.460125834002679e-06 Test: 4.44218646911816e-06\n",
      "Epoch: 38\n",
      "Loss: \n",
      "Training: 4.4380763495876e-06 Test: 4.35572039811144e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.482317048283705e-06 Test: 4.4394428260064285e-06\n",
      "Epoch: 39\n",
      "Loss: \n",
      "Training: 4.5122837812488374e-06 Test: 4.5629165069618994e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.467708358709695e-06 Test: 4.434245236015433e-06\n",
      "Epoch: 40\n",
      "Loss: \n",
      "Training: 4.456316625035841e-06 Test: 4.6254993374933734e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.469752080117778e-06 Test: 4.453124475501854e-06\n",
      "Epoch: 41\n",
      "Loss: \n",
      "Training: 4.485023028919254e-06 Test: 4.594901452813513e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.479443380827831e-06 Test: 4.4635747735131205e-06\n",
      "Epoch: 42\n",
      "Loss: \n",
      "Training: 4.412474217242211e-06 Test: 4.59809258278278e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.487273868933336e-06 Test: 4.477611949595651e-06\n",
      "Epoch: 43\n",
      "Loss: \n",
      "Training: 4.443620955238593e-06 Test: 4.35295401863348e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.477877788917639e-06 Test: 4.485346164405841e-06\n",
      "Epoch: 44\n",
      "Loss: \n",
      "Training: 4.419193752447413e-06 Test: 4.671848405708199e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.493964675365114e-06 Test: 4.47455699224821e-06\n",
      "Epoch: 45\n",
      "Loss: \n",
      "Training: 4.383122114145058e-06 Test: 4.609045740386997e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.491100633947411e-06 Test: 4.509789573683102e-06\n",
      "Epoch: 46\n",
      "Loss: \n",
      "Training: 4.538926083137441e-06 Test: 4.489345342323532e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.472081094189953e-06 Test: 4.523282083596792e-06\n",
      "Epoch: 47\n",
      "Loss: \n",
      "Training: 4.424892500897347e-06 Test: 4.456060579493739e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.479041885291908e-06 Test: 4.532847863256287e-06\n",
      "Epoch: 48\n",
      "Loss: \n",
      "Training: 4.38982227986097e-06 Test: 4.5005556651442e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4513929407899595e-06 Test: 4.531638436470895e-06\n",
      "Epoch: 49\n",
      "Loss: \n",
      "Training: 4.465982772476587e-06 Test: 4.559989789887955e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.446567533817297e-06 Test: 4.546121963174171e-06\n",
      "Epoch: 50\n",
      "Loss: \n",
      "Training: 4.408263717523127e-06 Test: 4.411903789293335e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.441937432940071e-06 Test: 4.545829291466777e-06\n",
      "Epoch: 51\n",
      "Loss: \n",
      "Training: 4.437400358351211e-06 Test: 4.558475306935279e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4371321421888e-06 Test: 4.524469736646773e-06\n",
      "Epoch: 52\n",
      "Loss: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 4.5356464738394975e-06 Test: 4.365092174206677e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.432369875131997e-06 Test: 4.520827122058949e-06\n",
      "Epoch: 53\n",
      "Loss: \n",
      "Training: 4.537139670434726e-06 Test: 4.6130494144345e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4446871007917244e-06 Test: 4.49752708120134e-06\n",
      "Epoch: 54\n",
      "Loss: \n",
      "Training: 4.451624411350799e-06 Test: 4.583385989363707e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4540389723113375e-06 Test: 4.523536620781442e-06\n",
      "Epoch: 55\n",
      "Loss: \n",
      "Training: 4.405585349565672e-06 Test: 4.645199080311712e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.457282038201676e-06 Test: 4.5146903791469925e-06\n",
      "Epoch: 56\n",
      "Loss: \n",
      "Training: 4.5176553228563125e-06 Test: 4.379776151455268e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.459528361743737e-06 Test: 4.518305713139464e-06\n",
      "Epoch: 57\n",
      "Loss: \n",
      "Training: 4.545549523038025e-06 Test: 4.440015093570456e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4574012857156245e-06 Test: 4.507348794052638e-06\n",
      "Epoch: 58\n",
      "Loss: \n",
      "Training: 4.512283162420051e-06 Test: 4.3883440958081e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.469466987929694e-06 Test: 4.505744245460308e-06\n",
      "Epoch: 59\n",
      "Loss: \n",
      "Training: 4.475462813644267e-06 Test: 4.424972415792942e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.481713076185601e-06 Test: 4.494523088526699e-06\n",
      "Epoch: 60\n",
      "Loss: \n",
      "Training: 4.4246124579809765e-06 Test: 4.458202036499272e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.482661080302369e-06 Test: 4.481021351117197e-06\n",
      "Epoch: 61\n",
      "Loss: \n",
      "Training: 4.488482525542033e-06 Test: 4.4128585130829435e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.484295954348154e-06 Test: 4.485651175837791e-06\n",
      "Epoch: 62\n",
      "Loss: \n",
      "Training: 4.487305875421735e-06 Test: 4.697596518347536e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.489404171067236e-06 Test: 4.4710894964525564e-06\n",
      "Epoch: 63\n",
      "Loss: \n",
      "Training: 4.525855844041322e-06 Test: 4.487542146521488e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.484570111225461e-06 Test: 4.504339930866643e-06\n",
      "Epoch: 64\n",
      "Loss: \n",
      "Training: 4.490011935238472e-06 Test: 4.599859953681236e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.483441728586119e-06 Test: 4.491789204075342e-06\n",
      "Epoch: 65\n",
      "Loss: \n",
      "Training: 4.457931865515455e-06 Test: 4.534928305678762e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.487280480974887e-06 Test: 4.493436600507096e-06\n",
      "Epoch: 66\n",
      "Loss: \n",
      "Training: 4.531741681829748e-06 Test: 4.453101004790459e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.492515132569866e-06 Test: 4.4824095230438005e-06\n",
      "Epoch: 67\n",
      "Loss: \n",
      "Training: 4.4700114319619965e-06 Test: 4.384532327612815e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.49392376846721e-06 Test: 4.48974200837732e-06\n",
      "Epoch: 68\n",
      "Loss: \n",
      "Training: 4.406504601388518e-06 Test: 4.5807701396734e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.486369959359605e-06 Test: 4.484193731781555e-06\n",
      "Epoch: 69\n",
      "Loss: \n",
      "Training: 4.444555356051608e-06 Test: 4.4491342389747445e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.475792103256452e-06 Test: 4.503436336168086e-06\n",
      "Epoch: 70\n",
      "Loss: \n",
      "Training: 4.6289453738755144e-06 Test: 4.551123271143115e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4727013574971864e-06 Test: 4.505852518486266e-06\n",
      "Epoch: 71\n",
      "Loss: \n",
      "Training: 4.543071526526332e-06 Test: 4.694249012845844e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.49313464908664e-06 Test: 4.51514464195065e-06\n",
      "Epoch: 72\n",
      "Loss: \n",
      "Training: 4.711613802678112e-06 Test: 4.350071894912349e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.49859354918507e-06 Test: 4.54328369192694e-06\n",
      "Epoch: 73\n",
      "Loss: \n",
      "Training: 4.508435919460296e-06 Test: 4.40277480100596e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.5210243419107075e-06 Test: 4.508531229583421e-06\n",
      "Epoch: 74\n",
      "Loss: \n",
      "Training: 4.523730008487947e-06 Test: 4.576150978978019e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.519282349452606e-06 Test: 4.500054495031869e-06\n",
      "Epoch: 75\n",
      "Loss: \n",
      "Training: 4.5203992409994054e-06 Test: 4.5130016226552435e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.5226541567775534e-06 Test: 4.497683597561547e-06\n",
      "Epoch: 76\n",
      "Loss: \n",
      "Training: 4.4376082048106175e-06 Test: 4.509432877161197e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.5289008943259485e-06 Test: 4.495490929259195e-06\n",
      "Epoch: 77\n",
      "Loss: \n",
      "Training: 4.4259476928430985e-06 Test: 4.338974849832675e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.519487546624035e-06 Test: 4.5011241164962705e-06\n",
      "Epoch: 78\n",
      "Loss: \n",
      "Training: 4.651145015132717e-06 Test: 4.565409222090825e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.515081172712145e-06 Test: 4.496568368718255e-06\n",
      "Epoch: 79\n",
      "Loss: \n",
      "Training: 4.5310625215087555e-06 Test: 4.39632570250769e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.5395452140865645e-06 Test: 4.4950322769599974e-06\n",
      "Epoch: 80\n",
      "Loss: \n",
      "Training: 4.4572217790008095e-06 Test: 4.4121500044618085e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.54819593063228e-06 Test: 4.4897514233132915e-06\n",
      "Epoch: 81\n",
      "Loss: \n",
      "Training: 4.348905822848238e-06 Test: 4.4028385422159975e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.531023571144809e-06 Test: 4.475854096645161e-06\n",
      "Epoch: 82\n",
      "Loss: \n",
      "Training: 4.3694277233242695e-06 Test: 4.617221259475775e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.511607000777e-06 Test: 4.446713049582177e-06\n",
      "Epoch: 83\n",
      "Loss: \n",
      "Training: 4.463405981808256e-06 Test: 4.612022861865799e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.477388392841615e-06 Test: 4.473427986038519e-06\n",
      "Epoch: 84\n",
      "Loss: \n",
      "Training: 4.475120750880685e-06 Test: 4.681389569161031e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.472885399076413e-06 Test: 4.494352792124503e-06\n",
      "Epoch: 85\n",
      "Loss: \n",
      "Training: 4.46854291723946e-06 Test: 4.525958503802555e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.468024473315685e-06 Test: 4.504876651142804e-06\n",
      "Epoch: 86\n",
      "Loss: \n",
      "Training: 4.424477832643125e-06 Test: 4.3597620783805635e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.46283884093969e-06 Test: 4.506172339257535e-06\n",
      "Epoch: 87\n",
      "Loss: \n",
      "Training: 4.519711444149507e-06 Test: 4.492250911762568e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.461525803722941e-06 Test: 4.4912052593794725e-06\n",
      "Epoch: 88\n",
      "Loss: \n",
      "Training: 4.4337728834830195e-06 Test: 4.473506731260632e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.470902178853581e-06 Test: 4.5065328655724605e-06\n",
      "Epoch: 89\n",
      "Loss: \n",
      "Training: 4.40560590742664e-06 Test: 4.68501373297952e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.449164965688613e-06 Test: 4.497342616489442e-06\n",
      "Epoch: 90\n",
      "Loss: \n",
      "Training: 4.489768199606383e-06 Test: 4.470463577194908e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.436619304280401e-06 Test: 4.526211419536625e-06\n",
      "Epoch: 91\n",
      "Loss: \n",
      "Training: 4.592269386525161e-06 Test: 4.735948605168955e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.439873946340958e-06 Test: 4.532042776809935e-06\n",
      "Epoch: 92\n",
      "Loss: \n",
      "Training: 4.52041347409288e-06 Test: 4.536433578433641e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4642103027086505e-06 Test: 4.565353783105231e-06\n",
      "Epoch: 93\n",
      "Loss: \n",
      "Training: 4.5694199724417224e-06 Test: 4.330010382733511e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.479308877785512e-06 Test: 4.557275015001017e-06\n",
      "Epoch: 94\n",
      "Loss: \n",
      "Training: 4.413081977523643e-06 Test: 4.579615417925571e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.489910276848858e-06 Test: 4.529073767087788e-06\n",
      "Epoch: 95\n",
      "Loss: \n",
      "Training: 4.470961596474586e-06 Test: 4.423932133756961e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.483706399513153e-06 Test: 4.518896351964242e-06\n",
      "Epoch: 96\n",
      "Loss: \n",
      "Training: 4.433923463550969e-06 Test: 4.4789059642843986e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.483948267436666e-06 Test: 4.508693714959683e-06\n",
      "Epoch: 97\n",
      "Loss: \n",
      "Training: 4.616184645930957e-06 Test: 4.553780335179572e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4848928305274505e-06 Test: 4.520608103550066e-06\n",
      "Epoch: 98\n",
      "Loss: \n",
      "Training: 4.409039060740287e-06 Test: 4.511182532858099e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.494540150705595e-06 Test: 4.526761045891768e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 99\n",
      "Loss: \n",
      "Training: 4.539197700200509e-06 Test: 4.669789170556817e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.492066768431323e-06 Test: 4.530528626051514e-06\n",
      "Epoch: 100\n",
      "Loss: \n",
      "Training: 4.460485108560032e-06 Test: 4.638361371391235e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.505425947708709e-06 Test: 4.529006169809243e-06\n",
      "Epoch: 101\n",
      "Loss: \n",
      "Training: 4.389522174772192e-06 Test: 4.33215965137462e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.502497638604074e-06 Test: 4.545795949228876e-06\n",
      "Epoch: 102\n",
      "Loss: \n",
      "Training: 4.367317187347486e-06 Test: 4.565001264395942e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4822229174287775e-06 Test: 4.505417053849443e-06\n",
      "Epoch: 103\n",
      "Loss: \n",
      "Training: 4.411119071376298e-06 Test: 4.39842920276346e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.466913288754239e-06 Test: 4.508273822445673e-06\n",
      "Epoch: 104\n",
      "Loss: \n",
      "Training: 4.311025621505049e-06 Test: 4.583702028869678e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4510831986476955e-06 Test: 4.515115704448668e-06\n",
      "Epoch: 105\n",
      "Loss: \n",
      "Training: 4.486666370386707e-06 Test: 4.592313327150173e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4408775630458365e-06 Test: 4.515524365543079e-06\n",
      "Epoch: 106\n",
      "Loss: \n",
      "Training: 4.548474943051816e-06 Test: 4.488085712869136e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.442448040437048e-06 Test: 4.5323624848824e-06\n",
      "Epoch: 107\n",
      "Loss: \n",
      "Training: 4.3966340167673976e-06 Test: 4.406439339849345e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.453903188387133e-06 Test: 4.533280459740873e-06\n",
      "Epoch: 108\n",
      "Loss: \n",
      "Training: 4.469410380891318e-06 Test: 4.501509199908714e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4319481254707765e-06 Test: 4.5185463602078505e-06\n",
      "Epoch: 109\n",
      "Loss: \n",
      "Training: 4.427537473107958e-06 Test: 4.586967623896185e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.437985257485881e-06 Test: 4.517579026912912e-06\n",
      "Epoch: 110\n",
      "Loss: \n",
      "Training: 4.590446199686688e-06 Test: 4.594275011854993e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.426819234776626e-06 Test: 4.509296872246849e-06\n",
      "Epoch: 111\n",
      "Loss: \n",
      "Training: 4.477012256272075e-06 Test: 4.396189084957349e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.439815343889292e-06 Test: 4.504888236293224e-06\n",
      "Epoch: 112\n",
      "Loss: \n",
      "Training: 4.436251115370751e-06 Test: 4.476984966575014e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.44856435203928e-06 Test: 4.511291179651498e-06\n",
      "Epoch: 113\n",
      "Loss: \n",
      "Training: 4.397080228750656e-06 Test: 4.319751392048117e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.455457744841606e-06 Test: 4.5024895498694045e-06\n",
      "Epoch: 114\n",
      "Loss: \n",
      "Training: 4.507713051137274e-06 Test: 4.321236984360276e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.454053860579041e-06 Test: 4.49462176879787e-06\n",
      "Epoch: 115\n",
      "Loss: \n",
      "Training: 4.508979015511834e-06 Test: 4.732700552474465e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.473722603542264e-06 Test: 4.468375264346931e-06\n",
      "Epoch: 116\n",
      "Loss: \n",
      "Training: 4.442602452499092e-06 Test: 4.375099075820216e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.475953868054777e-06 Test: 4.482413986879359e-06\n",
      "Epoch: 117\n",
      "Loss: \n",
      "Training: 4.422154403634252e-06 Test: 4.333573215815131e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.465366618999504e-06 Test: 4.471115323174468e-06\n",
      "Epoch: 118\n",
      "Loss: \n",
      "Training: 4.38920526003626e-06 Test: 4.6221593738736665e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.46791865768619e-06 Test: 4.463828710771046e-06\n",
      "Epoch: 119\n",
      "Loss: \n",
      "Training: 4.457617135160569e-06 Test: 4.571162459922517e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.459898145600684e-06 Test: 4.475893728167541e-06\n",
      "Epoch: 120\n",
      "Loss: \n",
      "Training: 4.528978048128701e-06 Test: 4.529280098573357e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.462906111805945e-06 Test: 4.474313211770174e-06\n",
      "Epoch: 121\n",
      "Loss: \n",
      "Training: 4.470154794121959e-06 Test: 4.3112838467709175e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.456759296650146e-06 Test: 4.46781372044201e-06\n",
      "Epoch: 122\n",
      "Loss: \n",
      "Training: 4.460444699923924e-06 Test: 4.311937314800167e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.456073550435135e-06 Test: 4.459323196623368e-06\n",
      "Epoch: 123\n",
      "Loss: \n",
      "Training: 4.53433042011097e-06 Test: 4.304201754474072e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.458492908890453e-06 Test: 4.442818431445883e-06\n",
      "Best params are updated.\n",
      "Epoch: 124\n",
      "Loss: \n",
      "Training: 4.256699448560387e-06 Test: 4.351462743764948e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.472217928026484e-06 Test: 4.441263467688479e-06\n",
      "Epoch: 125\n",
      "Loss: \n",
      "Training: 4.371021567850267e-06 Test: 4.594629028283878e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.447116567768796e-06 Test: 4.444286043628947e-06\n",
      "Epoch: 126\n",
      "Loss: \n",
      "Training: 4.615813336570376e-06 Test: 4.606478913294326e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.433320823002638e-06 Test: 4.430478891209888e-06\n",
      "Epoch: 127\n",
      "Loss: \n",
      "Training: 4.550456602870546e-06 Test: 4.418668612625222e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.450641911409766e-06 Test: 4.453616874957298e-06\n",
      "Epoch: 128\n",
      "Loss: \n",
      "Training: 4.520628307949886e-06 Test: 4.2016234113854864e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.463472131333396e-06 Test: 4.462126414638307e-06\n",
      "Epoch: 129\n",
      "Loss: \n",
      "Training: 4.460863715676622e-06 Test: 4.356509253820899e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.476614436124759e-06 Test: 4.420072818389489e-06\n",
      "Epoch: 130\n",
      "Loss: \n",
      "Training: 4.4345868147440275e-06 Test: 4.6724873485928e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.476939094176365e-06 Test: 4.398607497779327e-06\n",
      "Epoch: 131\n",
      "Loss: \n",
      "Training: 4.451128488790044e-06 Test: 4.419304324927834e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.467499970837897e-06 Test: 4.412928222781272e-06\n",
      "Epoch: 132\n",
      "Loss: \n",
      "Training: 4.5243418876704935e-06 Test: 4.301310277407972e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.465597340304706e-06 Test: 4.423730270596964e-06\n",
      "Epoch: 133\n",
      "Loss: \n",
      "Training: 4.312843855253178e-06 Test: 4.470741234617337e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.471987059079362e-06 Test: 4.422667566857744e-06\n",
      "Epoch: 134\n",
      "Loss: \n",
      "Training: 4.445279922103645e-06 Test: 4.549106613298074e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.449838402593582e-06 Test: 4.4393215148720695e-06\n",
      "Epoch: 135\n",
      "Loss: \n",
      "Training: 4.374167299904133e-06 Test: 4.448019260333007e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.468696449947909e-06 Test: 4.4590859018253826e-06\n",
      "Epoch: 136\n",
      "Loss: \n",
      "Training: 4.448522930311473e-06 Test: 4.342499375930777e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.469011023153296e-06 Test: 4.444424925030296e-06\n",
      "Epoch: 137\n",
      "Loss: \n",
      "Training: 4.500654241305695e-06 Test: 4.5376720247987435e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.452281982527405e-06 Test: 4.418026971293941e-06\n",
      "Epoch: 138\n",
      "Loss: \n",
      "Training: 4.6444656896375334e-06 Test: 4.389831486759635e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.44730174637092e-06 Test: 4.429927312511293e-06\n",
      "Epoch: 139\n",
      "Loss: \n",
      "Training: 4.458717079426152e-06 Test: 4.335641205466473e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.459685484539685e-06 Test: 4.448748120048708e-06\n",
      "Epoch: 140\n",
      "Loss: \n",
      "Training: 4.341927778472228e-06 Test: 4.6024298033942904e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.459470820914637e-06 Test: 4.446661315213266e-06\n",
      "Epoch: 141\n",
      "Loss: \n",
      "Training: 4.32229929861606e-06 Test: 4.311895984138818e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.450204917287458e-06 Test: 4.439655560693415e-06\n",
      "Epoch: 142\n",
      "Loss: \n",
      "Training: 4.672478447929285e-06 Test: 4.660793860792375e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.437321998270059e-06 Test: 4.4289147266145126e-06\n",
      "Epoch: 143\n",
      "Loss: \n",
      "Training: 4.431652851000648e-06 Test: 4.464542681878006e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.452135654295938e-06 Test: 4.464863084952953e-06\n",
      "Epoch: 144\n",
      "Loss: \n",
      "Training: 4.45990413930345e-06 Test: 4.486188765054414e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.464016553870686e-06 Test: 4.464243229679021e-06\n",
      "Epoch: 145\n",
      "Loss: \n",
      "Training: 4.502098621063377e-06 Test: 4.418959455103591e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.465478975590666e-06 Test: 4.4579514448546545e-06\n",
      "Epoch: 146\n",
      "Loss: \n",
      "Training: 4.525159903830296e-06 Test: 4.585345401493398e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.47827210770659e-06 Test: 4.455045464331713e-06\n",
      "Epoch: 147\n",
      "Loss: \n",
      "Training: 4.444471716784022e-06 Test: 4.681992455607189e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.485935805058472e-06 Test: 4.479330066887974e-06\n",
      "Epoch: 148\n",
      "Loss: \n",
      "Training: 4.515767612736509e-06 Test: 4.470866571245092e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.480317552606305e-06 Test: 4.493762109968819e-06\n",
      "Epoch: 149\n",
      "Loss: \n",
      "Training: 4.462647079775753e-06 Test: 4.424942966601857e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.467447744916203e-06 Test: 4.501865618417364e-06\n",
      "Epoch: 150\n",
      "Loss: \n",
      "Training: 4.432154160264128e-06 Test: 4.7076179614467166e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.467840744951163e-06 Test: 4.510795794530903e-06\n",
      "Epoch: 151\n",
      "Loss: \n",
      "Training: 4.45314066454589e-06 Test: 4.418015982429487e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4768633831303526e-06 Test: 4.521314610336145e-06\n",
      "Epoch: 152\n",
      "Loss: \n",
      "Training: 4.440849359885046e-06 Test: 4.645972206373357e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.489947519723336e-06 Test: 4.531926610165213e-06\n",
      "Epoch: 153\n",
      "Loss: \n",
      "Training: 4.468011692959245e-06 Test: 4.272367093448986e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.466784610918912e-06 Test: 4.530444444723311e-06\n",
      "Epoch: 154\n",
      "Loss: \n",
      "Training: 4.467539845333751e-06 Test: 4.612979078196642e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.470420495114773e-06 Test: 4.511226885880409e-06\n",
      "Epoch: 155\n",
      "Loss: \n",
      "Training: 4.417999995654708e-06 Test: 4.476170739543593e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.471184065717802e-06 Test: 4.523905917194632e-06\n",
      "Epoch: 156\n",
      "Loss: \n",
      "Training: 4.429398094741853e-06 Test: 4.496337264737208e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4627742031769354e-06 Test: 4.529627045638632e-06\n",
      "Epoch: 157\n",
      "Loss: \n",
      "Training: 4.486929171314182e-06 Test: 4.3768205303106975e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.45319802226809e-06 Test: 4.520726231963013e-06\n",
      "Epoch: 158\n",
      "Loss: \n",
      "Training: 4.5670054839654525e-06 Test: 4.5691435382292005e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.457443767721107e-06 Test: 4.490209039433363e-06\n",
      "Epoch: 159\n",
      "Loss: \n",
      "Training: 4.487705757074584e-06 Test: 4.403643396099416e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.462567554844001e-06 Test: 4.500036736131775e-06\n",
      "Epoch: 160\n",
      "Loss: \n",
      "Training: 4.4959252126857435e-06 Test: 4.385978636726443e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4650734225738845e-06 Test: 4.497906779081529e-06\n",
      "Epoch: 161\n",
      "Loss: \n",
      "Training: 4.528120315103837e-06 Test: 4.5657284251975936e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.471450527816046e-06 Test: 4.465742846609503e-06\n",
      "Epoch: 162\n",
      "Loss: \n",
      "Training: 4.399633645566099e-06 Test: 4.492827875689034e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.47894849287184e-06 Test: 4.480514090886314e-06\n",
      "Epoch: 163\n",
      "Loss: \n",
      "Training: 4.45958541257866e-06 Test: 4.662688187330684e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.474826921439946e-06 Test: 4.465199657817881e-06\n",
      "Epoch: 164\n",
      "Loss: \n",
      "Training: 4.3466772806471755e-06 Test: 4.4853218909851794e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.473984293401887e-06 Test: 4.5042317672060515e-06\n",
      "Epoch: 165\n",
      "Loss: \n",
      "Training: 4.530644686070167e-06 Test: 4.711157601864503e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.46189803693323e-06 Test: 4.491466048484906e-06\n",
      "Epoch: 166\n",
      "Loss: \n",
      "Training: 4.563058216992659e-06 Test: 4.41553085822164e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.473162505974776e-06 Test: 4.514964734716997e-06\n",
      "Epoch: 167\n",
      "Loss: \n",
      "Training: 4.490256646451811e-06 Test: 4.512755647529964e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.486528518199856e-06 Test: 4.5068840940654385e-06\n",
      "Epoch: 168\n",
      "Loss: \n",
      "Training: 4.418743470326155e-06 Test: 4.596739874822946e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.486861265713619e-06 Test: 4.520477605787366e-06\n",
      "Epoch: 169\n",
      "Loss: \n",
      "Training: 4.378236225446542e-06 Test: 4.6335755823970345e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.472035064349689e-06 Test: 4.52323723944674e-06\n",
      "Epoch: 170\n",
      "Loss: \n",
      "Training: 4.496554305936721e-06 Test: 4.42431306594748e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.461088111186885e-06 Test: 4.546230458076502e-06\n",
      "Epoch: 171\n",
      "Loss: \n",
      "Training: 4.443385611670466e-06 Test: 4.419759963208622e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.461151020511983e-06 Test: 4.550063900998605e-06\n",
      "Epoch: 172\n",
      "Loss: \n",
      "Training: 4.496521657643189e-06 Test: 4.778023984814515e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.452677550168646e-06 Test: 4.535467054799708e-06\n",
      "Epoch: 173\n",
      "Loss: \n",
      "Training: 4.344252015510231e-06 Test: 4.564022567048072e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.462366351376355e-06 Test: 4.5639866657122565e-06\n",
      "Epoch: 174\n",
      "Loss: \n",
      "Training: 4.392020415090718e-06 Test: 4.369437800469564e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.450833011669512e-06 Test: 4.554120103683995e-06\n",
      "Epoch: 175\n",
      "Loss: \n",
      "Training: 4.442495742537877e-06 Test: 4.541217631175293e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4553673251138655e-06 Test: 4.542531694632433e-06\n",
      "Epoch: 176\n",
      "Loss: \n",
      "Training: 4.359621930611505e-06 Test: 4.458602859853762e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.446552430760637e-06 Test: 4.525537697563512e-06\n",
      "Epoch: 177\n",
      "Loss: \n",
      "Training: 4.449274678552318e-06 Test: 4.4552015334482605e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.426208802122521e-06 Test: 4.5298448977267246e-06\n",
      "Epoch: 178\n",
      "Loss: \n",
      "Training: 4.641730481362591e-06 Test: 4.286189272170056e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.422110605332572e-06 Test: 4.5240894863185545e-06\n",
      "Epoch: 179\n",
      "Loss: \n",
      "Training: 4.558901495725751e-06 Test: 4.575049911400679e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.444409306436216e-06 Test: 4.493034426053266e-06\n",
      "Epoch: 180\n",
      "Loss: \n",
      "Training: 4.504871642150834e-06 Test: 4.429342659179851e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.462475833464137e-06 Test: 4.48718185895363e-06\n",
      "Epoch: 181\n",
      "Loss: \n",
      "Training: 4.548321960632012e-06 Test: 4.266962992789975e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.463307567085549e-06 Test: 4.487684818276867e-06\n",
      "Epoch: 182\n",
      "Loss: \n",
      "Training: 4.390649512309198e-06 Test: 4.4501093430767375e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4738012019817026e-06 Test: 4.472405121235003e-06\n",
      "Epoch: 183\n",
      "Loss: \n",
      "Training: 4.467283741207705e-06 Test: 4.531920238566849e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.463213987448304e-06 Test: 4.439613657061226e-06\n",
      "Epoch: 184\n",
      "Loss: \n",
      "Training: 4.429658760637575e-06 Test: 4.405290941685877e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.475517160018052e-06 Test: 4.436403424213103e-06\n",
      "Epoch: 185\n",
      "Loss: \n",
      "Training: 4.407451143284524e-06 Test: 4.538888895943579e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4792809945727365e-06 Test: 4.439988738334734e-06\n",
      "Epoch: 186\n",
      "Loss: \n",
      "Training: 4.417295107747122e-06 Test: 4.304877411226095e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.475776534647401e-06 Test: 4.439755864811563e-06\n",
      "Epoch: 187\n",
      "Loss: \n",
      "Training: 4.296888477332514e-06 Test: 4.573784686462239e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.481543852360963e-06 Test: 4.424383319948797e-06\n",
      "Epoch: 188\n",
      "Loss: \n",
      "Training: 4.387765870938349e-06 Test: 4.387018980443371e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.466305232238982e-06 Test: 4.436241635250194e-06\n",
      "Epoch: 189\n",
      "Loss: \n",
      "Training: 4.4294230429517515e-06 Test: 4.47890780708569e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.440908771196558e-06 Test: 4.446324606077526e-06\n",
      "Epoch: 190\n",
      "Loss: \n",
      "Training: 4.445126769177374e-06 Test: 4.4490795216889605e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.427960925919158e-06 Test: 4.436710395646027e-06\n",
      "Epoch: 191\n",
      "Loss: \n",
      "Training: 4.495612798591439e-06 Test: 4.50991899332483e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4219864386218114e-06 Test: 4.438684081896938e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 192\n",
      "Loss: \n",
      "Training: 4.353642497871498e-06 Test: 4.544655794298792e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.416715522417755e-06 Test: 4.462979681950423e-06\n",
      "Epoch: 193\n",
      "Loss: \n",
      "Training: 4.448948351385253e-06 Test: 4.380426499810059e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.413014820973985e-06 Test: 4.472434327072628e-06\n",
      "Epoch: 194\n",
      "Loss: \n",
      "Training: 4.471167133720715e-06 Test: 4.480105453354724e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.411181281991739e-06 Test: 4.457284953196949e-06\n",
      "Epoch: 195\n",
      "Loss: \n",
      "Training: 4.4069946529008975e-06 Test: 4.558116099037184e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.415332119300055e-06 Test: 4.464766404363834e-06\n",
      "Epoch: 196\n",
      "Loss: \n",
      "Training: 4.532326483704367e-06 Test: 4.264388908531666e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.41528647026169e-06 Test: 4.4666891246731946e-06\n",
      "Epoch: 197\n",
      "Loss: \n",
      "Training: 4.446419437439904e-06 Test: 4.584213743871433e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.426789607857416e-06 Test: 4.462640274403751e-06\n",
      "Epoch: 198\n",
      "Loss: \n",
      "Training: 4.723376563622489e-06 Test: 4.642739250825861e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.441742703868155e-06 Test: 4.463683180144671e-06\n",
      "Epoch: 199\n",
      "Loss: \n",
      "Training: 4.5927582712756044e-06 Test: 4.3837087446314135e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.475303773136568e-06 Test: 4.4892552071829195e-06\n",
      "Epoch: 200\n",
      "Loss: \n",
      "Training: 4.690791423199561e-06 Test: 4.531283441734857e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.491637295968954e-06 Test: 4.479735300937492e-06\n",
      "Epoch: 201\n",
      "Loss: \n",
      "Training: 4.408438477729403e-06 Test: 4.4589661356870255e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.516203761371173e-06 Test: 4.487955692942081e-06\n",
      "Epoch: 202\n",
      "Loss: \n",
      "Training: 4.4712225248708e-06 Test: 4.527594823996136e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.507486329284969e-06 Test: 4.482860407178302e-06\n",
      "Epoch: 203\n",
      "Loss: \n",
      "Training: 4.390549910330656e-06 Test: 4.703390772258836e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.519244331984899e-06 Test: 4.481154310148036e-06\n",
      "Epoch: 204\n",
      "Loss: \n",
      "Training: 4.381406072632907e-06 Test: 4.347412203671027e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.51340448787944e-06 Test: 4.513450737392914e-06\n",
      "Epoch: 205\n",
      "Loss: \n",
      "Training: 4.4516482660806005e-06 Test: 4.731375272217812e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.504428381770659e-06 Test: 4.500181412424544e-06\n",
      "Epoch: 206\n",
      "Loss: \n",
      "Training: 4.447881356466158e-06 Test: 4.66817571361032e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.508893743088629e-06 Test: 4.5175073297426075e-06\n",
      "Epoch: 207\n",
      "Loss: \n",
      "Training: 4.438653375107172e-06 Test: 4.615128120845748e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.500449230364808e-06 Test: 4.557886010250473e-06\n",
      "Epoch: 208\n",
      "Loss: \n",
      "Training: 4.392777601220621e-06 Test: 4.360179945016196e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.499672624131535e-06 Test: 4.560977447947904e-06\n",
      "Epoch: 209\n",
      "Loss: \n",
      "Training: 4.380191114775997e-06 Test: 4.496906613567146e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.466612727891348e-06 Test: 4.532721517366937e-06\n",
      "Epoch: 210\n",
      "Loss: \n",
      "Training: 4.493564841371774e-06 Test: 4.456449958975703e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.445356012241387e-06 Test: 4.54404130426051e-06\n",
      "Epoch: 211\n",
      "Loss: \n",
      "Training: 4.562298184387015e-06 Test: 4.6516508686789045e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.425633354058609e-06 Test: 4.536557955984595e-06\n",
      "Epoch: 212\n",
      "Loss: \n",
      "Training: 4.392233412791645e-06 Test: 4.465808734313663e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4410193247243704e-06 Test: 4.555826429283783e-06\n",
      "Epoch: 213\n",
      "Loss: \n",
      "Training: 4.47768904310567e-06 Test: 4.455446975620866e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.433120413516455e-06 Test: 4.549647820315536e-06\n",
      "Epoch: 214\n",
      "Loss: \n",
      "Training: 4.400299417042789e-06 Test: 4.4792014733967375e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.441834326793956e-06 Test: 4.524853440651739e-06\n",
      "Epoch: 215\n",
      "Loss: \n",
      "Training: 4.297686074595024e-06 Test: 4.677277403152875e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4437236612349446e-06 Test: 4.53803236762431e-06\n",
      "Epoch: 216\n",
      "Loss: \n",
      "Training: 4.404150150001515e-06 Test: 4.3685345688745766e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.428327442086387e-06 Test: 4.532622580717816e-06\n",
      "Epoch: 217\n",
      "Loss: \n",
      "Training: 4.447317539237176e-06 Test: 4.602652288603478e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.423954321439923e-06 Test: 4.502658466244241e-06\n",
      "Epoch: 218\n",
      "Loss: \n",
      "Training: 4.489678855857347e-06 Test: 4.6814430341680215e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.424820737852923e-06 Test: 4.501410883020014e-06\n",
      "Epoch: 219\n",
      "Loss: \n",
      "Training: 4.4173059894907926e-06 Test: 4.404698074293982e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.434510863316595e-06 Test: 4.533537191935196e-06\n",
      "Epoch: 220\n",
      "Loss: \n",
      "Training: 4.497764378196464e-06 Test: 4.641112569223e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4382223507880745e-06 Test: 4.52431633800788e-06\n",
      "Epoch: 221\n",
      "Loss: \n",
      "Training: 4.519489435733556e-06 Test: 4.68547530996114e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.438642304470544e-06 Test: 4.542782599032609e-06\n",
      "Epoch: 222\n",
      "Loss: \n",
      "Training: 4.537570163551534e-06 Test: 4.61555993241048e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.434361429605198e-06 Test: 4.546165043160833e-06\n",
      "Epoch: 223\n",
      "Loss: \n",
      "Training: 4.513015961955815e-06 Test: 4.589732382870682e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.448895104681186e-06 Test: 4.561140162970515e-06\n",
      "Epoch: 224\n",
      "Loss: \n",
      "Training: 4.402270078336705e-06 Test: 4.35759770250438e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4524277965662e-06 Test: 4.574568703695497e-06\n",
      "Epoch: 225\n",
      "Loss: \n",
      "Training: 4.486428632423144e-06 Test: 4.657801464763019e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.452624862695593e-06 Test: 4.562408326606261e-06\n",
      "Epoch: 226\n",
      "Loss: \n",
      "Training: 4.487560942364474e-06 Test: 4.465075194993789e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.471499118478405e-06 Test: 4.5604607327672755e-06\n",
      "Epoch: 227\n",
      "Loss: \n",
      "Training: 4.371960878987857e-06 Test: 4.586904727260652e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.479840197714702e-06 Test: 4.570114795379197e-06\n",
      "Epoch: 228\n",
      "Loss: \n",
      "Training: 4.391834874448379e-06 Test: 4.638804532846144e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.472304531689769e-06 Test: 4.568540039244915e-06\n",
      "Epoch: 229\n",
      "Loss: \n",
      "Training: 4.539101519124768e-06 Test: 4.654399511878691e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4625201335488716e-06 Test: 4.564276189112727e-06\n",
      "Epoch: 230\n",
      "Loss: \n",
      "Training: 4.436403340613871e-06 Test: 4.429196905479586e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.474699686512271e-06 Test: 4.589246332871198e-06\n",
      "Epoch: 231\n",
      "Loss: \n",
      "Training: 4.377888591480714e-06 Test: 4.327053289103508e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.468563582754009e-06 Test: 4.568054766496857e-06\n",
      "Epoch: 232\n",
      "Loss: \n",
      "Training: 4.3913995272876275e-06 Test: 4.659722957504206e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4544034983287266e-06 Test: 4.532212564411093e-06\n",
      "Epoch: 233\n",
      "Loss: \n",
      "Training: 4.5379063461414945e-06 Test: 4.397082507737429e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.439786434702336e-06 Test: 4.536628866920466e-06\n",
      "Epoch: 234\n",
      "Loss: \n",
      "Training: 4.4412580986102495e-06 Test: 4.620811753318252e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.442275473120905e-06 Test: 4.517363879407141e-06\n",
      "Epoch: 235\n",
      "Loss: \n",
      "Training: 4.4844222819315936e-06 Test: 4.704243765423474e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4461742751482586e-06 Test: 4.543685284488528e-06\n",
      "Epoch: 236\n",
      "Loss: \n",
      "Training: 4.440273333832669e-06 Test: 4.533555286788787e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.445973640099102e-06 Test: 4.548329514554573e-06\n",
      "Epoch: 237\n",
      "Loss: \n",
      "Training: 4.5329189154779175e-06 Test: 4.4887132846799915e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.441244879245922e-06 Test: 4.555177523734073e-06\n",
      "Epoch: 238\n",
      "Loss: \n",
      "Training: 4.325147894175581e-06 Test: 4.562097716325032e-06\n",
      "Rolling mean of Loss (Window is 10): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 4.457340682894929e-06 Test: 4.5453583794760076e-06\n",
      "Epoch: 239\n",
      "Loss: \n",
      "Training: 4.558599499516422e-06 Test: 4.453192030329231e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.450671984867649e-06 Test: 4.537687697823896e-06\n",
      "Epoch: 240\n",
      "Loss: \n",
      "Training: 4.384939688088834e-06 Test: 4.704212197335253e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.452621782906815e-06 Test: 4.51756694966895e-06\n",
      "Epoch: 241\n",
      "Loss: \n",
      "Training: 4.453851606516538e-06 Test: 4.521427258807592e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.44747541765431e-06 Test: 4.545068478854517e-06\n",
      "Epoch: 242\n",
      "Loss: \n",
      "Training: 4.363200488340256e-06 Test: 4.5071403760013116e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.455071719157893e-06 Test: 4.564505875824925e-06\n",
      "Epoch: 243\n",
      "Loss: \n",
      "Training: 4.527645382353561e-06 Test: 4.586459827244153e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.452251815263156e-06 Test: 4.549247617674635e-06\n",
      "Epoch: 244\n",
      "Loss: \n",
      "Training: 4.484170007166908e-06 Test: 4.596250242346371e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.451225718884363e-06 Test: 4.5681853496253075e-06\n",
      "Epoch: 245\n",
      "Loss: \n",
      "Training: 4.383027129836969e-06 Test: 4.426075465603365e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.455516909740028e-06 Test: 4.5657291985281195e-06\n",
      "Epoch: 246\n",
      "Loss: \n",
      "Training: 4.3576854502220295e-06 Test: 4.559877283328253e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.445377394530565e-06 Test: 4.537912368546109e-06\n",
      "Epoch: 247\n",
      "Loss: \n",
      "Training: 4.5243840925255794e-06 Test: 4.41252440698355e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.437118606169501e-06 Test: 4.5405445682000555e-06\n",
      "Epoch: 248\n",
      "Loss: \n",
      "Training: 4.526573125832384e-06 Test: 4.377578638822452e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4362651238742684e-06 Test: 4.532925680430411e-06\n",
      "Epoch: 249\n",
      "Loss: \n",
      "Training: 4.425631374052602e-06 Test: 4.499173853596439e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.456407647039948e-06 Test: 4.514473772680153e-06\n",
      "Epoch: 250\n",
      "Loss: \n",
      "Training: 4.371529068431207e-06 Test: 4.555182227287609e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.443110834493567e-06 Test: 4.519071955006874e-06\n",
      "Epoch: 251\n",
      "Loss: \n",
      "Training: 4.492052370729934e-06 Test: 4.547743776910573e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.441769772527803e-06 Test: 4.504168958002109e-06\n",
      "Epoch: 252\n",
      "Loss: \n",
      "Training: 4.438635535664007e-06 Test: 4.590105589202687e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.445589848949143e-06 Test: 4.506800609812408e-06\n",
      "Epoch: 253\n",
      "Loss: \n",
      "Training: 4.47217885765302e-06 Test: 4.502317594445454e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.453133353681518e-06 Test: 4.5150971311325455e-06\n",
      "Epoch: 254\n",
      "Loss: \n",
      "Training: 4.352511311996232e-06 Test: 4.477913692244113e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.447586701211464e-06 Test: 4.506682907852675e-06\n",
      "Epoch: 255\n",
      "Loss: \n",
      "Training: 4.355289032118505e-06 Test: 4.422945327329838e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.434420831694396e-06 Test: 4.49484925284245e-06\n",
      "Epoch: 256\n",
      "Loss: \n",
      "Training: 4.460366666441954e-06 Test: 4.280132269891956e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.43164702192255e-06 Test: 4.4945362390150964e-06\n",
      "Epoch: 257\n",
      "Loss: \n",
      "Training: 4.531002340015669e-06 Test: 4.466147900002147e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.441915143544542e-06 Test: 4.466561737671467e-06\n",
      "Epoch: 258\n",
      "Loss: \n",
      "Training: 4.510116546085815e-06 Test: 4.576994621780123e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.442576968293551e-06 Test: 4.471924086973327e-06\n",
      "Epoch: 259\n",
      "Loss: \n",
      "Training: 4.5137655441981365e-06 Test: 4.702872823316167e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.440931310318895e-06 Test: 4.491865685269095e-06\n",
      "Epoch: 260\n",
      "Loss: \n",
      "Training: 4.461168353851028e-06 Test: 4.297590307976373e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.449744727333447e-06 Test: 4.5122355822410676e-06\n",
      "Epoch: 261\n",
      "Loss: \n",
      "Training: 4.821781293441386e-06 Test: 4.568946924911152e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.45870865587543e-06 Test: 4.486476390309944e-06\n",
      "Epoch: 262\n",
      "Loss: \n",
      "Training: 4.483037294108429e-06 Test: 4.648497225930111e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.491681548146575e-06 Test: 4.4885967051100015e-06\n",
      "Epoch: 263\n",
      "Loss: \n",
      "Training: 4.406647369744433e-06 Test: 4.432361249265712e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.496121723991018e-06 Test: 4.494435868782744e-06\n",
      "Epoch: 264\n",
      "Loss: \n",
      "Training: 4.6578619801592876e-06 Test: 4.586952178488355e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.489568575200158e-06 Test: 4.4874402342647694e-06\n",
      "Epoch: 265\n",
      "Loss: \n",
      "Training: 4.418938711037144e-06 Test: 4.433749907234226e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.520103642016464e-06 Test: 4.498344082889193e-06\n",
      "Epoch: 266\n",
      "Loss: \n",
      "Training: 4.457964797225653e-06 Test: 4.513187828219627e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.526468609908328e-06 Test: 4.499424540879632e-06\n",
      "Epoch: 267\n",
      "Loss: \n",
      "Training: 4.394872750297804e-06 Test: 4.620781697032271e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.526228422986698e-06 Test: 4.522730096712399e-06\n",
      "Epoch: 268\n",
      "Loss: \n",
      "Training: 4.490342957507058e-06 Test: 4.448373909702445e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.512615464014912e-06 Test: 4.538193476415412e-06\n",
      "Epoch: 269\n",
      "Loss: \n",
      "Training: 4.4306708959205255e-06 Test: 4.4349231915153014e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.510638105157036e-06 Test: 4.525331405207644e-06\n",
      "Epoch: 270\n",
      "Loss: \n",
      "Training: 4.494445430112094e-06 Test: 4.674359043212865e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.502328640329275e-06 Test: 4.4985364420275574e-06\n",
      "Epoch: 271\n",
      "Loss: \n",
      "Training: 4.403048002188768e-06 Test: 4.6275946320324926e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.505656347955382e-06 Test: 4.536213315551207e-06\n",
      "Epoch: 272\n",
      "Loss: \n",
      "Training: 4.623190747766956e-06 Test: 4.712183619246036e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.46378301883012e-06 Test: 4.5420780862633404e-06\n",
      "Epoch: 273\n",
      "Loss: \n",
      "Training: 4.547519848048565e-06 Test: 4.3387944127394084e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.477798364195972e-06 Test: 4.548446725594933e-06\n",
      "Epoch: 274\n",
      "Loss: \n",
      "Training: 4.40165381591747e-06 Test: 4.441478592077645e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.491885612026385e-06 Test: 4.539090041942302e-06\n",
      "Epoch: 275\n",
      "Loss: \n",
      "Training: 4.439344329112897e-06 Test: 4.550729301130829e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.466264795602203e-06 Test: 4.524542683301232e-06\n",
      "Epoch: 276\n",
      "Loss: \n",
      "Training: 4.430794205940715e-06 Test: 4.636790964044187e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.468305357409778e-06 Test: 4.536240622690891e-06\n",
      "Epoch: 277\n",
      "Loss: \n",
      "Training: 4.362651098609163e-06 Test: 4.423832243539764e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.465588298281286e-06 Test: 4.548600936273348e-06\n",
      "Epoch: 278\n",
      "Loss: \n",
      "Training: 4.480570119379568e-06 Test: 4.336264333646122e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.462366133112422e-06 Test: 4.5289059909240976e-06\n",
      "Epoch: 279\n",
      "Loss: \n",
      "Training: 4.514211355447693e-06 Test: 4.372138526229419e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.461388849299672e-06 Test: 4.517695033318465e-06\n",
      "Epoch: 280\n",
      "Loss: \n",
      "Training: 4.437519932692535e-06 Test: 4.328205182020716e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.469742895252389e-06 Test: 4.5114165667898776e-06\n",
      "Epoch: 281\n",
      "Loss: \n",
      "Training: 4.575644896148991e-06 Test: 4.618702106792126e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.464050345510433e-06 Test: 4.476801180670663e-06\n",
      "Epoch: 282\n",
      "Loss: \n",
      "Training: 4.4487540333813555e-06 Test: 4.639792332630452e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.481310034906455e-06 Test: 4.4759119281466255e-06\n",
      "Epoch: 283\n",
      "Loss: \n",
      "Training: 4.498546655896225e-06 Test: 4.64137989601615e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.463866363467895e-06 Test: 4.468672799485066e-06\n",
      "Epoch: 284\n",
      "Loss: \n",
      "Training: 4.364223049273755e-06 Test: 4.337432114613216e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.458969044252661e-06 Test: 4.4989313478127405e-06\n",
      "Epoch: 285\n",
      "Loss: \n",
      "Training: 4.379843657094793e-06 Test: 4.523652261036609e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.45522596758829e-06 Test: 4.4885267000662974e-06\n",
      "Epoch: 286\n",
      "Loss: \n",
      "Training: 4.422375663837299e-06 Test: 4.323567992716863e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.449275900386479e-06 Test: 4.485818996056876e-06\n",
      "Epoch: 287\n",
      "Loss: \n",
      "Training: 4.403334646746893e-06 Test: 4.684828648538754e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.448434046176138e-06 Test: 4.454496698924144e-06\n",
      "Epoch: 288\n",
      "Loss: \n",
      "Training: 4.463316787215006e-06 Test: 4.4299762584645535e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.45250240098991e-06 Test: 4.480596339424043e-06\n",
      "Epoch: 289\n",
      "Loss: \n",
      "Training: 4.502295084256001e-06 Test: 4.716198996169275e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.450777067773454e-06 Test: 4.489967531905886e-06\n",
      "Epoch: 290\n",
      "Loss: \n",
      "Training: 4.481849808045234e-06 Test: 4.591895440157667e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.449585440654284e-06 Test: 4.524373578899872e-06\n",
      "Epoch: 291\n",
      "Loss: \n",
      "Training: 4.541403208078415e-06 Test: 4.40108045790942e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.454018428189555e-06 Test: 4.550742604713566e-06\n",
      "Epoch: 292\n",
      "Loss: \n",
      "Training: 4.423317194414779e-06 Test: 4.441370224610911e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.450594259382498e-06 Test: 4.528980439825296e-06\n",
      "Epoch: 293\n",
      "Loss: \n",
      "Training: 4.362588189433232e-06 Test: 4.6521601171568436e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.44805057548584e-06 Test: 4.509138229023342e-06\n",
      "Epoch: 294\n",
      "Loss: \n",
      "Training: 4.320054552524356e-06 Test: 4.5709729328870955e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.434454728839541e-06 Test: 4.510216251137411e-06\n",
      "Epoch: 295\n",
      "Loss: \n",
      "Training: 4.3719083788887046e-06 Test: 4.644536192351568e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4300378791646e-06 Test: 4.533570332964799e-06\n",
      "Epoch: 296\n",
      "Loss: \n",
      "Training: 4.572568387549337e-06 Test: 4.423726888072409e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.429244351343992e-06 Test: 4.545658726096294e-06\n",
      "Epoch: 297\n",
      "Loss: \n",
      "Training: 4.378975070367407e-06 Test: 4.394852071838325e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4442636237151955e-06 Test: 4.555674615631849e-06\n",
      "Epoch: 298\n",
      "Loss: \n",
      "Training: 4.342414815147911e-06 Test: 4.668210533476107e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4418276660772475e-06 Test: 4.526676957961806e-06\n",
      "Epoch: 299\n",
      "Loss: \n",
      "Training: 4.394621701277038e-06 Test: 4.377017918189963e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.429737468870537e-06 Test: 4.550500385462961e-06\n",
      "Epoch: 300\n",
      "Loss: \n",
      "Training: 4.418819588785372e-06 Test: 4.432804848853157e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.418970130572642e-06 Test: 4.516582277665031e-06\n",
      "Epoch: 301\n",
      "Loss: \n",
      "Training: 4.362389218743957e-06 Test: 4.626774178655816e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.412667108646655e-06 Test: 4.5006732185345794e-06\n",
      "Epoch: 302\n",
      "Loss: \n",
      "Training: 4.45989950350016e-06 Test: 4.4188384098122816e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.394765709713209e-06 Test: 4.523242590609219e-06\n",
      "Epoch: 303\n",
      "Loss: \n",
      "Training: 4.535750404899951e-06 Test: 4.408952041437029e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.398423940621748e-06 Test: 4.520989409129357e-06\n",
      "Epoch: 304\n",
      "Loss: \n",
      "Training: 4.488385184713547e-06 Test: 4.279420978056942e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4157401621684195e-06 Test: 4.496668601557375e-06\n",
      "Epoch: 305\n",
      "Loss: \n",
      "Training: 4.422462070336999e-06 Test: 4.624854169471901e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.432573225387339e-06 Test: 4.46751340607436e-06\n",
      "Epoch: 306\n",
      "Loss: \n",
      "Training: 4.391256932774991e-06 Test: 4.583750123038882e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.437628594532169e-06 Test: 4.4655452037863935e-06\n",
      "Epoch: 307\n",
      "Loss: \n",
      "Training: 4.453280743249538e-06 Test: 4.531840630453669e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.419497449054733e-06 Test: 4.48154752728304e-06\n",
      "Epoch: 308\n",
      "Loss: \n",
      "Training: 4.683256500511075e-06 Test: 4.631457681576607e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.426928016342947e-06 Test: 4.495246383144574e-06\n",
      "Epoch: 309\n",
      "Loss: \n",
      "Training: 4.501914583127573e-06 Test: 4.495004605676709e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.461012184879263e-06 Test: 4.491571097954625e-06\n",
      "Epoch: 310\n",
      "Loss: \n",
      "Training: 4.4336311111837385e-06 Test: 4.409252448710892e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.471741473064316e-06 Test: 4.5033697667033e-06\n",
      "Epoch: 311\n",
      "Loss: \n",
      "Training: 4.363321441379289e-06 Test: 4.601238313750938e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.473222625304152e-06 Test: 4.501014526689073e-06\n",
      "Epoch: 312\n",
      "Loss: \n",
      "Training: 4.4792784703484716e-06 Test: 4.681085379414906e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.473315847567685e-06 Test: 4.498460940198586e-06\n",
      "Epoch: 313\n",
      "Loss: \n",
      "Training: 4.408743144304777e-06 Test: 4.706648295615116e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.475253744252517e-06 Test: 4.524685637158849e-06\n",
      "Epoch: 314\n",
      "Loss: \n",
      "Training: 4.482044050965051e-06 Test: 4.479227613818016e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.462553018193e-06 Test: 4.5544552625766565e-06\n",
      "Epoch: 315\n",
      "Loss: \n",
      "Training: 4.402226624543384e-06 Test: 4.666413108671563e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.461918904818151e-06 Test: 4.574435926152764e-06\n",
      "Epoch: 316\n",
      "Loss: \n",
      "Training: 4.4649495950707355e-06 Test: 4.5234380875976465e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.459895360238789e-06 Test: 4.57859182007273e-06\n",
      "Epoch: 317\n",
      "Loss: \n",
      "Training: 4.52855798760022e-06 Test: 4.5013582226817074e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.467264626468364e-06 Test: 4.5725606165286065e-06\n",
      "Epoch: 318\n",
      "Loss: \n",
      "Training: 4.522675255256032e-06 Test: 4.5500093081839865e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.474792350903432e-06 Test: 4.56951237575141e-06\n",
      "Epoch: 319\n",
      "Loss: \n",
      "Training: 4.43463248315675e-06 Test: 4.338057654026929e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.458734226377927e-06 Test: 4.561367538412148e-06\n",
      "Epoch: 320\n",
      "Loss: \n",
      "Training: 4.477533962653236e-06 Test: 4.355126564816437e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4520060163808435e-06 Test: 4.54567284324717e-06\n",
      "Epoch: 321\n",
      "Loss: \n",
      "Training: 4.425438226687773e-06 Test: 4.78949759421275e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.456396301527794e-06 Test: 4.540260254857725e-06\n",
      "Epoch: 322\n",
      "Loss: \n",
      "Training: 4.357775439608399e-06 Test: 4.518347020385298e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.462607980058643e-06 Test: 4.5590861829039054e-06\n",
      "Epoch: 323\n",
      "Loss: \n",
      "Training: 4.528349681824142e-06 Test: 4.3186047178044e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.450457676984636e-06 Test: 4.542812347000945e-06\n",
      "Epoch: 324\n",
      "Loss: \n",
      "Training: 4.606183985073361e-06 Test: 4.532964266713265e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.462418330736572e-06 Test: 4.504007989219873e-06\n",
      "Epoch: 325\n",
      "Loss: \n",
      "Training: 4.461329944733702e-06 Test: 4.3916962410189024e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.474832324147403e-06 Test: 4.509381654509399e-06\n",
      "Epoch: 326\n",
      "Loss: \n",
      "Training: 4.5605869773854335e-06 Test: 4.5307454253079875e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.480742656166435e-06 Test: 4.4819099677441325e-06\n",
      "Epoch: 327\n",
      "Loss: \n",
      "Training: 4.4549714560004535e-06 Test: 4.252360204550332e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.490306394397905e-06 Test: 4.4826407015151665e-06\n",
      "Epoch: 328\n",
      "Loss: \n",
      "Training: 4.497800277042087e-06 Test: 4.735602972321457e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.482947741237928e-06 Test: 4.4577408997020285e-06\n",
      "Epoch: 329\n",
      "Loss: \n",
      "Training: 4.458494377197009e-06 Test: 4.464436132882361e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.480460243416534e-06 Test: 4.476300266115775e-06\n",
      "Epoch: 330\n",
      "Loss: \n",
      "Training: 4.368873323290776e-06 Test: 4.328159401995297e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.482846432820559e-06 Test: 4.488938114001318e-06\n",
      "Epoch: 331\n",
      "Loss: \n",
      "Training: 4.614972784696642e-06 Test: 4.47800320463487e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.471980368884313e-06 Test: 4.486241397719204e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 332\n",
      "Loss: \n",
      "Training: 4.454596688444413e-06 Test: 4.407482452138571e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4909338246852e-06 Test: 4.455091958761416e-06\n",
      "Epoch: 333\n",
      "Loss: \n",
      "Training: 4.426395905484487e-06 Test: 4.52884185566639e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.500615949568801e-06 Test: 4.444005501936744e-06\n",
      "Epoch: 334\n",
      "Loss: \n",
      "Training: 4.475771579788906e-06 Test: 4.531729528465707e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.490420571934837e-06 Test: 4.465029215722944e-06\n",
      "Epoch: 335\n",
      "Loss: \n",
      "Training: 4.4216568560203675e-06 Test: 4.592698131498449e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4773793314063905e-06 Test: 4.464905741898188e-06\n",
      "Epoch: 336\n",
      "Loss: \n",
      "Training: 4.4664430439117265e-06 Test: 4.5971729089747615e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.473412022535057e-06 Test: 4.485005930946143e-06\n",
      "Epoch: 337\n",
      "Loss: \n",
      "Training: 4.417591125487815e-06 Test: 4.53479137912031e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.463997629187686e-06 Test: 4.491648679312819e-06\n",
      "Epoch: 338\n",
      "Loss: \n",
      "Training: 4.360861057949362e-06 Test: 4.605829087445838e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.460259596136423e-06 Test: 4.5198917967698174e-06\n",
      "Epoch: 339\n",
      "Loss: \n",
      "Training: 4.526656954984952e-06 Test: 4.630437730305083e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.44656567422715e-06 Test: 4.506914408282256e-06\n",
      "Epoch: 340\n",
      "Loss: \n",
      "Training: 4.5147139298501926e-06 Test: 4.400787544739683e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.453381932005944e-06 Test: 4.523514568024528e-06\n",
      "Epoch: 341\n",
      "Loss: \n",
      "Training: 4.439831127102641e-06 Test: 4.475206489858928e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4679659926618865e-06 Test: 4.5307773822989656e-06\n",
      "Epoch: 342\n",
      "Loss: \n",
      "Training: 4.350613332748288e-06 Test: 4.4643183909798754e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.450451826902486e-06 Test: 4.5304977108213725e-06\n",
      "Epoch: 343\n",
      "Loss: \n",
      "Training: 4.542540215641122e-06 Test: 4.769179585945497e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.440053491332874e-06 Test: 4.536181304705504e-06\n",
      "Epoch: 344\n",
      "Loss: \n",
      "Training: 4.562695820186559e-06 Test: 4.3439917503110705e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.451667922348537e-06 Test: 4.560215077733413e-06\n",
      "Epoch: 345\n",
      "Loss: \n",
      "Training: 4.50234283633927e-06 Test: 4.609268988805734e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.460360346388302e-06 Test: 4.541441299917949e-06\n",
      "Epoch: 346\n",
      "Loss: \n",
      "Training: 4.446485345851429e-06 Test: 4.337009990465905e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.468428944420193e-06 Test: 4.5430983856486775e-06\n",
      "Epoch: 347\n",
      "Loss: \n",
      "Training: 4.483229115763898e-06 Test: 4.404498718279399e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.466433174614164e-06 Test: 4.517082093797791e-06\n",
      "Epoch: 348\n",
      "Loss: \n",
      "Training: 4.417127184314281e-06 Test: 4.571153515067965e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.472996973641772e-06 Test: 4.5040528277137005e-06\n",
      "Epoch: 349\n",
      "Loss: \n",
      "Training: 4.454380096343811e-06 Test: 4.359614634215221e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4786235862782634e-06 Test: 4.500585270475913e-06\n",
      "Epoch: 350\n",
      "Loss: \n",
      "Training: 4.628344714276149e-06 Test: 4.478500205994477e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.471395900414149e-06 Test: 4.473502960866927e-06\n",
      "Epoch: 351\n",
      "Loss: \n",
      "Training: 4.503774980592827e-06 Test: 4.58449994748251e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.482758978856745e-06 Test: 4.481274226992407e-06\n",
      "Epoch: 352\n",
      "Loss: \n",
      "Training: 4.438577183515914e-06 Test: 4.398738346456019e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.489153364205764e-06 Test: 4.4922035727547654e-06\n",
      "Epoch: 353\n",
      "Loss: \n",
      "Training: 4.4034020732177995e-06 Test: 4.569113701013843e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.497949749282527e-06 Test: 4.48564556830238e-06\n",
      "Epoch: 354\n",
      "Loss: \n",
      "Training: 4.4673973007940635e-06 Test: 4.642354553812656e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.484035935040194e-06 Test: 4.465638979809215e-06\n",
      "Epoch: 355\n",
      "Loss: \n",
      "Training: 4.422690426397503e-06 Test: 4.418836149340539e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.474506083100944e-06 Test: 4.495475260159373e-06\n",
      "Epoch: 356\n",
      "Loss: \n",
      "Training: 4.4237398807650075e-06 Test: 4.391994205752823e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.466540842106768e-06 Test: 4.4764319762128534e-06\n",
      "Epoch: 357\n",
      "Loss: \n",
      "Training: 4.458002227789781e-06 Test: 4.53908262355122e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4642662955981255e-06 Test: 4.481930397741545e-06\n",
      "Epoch: 358\n",
      "Loss: \n",
      "Training: 4.667868014086467e-06 Test: 4.259922673903968e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.461743606800714e-06 Test: 4.495388788268728e-06\n",
      "Epoch: 359\n",
      "Loss: \n",
      "Training: 4.418182339244417e-06 Test: 4.493230917321416e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.486817689777932e-06 Test: 4.464265704152328e-06\n",
      "Epoch: 360\n",
      "Loss: \n",
      "Training: 4.431934482925703e-06 Test: 4.353644997416499e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4831979140679926e-06 Test: 4.477627332462947e-06\n",
      "Epoch: 361\n",
      "Loss: \n",
      "Training: 4.4762471840889966e-06 Test: 4.399942574130085e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.463556890932948e-06 Test: 4.465141811605149e-06\n",
      "Epoch: 362\n",
      "Loss: \n",
      "Training: 4.43261540300317e-06 Test: 4.539251513836436e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.460804111282565e-06 Test: 4.4466860742699064e-06\n",
      "Epoch: 363\n",
      "Loss: \n",
      "Training: 4.428812219970302e-06 Test: 4.365541513470416e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.460207933231291e-06 Test: 4.460737391007948e-06\n",
      "Epoch: 364\n",
      "Loss: \n",
      "Training: 4.787056492007514e-06 Test: 4.57360629490551e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4627489479065415e-06 Test: 4.440380172253605e-06\n",
      "Epoch: 365\n",
      "Loss: \n",
      "Training: 4.455263809082888e-06 Test: 4.397489564814236e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.494714867027886e-06 Test: 4.433505346362891e-06\n",
      "Epoch: 366\n",
      "Loss: \n",
      "Training: 4.342421656677247e-06 Test: 4.435437341814038e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.497972205296424e-06 Test: 4.431370687910261e-06\n",
      "Epoch: 367\n",
      "Loss: \n",
      "Training: 4.52243504800692e-06 Test: 4.360638480135522e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.489840382887647e-06 Test: 4.435715001516382e-06\n",
      "Epoch: 368\n",
      "Loss: \n",
      "Training: 4.411930311005421e-06 Test: 4.320455619249703e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.496283664909362e-06 Test: 4.417870587174813e-06\n",
      "Epoch: 369\n",
      "Loss: \n",
      "Training: 4.45408066709847e-06 Test: 4.409030164872047e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.470689894601257e-06 Test: 4.4239238817093865e-06\n",
      "Epoch: 370\n",
      "Loss: \n",
      "Training: 4.46703357421036e-06 Test: 4.38863968569809e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.474279727386663e-06 Test: 4.41550380646445e-06\n",
      "Epoch: 371\n",
      "Loss: \n",
      "Training: 4.490243619798949e-06 Test: 4.379304295669177e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.477789636515129e-06 Test: 4.419003275292609e-06\n",
      "Epoch: 372\n",
      "Loss: \n",
      "Training: 4.515531944861919e-06 Test: 4.598074397959128e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.479189280086124e-06 Test: 4.416939447446517e-06\n",
      "Epoch: 373\n",
      "Loss: \n",
      "Training: 4.521726983153683e-06 Test: 4.346598571905858e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.487480934271999e-06 Test: 4.422821735858786e-06\n",
      "Epoch: 374\n",
      "Loss: \n",
      "Training: 4.351715490304935e-06 Test: 4.498770665208421e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.496772410590337e-06 Test: 4.42092744170233e-06\n",
      "Epoch: 375\n",
      "Loss: \n",
      "Training: 4.421373821804675e-06 Test: 4.580626635880923e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4532383104200795e-06 Test: 4.413443878732621e-06\n",
      "Epoch: 376\n",
      "Loss: \n",
      "Training: 4.389357606362375e-06 Test: 4.659188873608303e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.449849311692257e-06 Test: 4.4317575858392905e-06\n",
      "Epoch: 377\n",
      "Loss: \n",
      "Training: 4.422102029032959e-06 Test: 4.480832201844975e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.45454290666077e-06 Test: 4.4541327390187174e-06\n",
      "Epoch: 378\n",
      "Loss: \n",
      "Training: 4.322301370503376e-06 Test: 4.286888354189058e-06\n",
      "Rolling mean of Loss (Window is 10): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 4.444509604763375e-06 Test: 4.4661521111896635e-06\n",
      "Epoch: 379\n",
      "Loss: \n",
      "Training: 4.312363992079413e-06 Test: 4.3976044447145024e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.435546710713171e-06 Test: 4.462795384683598e-06\n",
      "Epoch: 380\n",
      "Loss: \n",
      "Training: 4.482060931005545e-06 Test: 4.525689782137347e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.421375043211265e-06 Test: 4.4616528126678435e-06\n",
      "Epoch: 381\n",
      "Loss: \n",
      "Training: 4.575146196756933e-06 Test: 4.665363194057665e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.422877778890783e-06 Test: 4.475357822311768e-06\n",
      "Epoch: 382\n",
      "Loss: \n",
      "Training: 4.429198456854585e-06 Test: 4.5611643167913916e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4313680365865815e-06 Test: 4.503963712150618e-06\n",
      "Epoch: 383\n",
      "Loss: \n",
      "Training: 4.424742795407421e-06 Test: 4.541942997616158e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.422734687785848e-06 Test: 4.500272704033844e-06\n",
      "Epoch: 384\n",
      "Loss: \n",
      "Training: 4.494342138303776e-06 Test: 4.42801917037178e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.413036269011222e-06 Test: 4.5198071466048745e-06\n",
      "Epoch: 385\n",
      "Loss: \n",
      "Training: 4.438234385508439e-06 Test: 4.636484258497085e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.427298933811106e-06 Test: 4.51273199712121e-06\n",
      "Epoch: 386\n",
      "Loss: \n",
      "Training: 4.569359837754658e-06 Test: 4.488527838965605e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.428984990181482e-06 Test: 4.518317759382827e-06\n",
      "Epoch: 387\n",
      "Loss: \n",
      "Training: 4.384510997274784e-06 Test: 4.556814277465003e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.44698521332071e-06 Test: 4.5012516559185565e-06\n",
      "Epoch: 388\n",
      "Loss: \n",
      "Training: 4.294981840662729e-06 Test: 4.7359757972623695e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.443226110144893e-06 Test: 4.508849863480559e-06\n",
      "Epoch: 389\n",
      "Loss: \n",
      "Training: 4.588631415882883e-06 Test: 4.616658292963644e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.440494157160829e-06 Test: 4.55375860778789e-06\n",
      "Epoch: 390\n",
      "Loss: \n",
      "Training: 4.379539095538648e-06 Test: 4.458369927470163e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4681208995411754e-06 Test: 4.5756639926128045e-06\n",
      "Epoch: 391\n",
      "Loss: \n",
      "Training: 4.42985544222303e-06 Test: 4.313291880049538e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4578687159944855e-06 Test: 4.568932007146087e-06\n",
      "Epoch: 392\n",
      "Loss: \n",
      "Training: 4.484360921486298e-06 Test: 4.360239919819755e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.443339640541095e-06 Test: 4.533724875745274e-06\n",
      "Epoch: 393\n",
      "Loss: \n",
      "Training: 4.424346795161552e-06 Test: 4.779347891328791e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.448855887004267e-06 Test: 4.51363243604811e-06\n",
      "Epoch: 394\n",
      "Loss: \n",
      "Training: 4.3444272524697836e-06 Test: 4.601021856213132e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.448816286979681e-06 Test: 4.5373729254193735e-06\n",
      "Epoch: 395\n",
      "Loss: \n",
      "Training: 4.396751557754036e-06 Test: 4.475085465842249e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.43382479839628e-06 Test: 4.554673194003509e-06\n",
      "Epoch: 396\n",
      "Loss: \n",
      "Training: 4.5174376610902855e-06 Test: 4.439080874586393e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.42967651562084e-06 Test: 4.538533314738025e-06\n",
      "Epoch: 397\n",
      "Loss: \n",
      "Training: 4.387920891055896e-06 Test: 4.445736370470912e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.424484297954403e-06 Test: 4.533588618300105e-06\n",
      "Epoch: 398\n",
      "Loss: \n",
      "Training: 4.495674107042482e-06 Test: 4.426751687751749e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.424825287332514e-06 Test: 4.522480827600696e-06\n",
      "Epoch: 399\n",
      "Loss: \n",
      "Training: 4.366267665823825e-06 Test: 4.375428201080894e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.444894513970489e-06 Test: 4.491558416649634e-06\n",
      "Epoch: 400\n",
      "Loss: \n",
      "Training: 4.3746164761137485e-06 Test: 4.847199095759092e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.422658138964583e-06 Test: 4.4674354074613585e-06\n",
      "Epoch: 401\n",
      "Loss: \n",
      "Training: 4.53834685374191e-06 Test: 4.702541880225945e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4221658770220936e-06 Test: 4.506318324290251e-06\n",
      "Epoch: 402\n",
      "Loss: \n",
      "Training: 4.524332284012403e-06 Test: 4.4695878716035585e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.433015018173982e-06 Test: 4.5452433243078915e-06\n",
      "Epoch: 403\n",
      "Loss: \n",
      "Training: 4.6620089701620685e-06 Test: 4.419348322632011e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.437012154426593e-06 Test: 4.556178119486271e-06\n",
      "Epoch: 404\n",
      "Loss: \n",
      "Training: 4.767630906061787e-06 Test: 4.599774456274907e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.460778371926644e-06 Test: 4.520178162616593e-06\n",
      "Epoch: 405\n",
      "Loss: \n",
      "Training: 4.532264344208654e-06 Test: 4.4451435198794735e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.503098737285843e-06 Test: 4.52005342262277e-06\n",
      "Epoch: 406\n",
      "Loss: \n",
      "Training: 4.468988936014641e-06 Test: 4.549144867970348e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.516650015931306e-06 Test: 4.517059228026494e-06\n",
      "Epoch: 407\n",
      "Loss: \n",
      "Training: 4.405691586284604e-06 Test: 4.318169512461863e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.511805143423741e-06 Test: 4.528065627364889e-06\n",
      "Epoch: 408\n",
      "Loss: \n",
      "Training: 4.367355764503203e-06 Test: 4.44497931465551e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.513582212946612e-06 Test: 4.515308941563984e-06\n",
      "Epoch: 409\n",
      "Loss: \n",
      "Training: 4.571507547495397e-06 Test: 4.7015199245685095e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.5007503786926844e-06 Test: 4.517131704254361e-06\n",
      "Epoch: 410\n",
      "Loss: \n",
      "Training: 4.489318351610043e-06 Test: 4.3723614056935475e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.5212743668598416e-06 Test: 4.549740876603122e-06\n",
      "Epoch: 411\n",
      "Loss: \n",
      "Training: 4.566006168620554e-06 Test: 4.616924410279073e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.532744554409471e-06 Test: 4.502257107596568e-06\n",
      "Epoch: 412\n",
      "Loss: \n",
      "Training: 4.355304905968512e-06 Test: 4.617094701898676e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.535510485897336e-06 Test: 4.49369536060188e-06\n",
      "Epoch: 413\n",
      "Loss: \n",
      "Training: 4.361279983369652e-06 Test: 4.345546885255867e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.518607748092947e-06 Test: 4.508446043631391e-06\n",
      "Epoch: 414\n",
      "Loss: \n",
      "Training: 4.506002387443186e-06 Test: 4.392247734344978e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4885348494137044e-06 Test: 4.5010658998937765e-06\n",
      "Epoch: 415\n",
      "Loss: \n",
      "Training: 4.3729754985479026e-06 Test: 4.361489960177275e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.462371997551845e-06 Test: 4.480313227700783e-06\n",
      "Epoch: 416\n",
      "Loss: \n",
      "Training: 4.5285343708502244e-06 Test: 4.35557337740505e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.446443112985769e-06 Test: 4.471947871730564e-06\n",
      "Epoch: 417\n",
      "Loss: \n",
      "Training: 4.5361342872416365e-06 Test: 4.566726424383501e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.452397656469328e-06 Test: 4.452590722674035e-06\n",
      "Epoch: 418\n",
      "Loss: \n",
      "Training: 4.42811368840707e-06 Test: 4.5302314169267e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4654419265650314e-06 Test: 4.477446413866199e-06\n",
      "Epoch: 419\n",
      "Loss: \n",
      "Training: 4.41969920137175e-06 Test: 4.6059626192014325e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.471517718955417e-06 Test: 4.485971624093318e-06\n",
      "Epoch: 420\n",
      "Loss: \n",
      "Training: 4.657188943394882e-06 Test: 4.315586962616873e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.456336884343053e-06 Test: 4.47641589355661e-06\n",
      "Epoch: 421\n",
      "Loss: \n",
      "Training: 4.6344684125181026e-06 Test: 4.465580113032827e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4731239435215365e-06 Test: 4.470738449248942e-06\n",
      "Epoch: 422\n",
      "Loss: \n",
      "Training: 4.423112394477141e-06 Test: 4.547981738521944e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.479970167911291e-06 Test: 4.455604019524317e-06\n",
      "Epoch: 423\n",
      "Loss: \n",
      "Training: 4.784039791870175e-06 Test: 4.375648653282994e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.486750916762154e-06 Test: 4.448692723186645e-06\n",
      "Epoch: 424\n",
      "Loss: \n",
      "Training: 4.465803962578925e-06 Test: 4.331052883185129e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.529026897612208e-06 Test: 4.451702899989357e-06\n",
      "Epoch: 425\n",
      "Loss: \n",
      "Training: 4.607578969755586e-06 Test: 4.549299147041452e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.525007055125781e-06 Test: 4.445583414873372e-06\n",
      "Epoch: 426\n",
      "Loss: \n",
      "Training: 4.4929651995293936e-06 Test: 4.375413944541588e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.548467402246549e-06 Test: 4.464364333559791e-06\n",
      "Epoch: 427\n",
      "Loss: \n",
      "Training: 4.576660071777799e-06 Test: 4.797965469653356e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.5449104851144665e-06 Test: 4.466348390273444e-06\n",
      "Epoch: 428\n",
      "Loss: \n",
      "Training: 4.428517109999496e-06 Test: 4.316687987480685e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.5489630635680825e-06 Test: 4.48947229480043e-06\n",
      "Epoch: 429\n",
      "Loss: \n",
      "Training: 4.382164450689988e-06 Test: 4.424449938135542e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.549003405727325e-06 Test: 4.468117951855828e-06\n",
      "Epoch: 430\n",
      "Loss: \n",
      "Training: 4.480475793349168e-06 Test: 4.489664170337558e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.545249930659149e-06 Test: 4.449966683749239e-06\n",
      "Epoch: 431\n",
      "Loss: \n",
      "Training: 4.449985085927882e-06 Test: 4.491530562791711e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.5275786156545774e-06 Test: 4.467374404521307e-06\n",
      "Epoch: 432\n",
      "Loss: \n",
      "Training: 4.404815068655861e-06 Test: 4.532496490522282e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.509130282995555e-06 Test: 4.4699694494971965e-06\n",
      "Epoch: 433\n",
      "Loss: \n",
      "Training: 4.690362041546571e-06 Test: 4.351627069083414e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.507300550413427e-06 Test: 4.4684209246972305e-06\n",
      "Epoch: 434\n",
      "Loss: \n",
      "Training: 4.61922677960392e-06 Test: 4.651899610488089e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.497932775381067e-06 Test: 4.466018766277272e-06\n",
      "Epoch: 435\n",
      "Loss: \n",
      "Training: 4.440196704013365e-06 Test: 4.3557658869672794e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.513275057083566e-06 Test: 4.498103439007567e-06\n",
      "Epoch: 436\n",
      "Loss: \n",
      "Training: 4.5264280643698406e-06 Test: 4.5946382698062685e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.496536830509344e-06 Test: 4.47875011300015e-06\n",
      "Epoch: 437\n",
      "Loss: \n",
      "Training: 4.376575550401457e-06 Test: 4.6609729598592435e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.499883116993389e-06 Test: 4.500672545526618e-06\n",
      "Epoch: 438\n",
      "Loss: \n",
      "Training: 4.437515744519637e-06 Test: 4.540196758224157e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.479874664855755e-06 Test: 4.486973294547207e-06\n",
      "Epoch: 439\n",
      "Loss: \n",
      "Training: 4.529613234398293e-06 Test: 4.350628147805111e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.480774528307769e-06 Test: 4.509324171621555e-06\n",
      "Epoch: 440\n",
      "Loss: \n",
      "Training: 4.368494749359283e-06 Test: 4.511484320846761e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.495519406678599e-06 Test: 4.501941992588511e-06\n",
      "Epoch: 441\n",
      "Loss: \n",
      "Training: 4.445075882603451e-06 Test: 4.513422411516575e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.48432130227961e-06 Test: 4.504124007639431e-06\n",
      "Epoch: 442\n",
      "Loss: \n",
      "Training: 4.419645967863326e-06 Test: 4.376448527574818e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.483830381947167e-06 Test: 4.506313192511917e-06\n",
      "Epoch: 443\n",
      "Loss: \n",
      "Training: 4.413191825895344e-06 Test: 4.465800481090958e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.485313471867914e-06 Test: 4.49070839621717e-06\n",
      "Epoch: 444\n",
      "Loss: \n",
      "Training: 4.431804593915953e-06 Test: 4.482497418334493e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.457596450302792e-06 Test: 4.5021257374179245e-06\n",
      "Epoch: 445\n",
      "Loss: \n",
      "Training: 4.4442846062595176e-06 Test: 4.49286692718584e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.438854231733995e-06 Test: 4.485185518202566e-06\n",
      "Epoch: 446\n",
      "Loss: \n",
      "Training: 4.46614904931311e-06 Test: 4.430029581528557e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4392630219586105e-06 Test: 4.498895622224422e-06\n",
      "Epoch: 447\n",
      "Loss: \n",
      "Training: 4.395835791859146e-06 Test: 4.365645553521371e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.433235120452937e-06 Test: 4.482434753396651e-06\n",
      "Epoch: 448\n",
      "Loss: \n",
      "Training: 4.520320050571738e-06 Test: 4.46675382102021e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.435161144598706e-06 Test: 4.452902012762864e-06\n",
      "Epoch: 449\n",
      "Loss: \n",
      "Training: 4.5077486903388745e-06 Test: 4.466257744613931e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.443441575203916e-06 Test: 4.445557719042469e-06\n",
      "Epoch: 450\n",
      "Loss: \n",
      "Training: 4.561491172979419e-06 Test: 4.466725106783378e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.441255120797974e-06 Test: 4.457120678723351e-06\n",
      "Epoch: 451\n",
      "Loss: \n",
      "Training: 4.496236936503506e-06 Test: 4.3629235757024375e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.460554763159987e-06 Test: 4.452644757317012e-06\n",
      "Epoch: 452\n",
      "Loss: \n",
      "Training: 4.515732829738717e-06 Test: 4.708699025637208e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.465670868549993e-06 Test: 4.437594873735598e-06\n",
      "Epoch: 453\n",
      "Loss: \n",
      "Training: 4.505445468655436e-06 Test: 4.611901837435321e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.475279554737532e-06 Test: 4.4708199235418385e-06\n",
      "Epoch: 454\n",
      "Loss: \n",
      "Training: 4.377777651348599e-06 Test: 4.586058434196325e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.484504919013542e-06 Test: 4.4854300591762745e-06\n",
      "Epoch: 455\n",
      "Loss: \n",
      "Training: 4.517238743848747e-06 Test: 4.560740826304284e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.479102224756807e-06 Test: 4.4957861607624575e-06\n",
      "Epoch: 456\n",
      "Loss: \n",
      "Training: 4.6326871007944855e-06 Test: 4.536399007801692e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.486397638515729e-06 Test: 4.5025735506743025e-06\n",
      "Epoch: 457\n",
      "Loss: \n",
      "Training: 4.423070490952312e-06 Test: 4.525647712330249e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.503051443663867e-06 Test: 4.513210493301616e-06\n",
      "Epoch: 458\n",
      "Loss: \n",
      "Training: 4.522117831885618e-06 Test: 4.436778212215591e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.505774913573183e-06 Test: 4.529210709182504e-06\n",
      "Epoch: 459\n",
      "Loss: \n",
      "Training: 4.534227481252593e-06 Test: 4.59458814662939e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.505954691704571e-06 Test: 4.526213148302042e-06\n",
      "Epoch: 460\n",
      "Loss: \n",
      "Training: 4.502465766706787e-06 Test: 4.379131585277558e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.508602570795943e-06 Test: 4.539046188503588e-06\n",
      "Epoch: 461\n",
      "Loss: \n",
      "Training: 4.671147170675148e-06 Test: 4.565304220394154e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.50270003016868e-06 Test: 4.530286836353006e-06\n",
      "Epoch: 462\n",
      "Loss: \n",
      "Training: 4.600563685565285e-06 Test: 4.599228541415882e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.5201910535858435e-06 Test: 4.550524900822178e-06\n",
      "Epoch: 463\n",
      "Loss: \n",
      "Training: 4.6128509925262815e-06 Test: 4.602584985327875e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.5286741391685e-06 Test: 4.539577852400045e-06\n",
      "Epoch: 464\n",
      "Loss: \n",
      "Training: 4.47416394083398e-06 Test: 4.542140163524174e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.539414691555585e-06 Test: 4.5386461671892995e-06\n",
      "Epoch: 465\n",
      "Loss: \n",
      "Training: 4.4546389408089655e-06 Test: 4.444989402301253e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.549053320504124e-06 Test: 4.5342543401220845e-06\n",
      "Epoch: 466\n",
      "Loss: \n",
      "Training: 4.42138066671598e-06 Test: 4.602277458067016e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.542793340200146e-06 Test: 4.522679197721781e-06\n",
      "Epoch: 467\n",
      "Loss: \n",
      "Training: 4.392110939693451e-06 Test: 4.745321112455539e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.521662696792295e-06 Test: 4.5292670427483134e-06\n",
      "Epoch: 468\n",
      "Loss: \n",
      "Training: 4.644656052162638e-06 Test: 4.745013585050565e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.51856674166641e-06 Test: 4.551234382760842e-06\n",
      "Epoch: 469\n",
      "Loss: \n",
      "Training: 4.5161970995503146e-06 Test: 4.46648603618405e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.530820563694111e-06 Test: 4.58205792004434e-06\n",
      "Epoch: 470\n",
      "Loss: \n",
      "Training: 4.401997070892404e-06 Test: 4.419917845626506e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.529017525523883e-06 Test: 4.569247708999807e-06\n",
      "Epoch: 471\n",
      "Loss: \n",
      "Training: 4.530461266954956e-06 Test: 4.449070064060418e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.518970655942445e-06 Test: 4.573326335034702e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 472\n",
      "Loss: \n",
      "Training: 4.407106743357731e-06 Test: 4.489131104820749e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.504902065570425e-06 Test: 4.5617029194013284e-06\n",
      "Epoch: 473\n",
      "Loss: \n",
      "Training: 4.6305691218076615e-06 Test: 4.713439200140321e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4855563713496706e-06 Test: 4.550693175741815e-06\n",
      "Epoch: 474\n",
      "Loss: \n",
      "Training: 4.486319738399212e-06 Test: 4.542962826433621e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.487328184277807e-06 Test: 4.561778597223059e-06\n",
      "Epoch: 475\n",
      "Loss: \n",
      "Training: 1.3915040602204326e-05 Test: 4.5656719589632995e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.488543764034331e-06 Test: 4.5618608635140045e-06\n",
      "Epoch: 476\n",
      "Loss: \n",
      "Training: 4.505405920800677e-06 Test: 4.682242861313365e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.4345839301738675e-06 Test: 4.573929119180209e-06\n",
      "Epoch: 477\n",
      "Loss: \n",
      "Training: 4.587734722159833e-06 Test: 4.555811543617841e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.442986455582337e-06 Test: 4.581925659504844e-06\n",
      "Epoch: 478\n",
      "Loss: \n",
      "Training: 4.794148771339086e-06 Test: 4.598470611491615e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.462548833828975e-06 Test: 4.562974702621074e-06\n",
      "Epoch: 479\n",
      "Loss: \n",
      "Training: 4.5992904506780135e-06 Test: 4.60062729019015e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.477498105746621e-06 Test: 4.5483204052651784e-06\n",
      "Epoch: 480\n",
      "Loss: \n",
      "Training: 4.418290042914231e-06 Test: 4.706875693727903e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.48580744085939e-06 Test: 4.561734530665789e-06\n",
      "Epoch: 481\n",
      "Loss: \n",
      "Training: 4.62111954250702e-06 Test: 4.441878543412904e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.487436738061573e-06 Test: 4.590430315475928e-06\n",
      "Epoch: 482\n",
      "Loss: \n",
      "Training: 4.584882289411227e-06 Test: 1.53426203225909e-05\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.49650256561678e-06 Test: 4.589711163411178e-06\n",
      "Epoch: 483\n",
      "Loss: \n",
      "Training: 4.629939504256628e-06 Test: 4.762854864565826e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.514280120222129e-06 Test: 5.675060085188193e-06\n",
      "Epoch: 484\n",
      "Loss: \n",
      "Training: 4.605624170984738e-06 Test: 4.697908142783006e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.5142171584670254e-06 Test: 5.680001651630742e-06\n",
      "Epoch: 485\n",
      "Loss: \n",
      "Training: 4.581250353570882e-06 Test: 4.73541064325504e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.526147601725579e-06 Test: 5.6954961832656805e-06\n",
      "Epoch: 486\n",
      "Loss: \n",
      "Training: 4.885455769599556e-06 Test: 4.528512466927224e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.5927685768622345e-06 Test: 5.712470051694855e-06\n",
      "Epoch: 487\n",
      "Loss: \n",
      "Training: 8.434408705784693e-06 Test: 4.8433560607202375e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.630773561742121e-06 Test: 5.697097012256241e-06\n",
      "Epoch: 488\n",
      "Loss: \n",
      "Training: 4.931185063954411e-06 Test: 4.851145508339804e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.0154409601046075e-06 Test: 5.725851463966481e-06\n",
      "Epoch: 489\n",
      "Loss: \n",
      "Training: 4.918151417576406e-06 Test: 4.308063896664698e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.02914458936614e-06 Test: 5.751118953651299e-06\n",
      "Epoch: 490\n",
      "Loss: \n",
      "Training: 4.6262076994858004e-06 Test: 4.90483740394112e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.061030686055979e-06 Test: 5.721862614298754e-06\n",
      "Epoch: 491\n",
      "Loss: \n",
      "Training: 1.2249473324137982e-05 Test: 4.525222673495407e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.081822451713135e-06 Test: 5.741658785320076e-06\n",
      "Epoch: 492\n",
      "Loss: \n",
      "Training: 4.691970295309086e-06 Test: 4.627630592809887e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.844657829876231e-06 Test: 5.749993198328326e-06\n",
      "Epoch: 493\n",
      "Loss: \n",
      "Training: 4.476948346689738e-06 Test: 4.603380470589922e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.855366630466018e-06 Test: 4.678494225350224e-06\n",
      "Epoch: 494\n",
      "Loss: \n",
      "Training: 8.13451319892544e-06 Test: 4.41378298215523e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.840067514709329e-06 Test: 4.662546785952635e-06\n",
      "Epoch: 495\n",
      "Loss: \n",
      "Training: 4.3391963084982735e-06 Test: 4.455032945553783e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.1929564175034014e-06 Test: 4.634134269889856e-06\n",
      "Epoch: 496\n",
      "Loss: \n",
      "Training: 4.657577589308431e-06 Test: 4.379815272502206e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.168751012996139e-06 Test: 4.606096500119731e-06\n",
      "Epoch: 497\n",
      "Loss: \n",
      "Training: 4.596688918771097e-06 Test: 4.635203443920799e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.145963194967027e-06 Test: 4.5912267806772294e-06\n",
      "Epoch: 498\n",
      "Loss: \n",
      "Training: 4.451105058913299e-06 Test: 4.763344834157283e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.762191216265667e-06 Test: 4.5704115189972855e-06\n",
      "Epoch: 499\n",
      "Loss: \n",
      "Training: 6.9816213341726176e-06 Test: 4.507295498420731e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.7141832157615555e-06 Test: 4.561631451579034e-06\n",
      "Epoch: 500\n",
      "Loss: \n",
      "Training: 4.4589919308268746e-06 Test: 4.490867287505209e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.9205302074211764e-06 Test: 4.581554611754638e-06\n",
      "Epoch: 501\n",
      "Loss: \n",
      "Training: 4.381153811965299e-06 Test: 4.651958723234343e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.903808630555284e-06 Test: 4.540157600111046e-06\n",
      "Epoch: 502\n",
      "Loss: \n",
      "Training: 4.627486018771656e-06 Test: 4.675674195341061e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.116976679338016e-06 Test: 4.55283120508494e-06\n",
      "Epoch: 503\n",
      "Loss: \n",
      "Training: 4.471026802786579e-06 Test: 4.6609659372145e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.110528251684273e-06 Test: 4.557635565338057e-06\n",
      "Epoch: 504\n",
      "Loss: \n",
      "Training: 4.385245376672063e-06 Test: 4.660041844578361e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.109936097293957e-06 Test: 4.563394112000514e-06\n",
      "Epoch: 505\n",
      "Loss: \n",
      "Training: 4.468259427618676e-06 Test: 4.692573258125032e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.735009315068619e-06 Test: 4.588019998242827e-06\n",
      "Epoch: 506\n",
      "Loss: \n",
      "Training: 4.434687460935626e-06 Test: 4.318625841843032e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.74791562698066e-06 Test: 4.611774029499952e-06\n",
      "Epoch: 507\n",
      "Loss: \n",
      "Training: 4.3367986434221485e-06 Test: 4.615907989571155e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.7256266141433784e-06 Test: 4.605655086434035e-06\n",
      "Epoch: 508\n",
      "Loss: \n",
      "Training: 4.37366196173133e-06 Test: 4.4200286444896445e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.699637586608484e-06 Test: 4.603725540999071e-06\n",
      "Epoch: 509\n",
      "Loss: \n",
      "Training: 4.523315572936263e-06 Test: 4.644892798427282e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.691893276890287e-06 Test: 4.569393922032307e-06\n",
      "Epoch: 510\n",
      "Loss: \n",
      "Training: 4.317626263938949e-06 Test: 4.372378958904971e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.446062700766651e-06 Test: 4.583153652032961e-06\n",
      "Epoch: 511\n",
      "Loss: \n",
      "Training: 4.27695467881158e-06 Test: 4.384375991753889e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.4319261340778584e-06 Test: 4.571304819172937e-06\n",
      "Epoch: 512\n",
      "Loss: \n",
      "Training: 4.44048330854307e-06 Test: 4.5427927444141465e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.421506220762487e-06 Test: 4.544546546024893e-06\n",
      "Epoch: 513\n",
      "Loss: \n",
      "Training: 4.281027153925883e-06 Test: 4.274368329495543e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.402805949739629e-06 Test: 4.531258400932202e-06\n",
      "Epoch: 514\n",
      "Loss: \n",
      "Training: 4.470297207390645e-06 Test: 4.23164137540912e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.3838059848535585e-06 Test: 4.492598640160305e-06\n",
      "Best params are updated.\n",
      "Epoch: 515\n",
      "Loss: \n",
      "Training: 4.1732077446008905e-06 Test: 4.4110304316764386e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.392311167925417e-06 Test: 4.4497585932433816e-06\n",
      "Best params are updated.\n",
      "Epoch: 516\n",
      "Loss: \n",
      "Training: 4.095783485074252e-06 Test: 4.435671685991835e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.362805999623638e-06 Test: 4.421604310598523e-06\n",
      "Epoch: 517\n",
      "Loss: \n",
      "Training: 4.177597780677476e-06 Test: 4.264413648969385e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.328915602037501e-06 Test: 4.433308895013403e-06\n",
      "Epoch: 518\n",
      "Loss: \n",
      "Training: 4.145563138423203e-06 Test: 4.391060402320181e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.312995515763033e-06 Test: 4.398159460953226e-06\n",
      "Epoch: 519\n",
      "Loss: \n",
      "Training: 4.133939767507285e-06 Test: 4.067381611449535e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.2901856334322205e-06 Test: 4.395262636736279e-06\n",
      "Epoch: 520\n",
      "Loss: \n",
      "Training: 4.155955613817966e-06 Test: 4.362747320805625e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.251248052889323e-06 Test: 4.3375115180385045e-06\n",
      "Best params are updated.\n",
      "Epoch: 521\n",
      "Loss: \n",
      "Training: 4.06007176006633e-06 Test: 4.026920497353419e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.235080987877225e-06 Test: 4.33654835422857e-06\n",
      "Epoch: 522\n",
      "Loss: \n",
      "Training: 4.106739089590377e-06 Test: 4.365498976781278e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.2133926960026994e-06 Test: 4.3008028047885224e-06\n",
      "Epoch: 523\n",
      "Loss: \n",
      "Training: 4.067873788559539e-06 Test: 4.003479722963681e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.180018274107431e-06 Test: 4.283073428025236e-06\n",
      "Best params are updated.\n",
      "Epoch: 524\n",
      "Loss: \n",
      "Training: 3.948506080735244e-06 Test: 3.948809378897107e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.1587029375707965e-06 Test: 4.255984567372049e-06\n",
      "Epoch: 525\n",
      "Loss: \n",
      "Training: 3.992295387610104e-06 Test: 3.989066272972692e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.106523824905256e-06 Test: 4.2277013677208485e-06\n",
      "Epoch: 526\n",
      "Loss: \n",
      "Training: 4.018895675957548e-06 Test: 4.293363608063326e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.088432589206177e-06 Test: 4.1855049518504734e-06\n",
      "Epoch: 527\n",
      "Loss: \n",
      "Training: 3.966262852850803e-06 Test: 3.913892889869632e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.080743808294507e-06 Test: 4.171274144057622e-06\n",
      "Best params are updated.\n",
      "Epoch: 528\n",
      "Loss: \n",
      "Training: 3.869539198341569e-06 Test: 3.876947372561276e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.0596103155118395e-06 Test: 4.1362220681476475e-06\n",
      "Best params are updated.\n",
      "Epoch: 529\n",
      "Loss: \n",
      "Training: 3.869004640063277e-06 Test: 3.829797975170174e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.032007921503676e-06 Test: 4.0848107651717565e-06\n",
      "Best params are updated.\n",
      "Epoch: 530\n",
      "Loss: \n",
      "Training: 3.821703626098192e-06 Test: 3.8153923035600045e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.005514408759275e-06 Test: 4.06105240154382e-06\n",
      "Epoch: 531\n",
      "Loss: \n",
      "Training: 3.824408846433304e-06 Test: 3.858638481329887e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.972089209987298e-06 Test: 4.006316899819258e-06\n",
      "Epoch: 532\n",
      "Loss: \n",
      "Training: 3.88390909293779e-06 Test: 3.852324489511852e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.9485229186239955e-06 Test: 3.989488698216906e-06\n",
      "Best params are updated.\n",
      "Epoch: 533\n",
      "Loss: \n",
      "Training: 3.6867807746322435e-06 Test: 3.842396820803985e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.926239918958737e-06 Test: 3.938171249489963e-06\n",
      "Epoch: 534\n",
      "Loss: \n",
      "Training: 3.829709164662485e-06 Test: 3.87977702715083e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.8881306175660066e-06 Test: 3.922062959273993e-06\n",
      "Best params are updated.\n",
      "Epoch: 535\n",
      "Loss: \n",
      "Training: 3.676601614888184e-06 Test: 4.094283503004462e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.876250925958731e-06 Test: 3.915159724099365e-06\n",
      "Epoch: 536\n",
      "Loss: \n",
      "Training: 3.7193575017658845e-06 Test: 3.8898642481519515e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.84468154868654e-06 Test: 3.925681447102542e-06\n",
      "Epoch: 537\n",
      "Loss: \n",
      "Training: 3.7529683482757514e-06 Test: 3.6590320250307783e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.8147277312673736e-06 Test: 3.885331511111405e-06\n",
      "Epoch: 538\n",
      "Loss: \n",
      "Training: 3.77899175915452e-06 Test: 3.840607939199299e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.793398280809868e-06 Test: 3.85984542462752e-06\n",
      "Epoch: 539\n",
      "Loss: \n",
      "Training: 3.677588728906923e-06 Test: 3.888547070513745e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.784343536891163e-06 Test: 3.856211481291322e-06\n",
      "Best params are updated.\n",
      "Epoch: 540\n",
      "Loss: \n",
      "Training: 3.6370717138749563e-06 Test: 3.658069398725021e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.765201945775528e-06 Test: 3.862086390825679e-06\n",
      "Best params are updated.\n",
      "Epoch: 541\n",
      "Loss: \n",
      "Training: 3.5141787030409906e-06 Test: 3.829628239646192e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.7467387545532042e-06 Test: 3.84635410034218e-06\n",
      "Epoch: 542\n",
      "Loss: \n",
      "Training: 3.6218681614718355e-06 Test: 3.534186265489644e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.7157157402139726e-06 Test: 3.8434530761738105e-06\n",
      "Epoch: 543\n",
      "Loss: \n",
      "Training: 3.602080356481037e-06 Test: 3.676134209142061e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.6895116470673777e-06 Test: 3.8116392537715907e-06\n",
      "Best params are updated.\n",
      "Epoch: 544\n",
      "Loss: \n",
      "Training: 3.456237894428212e-06 Test: 3.715881610347153e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.6810416052522566e-06 Test: 3.795012992605398e-06\n",
      "Epoch: 545\n",
      "Loss: \n",
      "Training: 3.5004282809235523e-06 Test: 3.5337162051999438e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.6436944782288294e-06 Test: 3.77862345092503e-06\n",
      "Epoch: 546\n",
      "Loss: \n",
      "Training: 3.6001485614889798e-06 Test: 3.6844700271737377e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.626077144832366e-06 Test: 3.7225667211445792e-06\n",
      "Best params are updated.\n",
      "Epoch: 547\n",
      "Loss: \n",
      "Training: 3.4260575392286497e-06 Test: 3.5322269741027384e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.6141562508046753e-06 Test: 3.7020272990467574e-06\n",
      "Epoch: 548\n",
      "Loss: \n",
      "Training: 3.5292541238229268e-06 Test: 3.4960238923656607e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.5814651698999654e-06 Test: 3.6893467939539533e-06\n",
      "Epoch: 549\n",
      "Loss: \n",
      "Training: 3.449976975652106e-06 Test: 3.7501214551150193e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.5564914063668073e-06 Test: 3.65488838927059e-06\n",
      "Epoch: 550\n",
      "Loss: \n",
      "Training: 3.4597909295544258e-06 Test: 3.6227469724774706e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.5337302310413244e-06 Test: 3.6410458277307174e-06\n",
      "Epoch: 551\n",
      "Loss: \n",
      "Training: 3.4310323710053673e-06 Test: 3.53318358313756e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.5160021526092713e-06 Test: 3.637513585105962e-06\n",
      "Best params are updated.\n",
      "Epoch: 552\n",
      "Loss: \n",
      "Training: 3.234382315531685e-06 Test: 3.1187192094660816e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.5076875194057085e-06 Test: 3.6078691194550986e-06\n",
      "Best params are updated.\n",
      "Epoch: 553\n",
      "Loss: \n",
      "Training: 3.122229376741057e-06 Test: 2.994558744856932e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4689389348116947e-06 Test: 3.5663224138527427e-06\n",
      "Epoch: 554\n",
      "Loss: \n",
      "Training: 3.1650980073960833e-06 Test: 3.28059191156497e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4209538368376963e-06 Test: 3.49816486742423e-06\n",
      "Epoch: 555\n",
      "Loss: \n",
      "Training: 3.3496938024583317e-06 Test: 3.3833722538338837e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3918398481344834e-06 Test: 3.4546358975460114e-06\n",
      "Epoch: 556\n",
      "Loss: \n",
      "Training: 3.1402297602518225e-06 Test: 3.1648407675103657e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3767664002879612e-06 Test: 3.4396015024094056e-06\n",
      "Epoch: 557\n",
      "Loss: \n",
      "Training: 3.2128511901658393e-06 Test: 3.2754191996550884e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.330774520164245e-06 Test: 3.3876385764430687e-06\n",
      "Epoch: 558\n",
      "Loss: \n",
      "Training: 3.1476545836426605e-06 Test: 3.5240728210345533e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.309453885257964e-06 Test: 3.3619577989983035e-06\n",
      "Epoch: 559\n",
      "Loss: \n",
      "Training: 3.139119021528633e-06 Test: 3.512744537346155e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.271293931239938e-06 Test: 3.3647626918651923e-06\n",
      "Best params are updated.\n",
      "Epoch: 560\n",
      "Loss: \n",
      "Training: 3.0938609760034674e-06 Test: 3.2626089049804576e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.240208135827591e-06 Test: 3.341025000088306e-06\n",
      "Epoch: 561\n",
      "Loss: \n",
      "Training: 3.1103032232239403e-06 Test: 3.3233771633503786e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.203615140472495e-06 Test: 3.305011193338605e-06\n",
      "Epoch: 562\n",
      "Loss: \n",
      "Training: 3.1331284866889714e-06 Test: 2.9590832445068763e-06\n",
      "Rolling mean of Loss (Window is 10): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 3.171542225694352e-06 Test: 3.284030551359887e-06\n",
      "Epoch: 563\n",
      "Loss: \n",
      "Training: 3.1422213689774923e-06 Test: 3.1893327696814044e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1614168428100805e-06 Test: 3.2680669548639663e-06\n",
      "Epoch: 564\n",
      "Loss: \n",
      "Training: 3.2236890210775853e-06 Test: 2.94673321705543e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1634160420337242e-06 Test: 3.2875443573464133e-06\n",
      "Epoch: 565\n",
      "Loss: \n",
      "Training: 3.193810623174498e-06 Test: 3.0104192763466644e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1692751434018744e-06 Test: 3.2541584878954595e-06\n",
      "Best params are updated.\n",
      "Epoch: 566\n",
      "Loss: \n",
      "Training: 3.0094167202249224e-06 Test: 3.152286706611502e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1536868254734914e-06 Test: 3.216863190146737e-06\n",
      "Epoch: 567\n",
      "Loss: \n",
      "Training: 3.1858505293198433e-06 Test: 2.945725652320979e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1406055214708013e-06 Test: 3.2156077840568508e-06\n",
      "Best params are updated.\n",
      "Epoch: 568\n",
      "Loss: \n",
      "Training: 2.9650026820255535e-06 Test: 3.182162186806075e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.137905455386201e-06 Test: 3.1826384293234397e-06\n",
      "Best params are updated.\n",
      "Epoch: 569\n",
      "Loss: \n",
      "Training: 2.9051445814611033e-06 Test: 3.3170899235084183e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1196402652244904e-06 Test: 3.1484473659005925e-06\n",
      "Epoch: 570\n",
      "Loss: \n",
      "Training: 2.9167719000536027e-06 Test: 3.070498820556002e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.0962428212177378e-06 Test: 3.128881904516819e-06\n",
      "Best params are updated.\n",
      "Epoch: 571\n",
      "Loss: \n",
      "Training: 2.892449250752742e-06 Test: 3.1454697477306627e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.078533913622751e-06 Test: 3.1096708960743732e-06\n",
      "Best params are updated.\n",
      "Epoch: 572\n",
      "Loss: \n",
      "Training: 2.772218757173194e-06 Test: 1.4926948977301155e-05\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.0567485163756313e-06 Test: 3.091880154512402e-06\n",
      "Epoch: 573\n",
      "Loss: \n",
      "Training: 3.017250337969305e-06 Test: 3.2140513349513448e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.020657543424053e-06 Test: 4.28866672779183e-06\n",
      "Epoch: 574\n",
      "Loss: \n",
      "Training: 2.9274060018724717e-06 Test: 2.8595093439660995e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.008160440323235e-06 Test: 4.291138584318824e-06\n",
      "Best params are updated.\n",
      "Epoch: 575\n",
      "Loss: \n",
      "Training: 2.6997479635801597e-06 Test: 2.8772445591444527e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.9785321384027238e-06 Test: 4.282416197009891e-06\n",
      "Epoch: 576\n",
      "Loss: \n",
      "Training: 2.956186895019825e-06 Test: 2.7093863619483417e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.92912587244329e-06 Test: 4.269098725289669e-06\n",
      "Best params are updated.\n",
      "Epoch: 577\n",
      "Loss: \n",
      "Training: 2.600878113727519e-06 Test: 2.7938701724582773e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.9238028899227806e-06 Test: 4.224808690823353e-06\n",
      "Epoch: 578\n",
      "Loss: \n",
      "Training: 2.618520766973477e-06 Test: 3.2869404781157546e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8653056483635483e-06 Test: 4.209623142837083e-06\n",
      "Epoch: 579\n",
      "Loss: \n",
      "Training: 2.96144352707187e-06 Test: 2.937595596084179e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8306574568583405e-06 Test: 4.220100971968051e-06\n",
      "Epoch: 580\n",
      "Loss: \n",
      "Training: 2.6407671447081628e-06 Test: 3.032366929164822e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8362873514194166e-06 Test: 4.182151539225628e-06\n",
      "Epoch: 581\n",
      "Loss: \n",
      "Training: 2.7603981490347595e-06 Test: 2.598376622010739e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8086868758848727e-06 Test: 4.178338350086509e-06\n",
      "Epoch: 582\n",
      "Loss: \n",
      "Training: 3.0487751863949066e-06 Test: 2.946733971951443e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7954817657130742e-06 Test: 4.123629037514517e-06\n",
      "Best params are updated.\n",
      "Epoch: 583\n",
      "Loss: \n",
      "Training: 2.5009778946504793e-06 Test: 2.965386172253692e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8231374086352454e-06 Test: 2.925607536979545e-06\n",
      "Epoch: 584\n",
      "Loss: \n",
      "Training: 2.8037867510759925e-06 Test: 2.804757514003434e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7715101643033632e-06 Test: 2.90074102070978e-06\n",
      "Epoch: 585\n",
      "Loss: \n",
      "Training: 2.727931918421498e-06 Test: 2.784242362289284e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.759148239223715e-06 Test: 2.8952658377135136e-06\n",
      "Epoch: 586\n",
      "Loss: \n",
      "Training: 2.7471942332347127e-06 Test: 2.886507479988525e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7619666347078488e-06 Test: 2.885965618027997e-06\n",
      "Epoch: 587\n",
      "Loss: \n",
      "Training: 2.976774316977559e-06 Test: 2.8213294554831465e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.741067368529338e-06 Test: 2.9036777298320153e-06\n",
      "Epoch: 588\n",
      "Loss: \n",
      "Training: 3.1156476155521604e-06 Test: 2.887756713133178e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7786569888543416e-06 Test: 2.906423658134502e-06\n",
      "Best params are updated.\n",
      "Epoch: 589\n",
      "Loss: \n",
      "Training: 2.427659006175433e-06 Test: 2.909966381645373e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8283696737122098e-06 Test: 2.8665052816362446e-06\n",
      "Epoch: 590\n",
      "Loss: \n",
      "Training: 2.6555861771404632e-06 Test: 3.2024730323255764e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7749912216225666e-06 Test: 2.863742360192364e-06\n",
      "Epoch: 591\n",
      "Loss: \n",
      "Training: 2.675724679958829e-06 Test: 2.82783868832466e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7764731248657968e-06 Test: 2.8807529705084395e-06\n",
      "Epoch: 592\n",
      "Loss: \n",
      "Training: 2.816442118952485e-06 Test: 3.489984980131417e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.768005777958204e-06 Test: 2.9036991771398313e-06\n",
      "Epoch: 593\n",
      "Loss: \n",
      "Training: 3.076432702032714e-06 Test: 2.987689799421964e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7447724712139615e-06 Test: 2.9580242779578284e-06\n",
      "Epoch: 594\n",
      "Loss: \n",
      "Training: 2.433327699748701e-06 Test: 3.1153191049642127e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.802317951952185e-06 Test: 2.9602546406746554e-06\n",
      "Epoch: 595\n",
      "Loss: \n",
      "Training: 2.840835294498721e-06 Test: 3.0365982904604037e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7652720468194557e-06 Test: 2.991310799770734e-06\n",
      "Epoch: 596\n",
      "Loss: \n",
      "Training: 2.6715307124701776e-06 Test: 2.737139018073438e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.776562384427178e-06 Test: 3.0165463925878455e-06\n",
      "Epoch: 597\n",
      "Loss: \n",
      "Training: 2.8029558959607826e-06 Test: 3.268212923138563e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7689960323507242e-06 Test: 3.0016095463963368e-06\n",
      "Epoch: 598\n",
      "Loss: \n",
      "Training: 3.0661465798460227e-06 Test: 2.9905992289192946e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7516141902490464e-06 Test: 3.0462978931618784e-06\n",
      "Epoch: 599\n",
      "Loss: \n",
      "Training: 2.7268962728584303e-06 Test: 2.9737845826651275e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7466640866784326e-06 Test: 3.0565821447404907e-06\n",
      "Epoch: 600\n",
      "Loss: \n",
      "Training: 2.9411807362945154e-06 Test: 4.0805787952623505e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.776587813346733e-06 Test: 3.0629639648424656e-06\n",
      "Epoch: 601\n",
      "Loss: \n",
      "Training: 3.920796967548833e-06 Test: 5.772688185819777e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8051472692621384e-06 Test: 3.150774541136143e-06\n",
      "Epoch: 602\n",
      "Loss: \n",
      "Training: 6.116842820691161e-06 Test: 6.083181071080338e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.9296544980211385e-06 Test: 3.4452594908856548e-06\n",
      "Epoch: 603\n",
      "Loss: \n",
      "Training: 5.705594929132937e-06 Test: 5.7702537104370136e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.2596945681950057e-06 Test: 3.7045790999805467e-06\n",
      "Epoch: 604\n",
      "Loss: \n",
      "Training: 5.53777198052372e-06 Test: 5.890828426615207e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.5226107909050284e-06 Test: 3.9828354910820516e-06\n",
      "Epoch: 605\n",
      "Loss: \n",
      "Training: 5.537086282547967e-06 Test: 5.572675221445943e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.83305521898253e-06 Test: 4.260386423247152e-06\n",
      "Epoch: 606\n",
      "Loss: \n",
      "Training: 5.7645494302148164e-06 Test: 5.594727695263143e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.1026803177874545e-06 Test: 4.513994116345705e-06\n",
      "Epoch: 607\n",
      "Loss: \n",
      "Training: 5.277032810974318e-06 Test: 5.56651032202274e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.411982189561918e-06 Test: 4.799752984064676e-06\n",
      "Epoch: 608\n",
      "Loss: \n",
      "Training: 5.372798179995582e-06 Test: 5.5373598494538005e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.6593898810632715e-06 Test: 5.0295827239530935e-06\n",
      "Epoch: 609\n",
      "Loss: \n",
      "Training: 5.840472182691893e-06 Test: 5.5559401636132634e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.8900550410782276e-06 Test: 5.284258786006544e-06\n",
      "Epoch: 610\n",
      "Loss: \n",
      "Training: 5.357042034530082e-06 Test: 5.447691950031621e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.201412632061574e-06 Test: 5.5424743441013585e-06\n",
      "Epoch: 611\n",
      "Loss: \n",
      "Training: 5.192859819883158e-06 Test: 5.354911840307703e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.442998761885131e-06 Test: 5.679185659578284e-06\n",
      "Epoch: 612\n",
      "Loss: \n",
      "Training: 5.141785647353691e-06 Test: 5.024733932908908e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.570205047118563e-06 Test: 5.637408025027077e-06\n",
      "Epoch: 613\n",
      "Loss: \n",
      "Training: 4.914160234699411e-06 Test: 5.18425888546118e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.4726993297848155e-06 Test: 5.531563311209935e-06\n",
      "Epoch: 614\n",
      "Loss: \n",
      "Training: 5.104428273817167e-06 Test: 4.746949360657003e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.3935558603414634e-06 Test: 5.472963828712352e-06\n",
      "Epoch: 615\n",
      "Loss: \n",
      "Training: 4.922458939782577e-06 Test: 4.9437816354523135e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.350221489670808e-06 Test: 5.35857592211653e-06\n",
      "Epoch: 616\n",
      "Loss: \n",
      "Training: 4.907163401373062e-06 Test: 4.734069048910947e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.288758755394269e-06 Test: 5.2956865635171674e-06\n",
      "Epoch: 617\n",
      "Loss: \n",
      "Training: 4.533727428475886e-06 Test: 4.685715499644622e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.2030201525100945e-06 Test: 5.209620698881949e-06\n",
      "Epoch: 618\n",
      "Loss: \n",
      "Training: 4.459782010777175e-06 Test: 4.680300490538122e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.12868961426025e-06 Test: 5.121541216644136e-06\n",
      "Epoch: 619\n",
      "Loss: \n",
      "Training: 4.285819210128996e-06 Test: 4.411074334395594e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.03738799733841e-06 Test: 5.035835280752569e-06\n",
      "Epoch: 620\n",
      "Loss: \n",
      "Training: 4.064119076121915e-06 Test: 4.517338554820273e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.881922700082121e-06 Test: 4.921348697830802e-06\n",
      "Epoch: 621\n",
      "Loss: \n",
      "Training: 4.463170909104577e-06 Test: 4.232276740755015e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.752630404241304e-06 Test: 4.828313358309666e-06\n",
      "Epoch: 622\n",
      "Loss: \n",
      "Training: 4.2384173195875865e-06 Test: 3.824687559374159e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.679661513163446e-06 Test: 4.716049848354398e-06\n",
      "Epoch: 623\n",
      "Loss: \n",
      "Training: 3.7836146521434606e-06 Test: 3.870191954942312e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.589324680386836e-06 Test: 4.596045211000923e-06\n",
      "Epoch: 624\n",
      "Loss: \n",
      "Training: 3.6994934698181494e-06 Test: 3.857336589302198e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.476270122131241e-06 Test: 4.464638517949036e-06\n",
      "Epoch: 625\n",
      "Loss: \n",
      "Training: 4.2191124964257785e-06 Test: 3.94179588812486e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.335776641731339e-06 Test: 4.3756772408135556e-06\n",
      "Epoch: 626\n",
      "Loss: \n",
      "Training: 4.1172562758449e-06 Test: 4.084599365127238e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.265441997395659e-06 Test: 4.27547866608081e-06\n",
      "Epoch: 627\n",
      "Loss: \n",
      "Training: 4.097607982032642e-06 Test: 4.206952544066683e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.186451284842843e-06 Test: 4.210531697702439e-06\n",
      "Epoch: 628\n",
      "Loss: \n",
      "Training: 4.154754606493367e-06 Test: 4.279896014777948e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.142839340198519e-06 Test: 4.162655402144645e-06\n",
      "Epoch: 629\n",
      "Loss: \n",
      "Training: 4.3734952528043474e-06 Test: 4.168780535782903e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.1123365997701375e-06 Test: 4.1226149545686284e-06\n",
      "Epoch: 630\n",
      "Loss: \n",
      "Training: 3.8043051779047224e-06 Test: 3.4478811702428907e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.121104204037673e-06 Test: 4.098385574707359e-06\n",
      "Epoch: 631\n",
      "Loss: \n",
      "Training: 3.0771593839494016e-06 Test: 2.8518823441440363e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.0951228142159535e-06 Test: 3.99143983624962e-06\n",
      "Epoch: 632\n",
      "Loss: \n",
      "Training: 2.7495867884792473e-06 Test: 2.524541839717979e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.956521661700436e-06 Test: 3.853400396588522e-06\n",
      "Best params are updated.\n",
      "Epoch: 633\n",
      "Loss: \n",
      "Training: 2.2449223625774388e-06 Test: 2.8278211805294765e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.807638608589602e-06 Test: 3.723385824622905e-06\n",
      "Epoch: 634\n",
      "Loss: \n",
      "Training: 2.4564218367982967e-06 Test: 3.3996404137496716e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.6537693796329992e-06 Test: 3.6191487471816213e-06\n",
      "Epoch: 635\n",
      "Loss: \n",
      "Training: 3.3656334148413103e-06 Test: 4.186510742248022e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.529462216331014e-06 Test: 3.5733791296263685e-06\n",
      "Epoch: 636\n",
      "Loss: \n",
      "Training: 3.6761785979046975e-06 Test: 4.258465775595614e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4441143081725673e-06 Test: 3.597850615038685e-06\n",
      "Epoch: 637\n",
      "Loss: \n",
      "Training: 4.117983088803022e-06 Test: 4.031393142436023e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4000065403785467e-06 Test: 3.615237256085523e-06\n",
      "Epoch: 638\n",
      "Loss: \n",
      "Training: 4.109258754204769e-06 Test: 4.271938869975826e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4020440510555853e-06 Test: 3.597681315922456e-06\n",
      "Epoch: 639\n",
      "Loss: \n",
      "Training: 4.32214850504508e-06 Test: 5.0463940611229045e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3974944658267256e-06 Test: 3.5968856014422435e-06\n",
      "Epoch: 640\n",
      "Loss: \n",
      "Training: 4.861080063649167e-06 Test: 5.465917162356071e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3923597910507985e-06 Test: 3.684646953976244e-06\n",
      "Epoch: 641\n",
      "Loss: \n",
      "Training: 5.365103303610393e-06 Test: 5.740721178473346e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4980372796252433e-06 Test: 3.886450553187562e-06\n",
      "Epoch: 642\n",
      "Loss: \n",
      "Training: 5.735045714414687e-06 Test: 5.629379105000751e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.726831671591342e-06 Test: 4.1753344366204945e-06\n",
      "Epoch: 643\n",
      "Loss: \n",
      "Training: 5.729687654162717e-06 Test: 5.7119017760202144e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.025377564184886e-06 Test: 4.485818163148771e-06\n",
      "Epoch: 644\n",
      "Loss: \n",
      "Training: 5.717051865098303e-06 Test: 5.764589183772031e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.373854093343414e-06 Test: 4.7742262226978455e-06\n",
      "Epoch: 645\n",
      "Loss: \n",
      "Training: 5.731550431670808e-06 Test: 6.023473112421012e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.699917096173415e-06 Test: 5.01072109970008e-06\n",
      "Epoch: 646\n",
      "Loss: \n",
      "Training: 5.796772675779864e-06 Test: 5.866733781350385e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.936508797856364e-06 Test: 5.194417336717379e-06\n",
      "Epoch: 647\n",
      "Loss: \n",
      "Training: 5.821063545322393e-06 Test: 5.921038158308181e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.1485682056438805e-06 Test: 5.355244137292857e-06\n",
      "Epoch: 648\n",
      "Loss: \n",
      "Training: 5.905062451244975e-06 Test: 5.933553867515784e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.318876251295817e-06 Test: 5.544208638880073e-06\n",
      "Epoch: 649\n",
      "Loss: \n",
      "Training: 6.140913406607262e-06 Test: 6.110255090107651e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.498456620999837e-06 Test: 5.710370138634068e-06\n",
      "Epoch: 650\n",
      "Loss: \n",
      "Training: 6.03738066153502e-06 Test: 6.26373235545417e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.6803331111560565e-06 Test: 5.816756241532542e-06\n",
      "Epoch: 651\n",
      "Loss: \n",
      "Training: 6.097448895904888e-06 Test: 6.150805620929738e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.797963170944641e-06 Test: 5.896537760842352e-06\n",
      "Epoch: 652\n",
      "Loss: \n",
      "Training: 6.143375461846495e-06 Test: 6.0316967466394405e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.871197730174091e-06 Test: 5.937546205087991e-06\n",
      "Epoch: 653\n",
      "Loss: \n",
      "Training: 6.120419319328631e-06 Test: 5.342592478856019e-06\n",
      "Rolling mean of Loss (Window is 10): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 5.912030704917272e-06 Test: 5.977777969251861e-06\n",
      "Epoch: 654\n",
      "Loss: \n",
      "Training: 5.327473632109008e-06 Test: 4.998963042306663e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.951103871433864e-06 Test: 5.940847039535441e-06\n",
      "Epoch: 655\n",
      "Loss: \n",
      "Training: 4.728002648135653e-06 Test: 5.032975300485247e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.912146048134935e-06 Test: 5.864284425388904e-06\n",
      "Epoch: 656\n",
      "Loss: \n",
      "Training: 4.870519011979115e-06 Test: 5.498046117329559e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.811791269781419e-06 Test: 5.765234644195328e-06\n",
      "Epoch: 657\n",
      "Loss: \n",
      "Training: 5.441454082187052e-06 Test: 5.8631048515810245e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.719165903401344e-06 Test: 5.728365877793245e-06\n",
      "Epoch: 658\n",
      "Loss: \n",
      "Training: 5.659994481443542e-06 Test: 6.496232574111755e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.68120495708781e-06 Test: 5.72257254712053e-06\n",
      "Epoch: 659\n",
      "Loss: \n",
      "Training: 6.269088142575321e-06 Test: 6.701429184643384e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.656698160107665e-06 Test: 5.778840417780127e-06\n",
      "Epoch: 660\n",
      "Loss: \n",
      "Training: 6.96445121381892e-06 Test: 6.776160757594353e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.669515633704471e-06 Test: 5.837957827233701e-06\n",
      "Epoch: 661\n",
      "Loss: \n",
      "Training: 6.84495610969823e-06 Test: 1.095816608232067e-05\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.762222688932863e-06 Test: 5.889200667447719e-06\n",
      "Epoch: 662\n",
      "Loss: \n",
      "Training: 1.1860731941310346e-05 Test: 6.926352483244491e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.836973410312197e-06 Test: 6.369936713586812e-06\n",
      "Epoch: 663\n",
      "Loss: \n",
      "Training: 6.739291282748152e-06 Test: 6.807225124200633e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.408709058258582e-06 Test: 6.459402287247317e-06\n",
      "Epoch: 664\n",
      "Loss: \n",
      "Training: 6.815868017495878e-06 Test: 6.901505467835224e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.470596254600534e-06 Test: 6.605865551781778e-06\n",
      "Epoch: 665\n",
      "Loss: \n",
      "Training: 6.736856069306122e-06 Test: 6.9941400702012436e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.619435693139221e-06 Test: 6.796119794334634e-06\n",
      "Epoch: 666\n",
      "Loss: \n",
      "Training: 6.847334903760646e-06 Test: 6.703231704842186e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.820321035256268e-06 Test: 6.992236271306233e-06\n",
      "Epoch: 667\n",
      "Loss: \n",
      "Training: 6.896661159567447e-06 Test: 6.725785270364619e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 7.018002624434422e-06 Test: 7.1127548300574955e-06\n",
      "Epoch: 668\n",
      "Loss: \n",
      "Training: 6.810114869067281e-06 Test: 6.84041234551023e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 7.1635233321724615e-06 Test: 7.199022871935855e-06\n",
      "Epoch: 669\n",
      "Loss: \n",
      "Training: 6.8925016763393386e-06 Test: 6.956363148031751e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 7.278535370934836e-06 Test: 7.233440849075702e-06\n",
      "Epoch: 670\n",
      "Loss: \n",
      "Training: 6.8440550387274116e-06 Test: 6.626652407323956e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 7.340876724311236e-06 Test: 7.258934245414539e-06\n",
      "Epoch: 671\n",
      "Loss: \n",
      "Training: 6.626266871121644e-06 Test: 6.715823418204987e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 7.328837106802084e-06 Test: 7.2439834103875e-06\n",
      "Epoch: 672\n",
      "Loss: \n",
      "Training: 6.697300070978021e-06 Test: 6.528455600184493e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 7.306968182944426e-06 Test: 6.819749143975933e-06\n",
      "Epoch: 673\n",
      "Loss: \n",
      "Training: 6.719922983693251e-06 Test: 6.8788562132454615e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.790624995911196e-06 Test: 6.779959455669933e-06\n",
      "Epoch: 674\n",
      "Loss: \n",
      "Training: 6.715700815230918e-06 Test: 6.635579989136119e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.7886881660057035e-06 Test: 6.787122564574415e-06\n",
      "Epoch: 675\n",
      "Loss: \n",
      "Training: 6.417320645911005e-06 Test: 6.701177385966367e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.778671445779207e-06 Test: 6.760530016704506e-06\n",
      "Epoch: 676\n",
      "Loss: \n",
      "Training: 6.6866607653380735e-06 Test: 6.993007473925384e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.746717903439696e-06 Test: 6.731233748281017e-06\n",
      "Epoch: 677\n",
      "Loss: \n",
      "Training: 6.776732583190693e-06 Test: 6.779753307729338e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.730650489597439e-06 Test: 6.760211325189337e-06\n",
      "Epoch: 678\n",
      "Loss: \n",
      "Training: 6.8429126666838065e-06 Test: 6.9250115459244395e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.718657631959764e-06 Test: 6.765608128925809e-06\n",
      "Epoch: 679\n",
      "Loss: \n",
      "Training: 6.980605659278134e-06 Test: 7.020563236663406e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.721937411721417e-06 Test: 6.774068048967229e-06\n",
      "Epoch: 680\n",
      "Loss: \n",
      "Training: 6.84043585553279e-06 Test: 7.030806710770543e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.730747810015296e-06 Test: 6.780488057830395e-06\n",
      "Epoch: 681\n",
      "Loss: \n",
      "Training: 6.855005441270936e-06 Test: 6.987235731996325e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.730385891695832e-06 Test: 6.820903488175052e-06\n",
      "Epoch: 682\n",
      "Loss: \n",
      "Training: 6.914696138112741e-06 Test: 6.973514842996098e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.753259748710762e-06 Test: 6.848044719554186e-06\n",
      "Epoch: 683\n",
      "Loss: \n",
      "Training: 6.7380959209598284e-06 Test: 6.893697975346672e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.774999355424235e-06 Test: 6.892550643835348e-06\n",
      "Epoch: 684\n",
      "Loss: \n",
      "Training: 6.986132266512665e-06 Test: 6.726877742311594e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.776816649150893e-06 Test: 6.894034820045469e-06\n",
      "Epoch: 685\n",
      "Loss: \n",
      "Training: 6.624873058102943e-06 Test: 6.601188784402699e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.803859794279066e-06 Test: 6.903164595363017e-06\n",
      "Epoch: 686\n",
      "Loss: \n",
      "Training: 6.615117273367449e-06 Test: 6.531205737651349e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.8246150354982615e-06 Test: 6.893165735206651e-06\n",
      "Epoch: 687\n",
      "Loss: \n",
      "Training: 6.813080940938436e-06 Test: 6.80380560625978e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.817460686301199e-06 Test: 6.846985561579246e-06\n",
      "Epoch: 688\n",
      "Loss: \n",
      "Training: 6.603942285768201e-06 Test: 6.7717873228443e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.821095522075972e-06 Test: 6.849390791432292e-06\n",
      "Epoch: 689\n",
      "Loss: \n",
      "Training: 6.67552034624752e-06 Test: 6.411167616279516e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.797198483984412e-06 Test: 6.834068369124277e-06\n",
      "Epoch: 690\n",
      "Loss: \n",
      "Training: 6.294850377336511e-06 Test: 6.387568894447065e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.766689952681351e-06 Test: 6.773128807085888e-06\n",
      "Epoch: 691\n",
      "Loss: \n",
      "Training: 6.350251635738382e-06 Test: 6.664104738334062e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.712131404861723e-06 Test: 6.70880502545354e-06\n",
      "Epoch: 692\n",
      "Loss: \n",
      "Training: 6.582621066253702e-06 Test: 6.616585715436841e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.661656024308469e-06 Test: 6.676491926087314e-06\n",
      "Epoch: 693\n",
      "Loss: \n",
      "Training: 6.436748583597176e-06 Test: 6.248442560889715e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.6284485171225645e-06 Test: 6.640799013331387e-06\n",
      "Epoch: 694\n",
      "Loss: \n",
      "Training: 6.162462042904745e-06 Test: 6.3305572977614144e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.598313783386298e-06 Test: 6.576273471885693e-06\n",
      "Epoch: 695\n",
      "Loss: \n",
      "Training: 6.1711173168124814e-06 Test: 6.503325003907026e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.515946761025507e-06 Test: 6.5366414274306754e-06\n",
      "Epoch: 696\n",
      "Loss: \n",
      "Training: 6.559454864389053e-06 Test: 6.315925554279773e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.470571186896461e-06 Test: 6.526855049381107e-06\n",
      "Epoch: 697\n",
      "Loss: \n",
      "Training: 6.3182398154033885e-06 Test: 6.234926033840744e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.465004945998621e-06 Test: 6.5053270310439505e-06\n",
      "Epoch: 698\n",
      "Loss: \n",
      "Training: 6.033962087502975e-06 Test: 6.090678989604726e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.4155208334451144e-06 Test: 6.448439073802046e-06\n",
      "Epoch: 699\n",
      "Loss: \n",
      "Training: 6.028637455229874e-06 Test: 5.916185422127963e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.358522813618592e-06 Test: 6.380328240478089e-06\n",
      "Epoch: 700\n",
      "Loss: \n",
      "Training: 6.029748554803465e-06 Test: 4.388809484351851e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.293834524516828e-06 Test: 6.330830021062933e-06\n",
      "Epoch: 701\n",
      "Loss: \n",
      "Training: 4.292520517210971e-06 Test: 5.828066330300066e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.267324342263524e-06 Test: 6.130954080053412e-06\n",
      "Epoch: 702\n",
      "Loss: \n",
      "Training: 5.981142928555441e-06 Test: 4.983263273797677e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.061551230410782e-06 Test: 6.0473502392500114e-06\n",
      "Epoch: 703\n",
      "Loss: \n",
      "Training: 4.987249084374095e-06 Test: 5.099502891391494e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.001403416640957e-06 Test: 5.884017995086095e-06\n",
      "Epoch: 704\n",
      "Loss: \n",
      "Training: 4.81060241949755e-06 Test: 4.9923755379206955e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.856453466718648e-06 Test: 5.769124028136273e-06\n",
      "Epoch: 705\n",
      "Loss: \n",
      "Training: 4.9168310796818715e-06 Test: 5.168340079534418e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.721267504377929e-06 Test: 5.6353058521522005e-06\n",
      "Epoch: 706\n",
      "Loss: \n",
      "Training: 5.2093729320953786e-06 Test: 5.3042260641165116e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.595838880664869e-06 Test: 5.50180735971494e-06\n",
      "Epoch: 707\n",
      "Loss: \n",
      "Training: 5.069972132727874e-06 Test: 5.445028089281091e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.4608306874355015e-06 Test: 5.400637410698615e-06\n",
      "Epoch: 708\n",
      "Loss: \n",
      "Training: 5.2455915914345e-06 Test: 5.59680868994042e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.3360039191679494e-06 Test: 5.3216476162426495e-06\n",
      "Epoch: 709\n",
      "Loss: \n",
      "Training: 5.351240253378141e-06 Test: 5.682953996024203e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.257166869561102e-06 Test: 5.2722605862762194e-06\n",
      "Epoch: 710\n",
      "Loss: \n",
      "Training: 5.906674096770905e-06 Test: 5.766020559641803e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.189427149375928e-06 Test: 5.248937443665843e-06\n",
      "Epoch: 711\n",
      "Loss: \n",
      "Training: 5.74466498197199e-06 Test: 5.973345523110357e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.177119703572673e-06 Test: 5.3866585511948385e-06\n",
      "Epoch: 712\n",
      "Loss: \n",
      "Training: 5.8369453932939295e-06 Test: 6.281238681817895e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.322334150048775e-06 Test: 5.401186470475867e-06\n",
      "Epoch: 713\n",
      "Loss: \n",
      "Training: 6.068964630222317e-06 Test: 6.0755463769531986e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.307914396522624e-06 Test: 5.530984011277889e-06\n",
      "Epoch: 714\n",
      "Loss: \n",
      "Training: 6.081977934836143e-06 Test: 6.300912222353243e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.416085951107446e-06 Test: 5.62858835983406e-06\n",
      "Epoch: 715\n",
      "Loss: \n",
      "Training: 6.189040940825761e-06 Test: 6.151727077068225e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.543223502641305e-06 Test: 5.759442028277315e-06\n",
      "Epoch: 716\n",
      "Loss: \n",
      "Training: 6.162164112438736e-06 Test: 6.2446290033346676e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.670444488755694e-06 Test: 5.857780728030695e-06\n",
      "Epoch: 717\n",
      "Loss: \n",
      "Training: 6.260516972375507e-06 Test: 6.170458337920394e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.7657236067900285e-06 Test: 5.951821021952511e-06\n",
      "Epoch: 718\n",
      "Loss: \n",
      "Training: 6.168758901912884e-06 Test: 6.176703179055319e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.8847780907547935e-06 Test: 6.024364046816441e-06\n",
      "Epoch: 719\n",
      "Loss: \n",
      "Training: 6.129780248955174e-06 Test: 6.232202356668087e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.977094821802632e-06 Test: 6.082353495727931e-06\n",
      "Epoch: 720\n",
      "Loss: \n",
      "Training: 5.95694485407317e-06 Test: 6.047844384203214e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.054948821360336e-06 Test: 6.137278331792317e-06\n",
      "Epoch: 721\n",
      "Loss: \n",
      "Training: 5.95092564253108e-06 Test: 6.192242924914239e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.059975897090561e-06 Test: 6.165460714248459e-06\n",
      "Epoch: 722\n",
      "Loss: \n",
      "Training: 6.010241838893674e-06 Test: 6.0643862348192525e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.08060196314647e-06 Test: 6.187350454428849e-06\n",
      "Epoch: 723\n",
      "Loss: \n",
      "Training: 5.973971505567897e-06 Test: 5.811263225857069e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.0979316077064455e-06 Test: 6.165665209728984e-06\n",
      "Epoch: 724\n",
      "Loss: \n",
      "Training: 5.718436367952036e-06 Test: 5.677418419955403e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.088432295241003e-06 Test: 6.1392368946193715e-06\n",
      "Epoch: 725\n",
      "Loss: \n",
      "Training: 5.688842683292049e-06 Test: 5.568320401919989e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.052078138552592e-06 Test: 6.076887514379587e-06\n",
      "Epoch: 726\n",
      "Loss: \n",
      "Training: 5.622693014068664e-06 Test: 5.56471233496055e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.0020583127992205e-06 Test: 6.018546846864763e-06\n",
      "Epoch: 727\n",
      "Loss: \n",
      "Training: 5.470937624325432e-06 Test: 5.288962520978197e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.948111202962214e-06 Test: 5.950555180027351e-06\n",
      "Epoch: 728\n",
      "Loss: \n",
      "Training: 5.087589901879419e-06 Test: 4.957469779967003e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.869153268157205e-06 Test: 5.862405598333132e-06\n",
      "Epoch: 729\n",
      "Loss: \n",
      "Training: 4.884230029787487e-06 Test: 4.807915677825469e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.7610363681538595e-06 Test: 5.7404822584243e-06\n",
      "Epoch: 730\n",
      "Loss: \n",
      "Training: 4.565446949232405e-06 Test: 4.623514362726526e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.63648134623709e-06 Test: 5.598053590540039e-06\n",
      "Epoch: 731\n",
      "Loss: \n",
      "Training: 4.627294100967775e-06 Test: 4.325900569357654e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.497331555753014e-06 Test: 5.45562058839237e-06\n",
      "Epoch: 732\n",
      "Loss: \n",
      "Training: 4.3270511592072165e-06 Test: 4.343406965652835e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.364968401596684e-06 Test: 5.268986352836711e-06\n",
      "Epoch: 733\n",
      "Loss: \n",
      "Training: 4.395116207052471e-06 Test: 3.913765030959644e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.196649333628038e-06 Test: 5.09688842592007e-06\n",
      "Epoch: 734\n",
      "Loss: \n",
      "Training: 3.834308167488059e-06 Test: 3.845930417403319e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.0387638037764955e-06 Test: 4.907138606430327e-06\n",
      "Epoch: 735\n",
      "Loss: \n",
      "Training: 3.7300552601549105e-06 Test: 3.663410176316403e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.8503509837300974e-06 Test: 4.7239898061751195e-06\n",
      "Epoch: 736\n",
      "Loss: \n",
      "Training: 3.6910542736416225e-06 Test: 3.477721714922667e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.654472241416384e-06 Test: 4.53349878361476e-06\n",
      "Epoch: 737\n",
      "Loss: \n",
      "Training: 3.5645912508012474e-06 Test: 3.446200090060648e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.46130836737368e-06 Test: 4.3247997216109715e-06\n",
      "Epoch: 738\n",
      "Loss: \n",
      "Training: 3.3150835267142986e-06 Test: 3.3058150218018056e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.270673730021262e-06 Test: 4.140523478519217e-06\n",
      "Epoch: 739\n",
      "Loss: \n",
      "Training: 3.254122947891147e-06 Test: 3.40475803920432e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.0934230925047494e-06 Test: 3.975358002702698e-06\n",
      "Epoch: 740\n",
      "Loss: \n",
      "Training: 3.3630089656067425e-06 Test: 3.6769182987946783e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.930412384315115e-06 Test: 3.8350422388405835e-06\n",
      "Epoch: 741\n",
      "Loss: \n",
      "Training: 3.6806646816173573e-06 Test: 4.408875719687249e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.810168585952549e-06 Test: 3.740382632447398e-06\n",
      "Epoch: 742\n",
      "Loss: \n",
      "Training: 4.607431873827707e-06 Test: 4.897134712151103e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.715505644017507e-06 Test: 3.748680147480357e-06\n",
      "Epoch: 743\n",
      "Loss: \n",
      "Training: 4.902046536202915e-06 Test: 5.118753905248632e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.7435437154795563e-06 Test: 3.804052922130184e-06\n",
      "Epoch: 744\n",
      "Loss: \n",
      "Training: 4.938629536357764e-06 Test: 5.411591260487661e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.794236748394601e-06 Test: 3.924551809559083e-06\n",
      "Epoch: 745\n",
      "Loss: \n",
      "Training: 5.40201405830919e-06 Test: 5.451727946351973e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.904668885281571e-06 Test: 4.081117893867516e-06\n",
      "Epoch: 746\n",
      "Loss: \n",
      "Training: 5.209986847121712e-06 Test: 5.477076580639472e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.071864765097e-06 Test: 4.259949670871074e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 747\n",
      "Loss: \n",
      "Training: 5.439740542415773e-06 Test: 5.861172860217199e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.223758022445008e-06 Test: 4.459885157442753e-06\n",
      "Epoch: 748\n",
      "Loss: \n",
      "Training: 5.8997533860127545e-06 Test: 5.925726085975268e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.411272951606461e-06 Test: 4.701382434458409e-06\n",
      "Epoch: 749\n",
      "Loss: \n",
      "Training: 6.106334507980179e-06 Test: 6.0460404798487975e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.6697399375363056e-06 Test: 4.963373540875755e-06\n",
      "Epoch: 750\n",
      "Loss: \n",
      "Training: 6.176353307459571e-06 Test: 7.478490857931044e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.954961093545209e-06 Test: 5.227501784940202e-06\n",
      "Epoch: 751\n",
      "Loss: \n",
      "Training: 7.343773776007627e-06 Test: 6.601402557804696e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.236295527730492e-06 Test: 5.60765904085384e-06\n",
      "Epoch: 752\n",
      "Loss: \n",
      "Training: 6.713622283972051e-06 Test: 6.234493699880593e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.60260643716952e-06 Test: 5.826911724665584e-06\n",
      "Epoch: 753\n",
      "Loss: \n",
      "Training: 6.081976925874176e-06 Test: 4.264345021093765e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.8132254781839535e-06 Test: 5.960647623438533e-06\n",
      "Epoch: 754\n",
      "Loss: \n",
      "Training: 4.028136445773715e-06 Test: 8.02744296750765e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.9312185171510796e-06 Test: 5.875206735023047e-06\n",
      "Epoch: 755\n",
      "Loss: \n",
      "Training: 7.858351148731527e-06 Test: 5.308948833857759e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.840169208092674e-06 Test: 6.136791905725047e-06\n",
      "Epoch: 756\n",
      "Loss: \n",
      "Training: 5.3217146171327735e-06 Test: 3.6352113654288807e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.08580291713491e-06 Test: 6.122513994475625e-06\n",
      "Epoch: 757\n",
      "Loss: \n",
      "Training: 3.560269583109763e-06 Test: 7.449785066392893e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.096975694136015e-06 Test: 5.9383274729545656e-06\n",
      "Epoch: 758\n",
      "Loss: \n",
      "Training: 7.078994238454461e-06 Test: 4.996131942356023e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.909028598205414e-06 Test: 6.0971886935721345e-06\n",
      "Epoch: 759\n",
      "Loss: \n",
      "Training: 4.964419268180942e-06 Test: 3.54770790191575e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.026952683449584e-06 Test: 6.004229279210211e-06\n",
      "Epoch: 760\n",
      "Loss: \n",
      "Training: 3.5374790025153737e-06 Test: 3.6997189245847847e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.91276115946966e-06 Test: 5.754396021416905e-06\n",
      "Epoch: 761\n",
      "Loss: \n",
      "Training: 3.2059646030725754e-06 Test: 3.964047781708062e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.6488737289752405e-06 Test: 5.376518828082279e-06\n",
      "Epoch: 762\n",
      "Loss: \n",
      "Training: 3.856317181641324e-06 Test: 3.204225107810079e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.235092811681736e-06 Test: 5.112783350472616e-06\n",
      "Epoch: 763\n",
      "Loss: \n",
      "Training: 3.10987560945288e-06 Test: 3.5581878402810104e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.949362301448663e-06 Test: 4.809756491265564e-06\n",
      "Epoch: 764\n",
      "Loss: \n",
      "Training: 4.024182313295023e-06 Test: 3.2533283468289284e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.6521521698065335e-06 Test: 4.739140773184289e-06\n",
      "Epoch: 765\n",
      "Loss: \n",
      "Training: 3.1565587762850066e-06 Test: 3.3556211219010706e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.651756756558664e-06 Test: 4.2617293111164165e-06\n",
      "Epoch: 766\n",
      "Loss: \n",
      "Training: 2.9737109991479023e-06 Test: 2.884319628145473e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.181577519314012e-06 Test: 4.066396539920748e-06\n",
      "Epoch: 767\n",
      "Loss: \n",
      "Training: 2.664658455625171e-06 Test: 3.4424160985241343e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.9467771575155255e-06 Test: 3.991307366192407e-06\n",
      "Epoch: 768\n",
      "Loss: \n",
      "Training: 3.4066366151518146e-06 Test: 3.444636046674575e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.857216044767066e-06 Test: 3.5905704694055317e-06\n",
      "Epoch: 769\n",
      "Loss: \n",
      "Training: 3.6343718889470184e-06 Test: 2.772459341897488e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4899802824368012e-06 Test: 3.4354208798373863e-06\n",
      "Epoch: 770\n",
      "Loss: \n",
      "Training: 2.6484560561193096e-06 Test: 3.2315620916872575e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.356975544513409e-06 Test: 3.35789602383556e-06\n",
      "Epoch: 771\n",
      "Loss: \n",
      "Training: 2.896038524040916e-06 Test: 3.93055820576996e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.268073249873802e-06 Test: 3.311080340545808e-06\n",
      "Epoch: 772\n",
      "Loss: \n",
      "Training: 4.7654024214122725e-06 Test: 2.93880116570857e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.2370806419706365e-06 Test: 3.3077313829519975e-06\n",
      "Epoch: 773\n",
      "Loss: \n",
      "Training: 2.626139386068813e-06 Test: 3.193660450041706e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.327989165947731e-06 Test: 3.281188988741847e-06\n",
      "Epoch: 774\n",
      "Loss: \n",
      "Training: 2.726129241226493e-06 Test: 2.577359796776779e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.2796155436093247e-06 Test: 3.244736249717916e-06\n",
      "Epoch: 775\n",
      "Loss: \n",
      "Training: 2.6594762284800947e-06 Test: 3.822354251305579e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1498102364024717e-06 Test: 3.177139394712701e-06\n",
      "Epoch: 776\n",
      "Loss: \n",
      "Training: 2.7064633997109988e-06 Test: 2.7922115793857895e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.100101981621981e-06 Test: 3.2238127076531526e-06\n",
      "Epoch: 777\n",
      "Loss: \n",
      "Training: 2.651023669300846e-06 Test: 2.89097884761767e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.07337722167829e-06 Test: 3.2146019027771845e-06\n",
      "Epoch: 778\n",
      "Loss: \n",
      "Training: 2.7488562284745e-06 Test: 3.389556611671085e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.072013743045858e-06 Test: 3.1594581776865374e-06\n",
      "Epoch: 779\n",
      "Loss: \n",
      "Training: 2.8629027127046143e-06 Test: 2.7265801832763353e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.0062357043781266e-06 Test: 3.1539502341861883e-06\n",
      "Epoch: 780\n",
      "Loss: \n",
      "Training: 3.7553195874101366e-06 Test: 3.5060967280506396e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.9290887867538862e-06 Test: 3.1493623183240733e-06\n",
      "Epoch: 781\n",
      "Loss: \n",
      "Training: 3.2207853500203484e-06 Test: 2.724979414438951e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.039775139882968e-06 Test: 3.176815781960412e-06\n",
      "Epoch: 782\n",
      "Loss: \n",
      "Training: 2.9332490658440964e-06 Test: 3.3869344847729555e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.0722498224809115e-06 Test: 3.0562579028273105e-06\n",
      "Epoch: 783\n",
      "Loss: \n",
      "Training: 2.3688310882020476e-06 Test: 2.6671586179658596e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8890344869240945e-06 Test: 3.1010712347337494e-06\n",
      "Epoch: 784\n",
      "Loss: \n",
      "Training: 2.8375510251788445e-06 Test: 3.2823405570518117e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8633036571374178e-06 Test: 3.048421051526164e-06\n",
      "Epoch: 785\n",
      "Loss: \n",
      "Training: 3.0308202495900147e-06 Test: 2.8765708992422736e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8744458355326523e-06 Test: 3.1189191275536677e-06\n",
      "Epoch: 786\n",
      "Loss: \n",
      "Training: 2.6876294347090214e-06 Test: 2.7589417253986785e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.911580237643645e-06 Test: 3.0243407923473366e-06\n",
      "Epoch: 787\n",
      "Loss: \n",
      "Training: 3.2205091593026036e-06 Test: 3.6293322456941114e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.9096968411434473e-06 Test: 3.021013806948626e-06\n",
      "Epoch: 788\n",
      "Loss: \n",
      "Training: 2.414986083197548e-06 Test: 2.7891859115962334e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.9666453901436227e-06 Test: 3.09484914675627e-06\n",
      "Epoch: 789\n",
      "Loss: \n",
      "Training: 3.0018900341918725e-06 Test: 2.7585009931958603e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.9332583756159274e-06 Test: 3.0348120767487847e-06\n",
      "Epoch: 790\n",
      "Loss: \n",
      "Training: 2.664899164934193e-06 Test: 2.888693601480172e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.9471571077646538e-06 Test: 3.038004157740737e-06\n",
      "Epoch: 791\n",
      "Loss: \n",
      "Training: 2.5505163970688473e-06 Test: 3.068091666373039e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8381150655170593e-06 Test: 2.9762638450836905e-06\n",
      "Epoch: 792\n",
      "Loss: \n",
      "Training: 3.1480266722144225e-06 Test: 3.1077218631375155e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.771088170221909e-06 Test: 3.0105750702770992e-06\n",
      "Epoch: 793\n",
      "Loss: \n",
      "Training: 2.871776640986045e-06 Test: 3.3175985633879307e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.792565930858942e-06 Test: 2.9826538081135553e-06\n",
      "Epoch: 794\n",
      "Loss: \n",
      "Training: 2.4004556044296287e-06 Test: 3.5777713311540627e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8428604861373413e-06 Test: 3.0476978026557622e-06\n",
      "Epoch: 795\n",
      "Loss: \n",
      "Training: 3.0459479965052924e-06 Test: 3.1386120862274532e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7991509440624197e-06 Test: 3.0772408800659877e-06\n",
      "Epoch: 796\n",
      "Loss: \n",
      "Training: 2.9935205727063407e-06 Test: 2.817516045258239e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8006637187539474e-06 Test: 3.1034449987645054e-06\n",
      "Epoch: 797\n",
      "Loss: \n",
      "Training: 2.3337295789239115e-06 Test: 3.4686110740961334e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.83125283255368e-06 Test: 3.109302430750461e-06\n",
      "Epoch: 798\n",
      "Loss: \n",
      "Training: 3.021724078251379e-06 Test: 3.021614645831078e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7425748745158104e-06 Test: 3.0932303135906636e-06\n",
      "Epoch: 799\n",
      "Loss: \n",
      "Training: 3.833258389027968e-06 Test: 3.5994833333356237e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8032486740211935e-06 Test: 3.1164731870141484e-06\n",
      "Epoch: 800\n",
      "Loss: \n",
      "Training: 3.986860975278726e-06 Test: 6.584406807350205e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.886385509504803e-06 Test: 3.200571421028125e-06\n",
      "Epoch: 801\n",
      "Loss: \n",
      "Training: 6.54592746369204e-06 Test: 9.440475800971106e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.0185816905392564e-06 Test: 3.5701427416151283e-06\n",
      "Epoch: 802\n",
      "Loss: \n",
      "Training: 9.337886762257352e-06 Test: 6.323063378427815e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.418122797201575e-06 Test: 4.2073811550749345e-06\n",
      "Epoch: 803\n",
      "Loss: \n",
      "Training: 6.603891494144563e-06 Test: 5.181055153720198e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.037108806205869e-06 Test: 4.528915306603965e-06\n",
      "Epoch: 804\n",
      "Loss: \n",
      "Training: 5.7713352580175005e-06 Test: 6.224924121207769e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.410320291521721e-06 Test: 4.715260965637192e-06\n",
      "Epoch: 805\n",
      "Loss: \n",
      "Training: 6.332829775973736e-06 Test: 6.586511503205913e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.747408256880508e-06 Test: 4.979976244642562e-06\n",
      "Epoch: 806\n",
      "Loss: \n",
      "Training: 6.665296667851399e-06 Test: 5.181248941709514e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.076096434827352e-06 Test: 5.3247661863404075e-06\n",
      "Epoch: 807\n",
      "Loss: \n",
      "Training: 4.162039798249573e-06 Test: 6.098859439695152e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.443274044341859e-06 Test: 5.561139475985535e-06\n",
      "Epoch: 808\n",
      "Loss: \n",
      "Training: 6.271117815671311e-06 Test: 6.782338290592674e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.626105066274424e-06 Test: 5.824164312545438e-06\n",
      "Epoch: 809\n",
      "Loss: \n",
      "Training: 6.77776970690162e-06 Test: 4.611237379861715e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.951044440016418e-06 Test: 6.200236677021597e-06\n",
      "Epoch: 810\n",
      "Loss: \n",
      "Training: 4.313727930257068e-06 Test: 4.4301565836487155e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.245495571803782e-06 Test: 6.301412081674206e-06\n",
      "Epoch: 811\n",
      "Loss: \n",
      "Training: 4.507782009998656e-06 Test: 4.1772670147073816e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.278182267301615e-06 Test: 6.0859870593040565e-06\n",
      "Epoch: 812\n",
      "Loss: \n",
      "Training: 4.178025568442438e-06 Test: 4.227387262616768e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.0743677219322774e-06 Test: 5.559666180677684e-06\n",
      "Epoch: 813\n",
      "Loss: \n",
      "Training: 4.236082007321318e-06 Test: 3.93300688919913e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.5583816025507865e-06 Test: 5.3500985690965796e-06\n",
      "Epoch: 814\n",
      "Loss: \n",
      "Training: 3.8624815374215074e-06 Test: 3.306001870035835e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.321600653868462e-06 Test: 5.225293742644473e-06\n",
      "Epoch: 815\n",
      "Loss: \n",
      "Training: 2.985211771218093e-06 Test: 3.7367542910605504e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.130715281808863e-06 Test: 4.93340151752728e-06\n",
      "Epoch: 816\n",
      "Loss: \n",
      "Training: 3.57565754105168e-06 Test: 3.4422361298131727e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.795953481333299e-06 Test: 4.648425796312744e-06\n",
      "Epoch: 817\n",
      "Loss: \n",
      "Training: 3.5480745087618433e-06 Test: 3.2783148418654885e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.486989568653327e-06 Test: 4.47452451512311e-06\n",
      "Epoch: 818\n",
      "Loss: \n",
      "Training: 3.134183081700459e-06 Test: 3.0289096483060163e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.425593039704554e-06 Test: 4.192470055340143e-06\n",
      "Epoch: 819\n",
      "Loss: \n",
      "Training: 3.1538206531551706e-06 Test: 2.6591054581425114e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.111899566307468e-06 Test: 3.817127191111477e-06\n",
      "Epoch: 820\n",
      "Loss: \n",
      "Training: 2.889889978330267e-06 Test: 3.080516247597621e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.749504660932823e-06 Test: 3.621913998939557e-06\n",
      "Epoch: 821\n",
      "Loss: \n",
      "Training: 3.6631891125926916e-06 Test: 3.269402713883665e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.607120865740143e-06 Test: 3.486949965334447e-06\n",
      "Epoch: 822\n",
      "Loss: \n",
      "Training: 2.9857597950722335e-06 Test: 2.9598228205301675e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.5226615759995465e-06 Test: 3.3961635352520755e-06\n",
      "Epoch: 823\n",
      "Loss: \n",
      "Training: 3.28813008911793e-06 Test: 3.13158179833265e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4034349986625267e-06 Test: 3.2694070910434155e-06\n",
      "Epoch: 824\n",
      "Loss: \n",
      "Training: 3.1042967047525112e-06 Test: 3.142557658986413e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3086398068421877e-06 Test: 3.1892645819567676e-06\n",
      "Epoch: 825\n",
      "Loss: \n",
      "Training: 2.6650471172911977e-06 Test: 3.4045734093376273e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.232821323575288e-06 Test: 3.172920160851825e-06\n",
      "Epoch: 826\n",
      "Loss: \n",
      "Training: 3.2956234307509094e-06 Test: 3.5571583577812588e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.2008048581825982e-06 Test: 3.139702072679533e-06\n",
      "Epoch: 827\n",
      "Loss: \n",
      "Training: 3.1047931362314505e-06 Test: 3.2150761151467466e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.172801447152521e-06 Test: 3.1511942954763414e-06\n",
      "Epoch: 828\n",
      "Loss: \n",
      "Training: 3.3629401750003487e-06 Test: 2.9562526348769297e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.128473309899482e-06 Test: 3.144870422804468e-06\n",
      "Epoch: 829\n",
      "Loss: \n",
      "Training: 3.111258021617534e-06 Test: 3.3858320588367825e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1513490192294717e-06 Test: 3.137604721461559e-06\n",
      "Epoch: 830\n",
      "Loss: \n",
      "Training: 3.098286355535586e-06 Test: 4.0096944812100766e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1470927560757073e-06 Test: 3.2102773815309855e-06\n",
      "Epoch: 831\n",
      "Loss: \n",
      "Training: 2.664283913850283e-06 Test: 3.765413942089795e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.167932393796239e-06 Test: 3.3031952048922314e-06\n",
      "Epoch: 832\n",
      "Loss: \n",
      "Training: 3.5651471846422263e-06 Test: 3.8230399567966296e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.0680418739219986e-06 Test: 3.3527963277128454e-06\n",
      "Epoch: 833\n",
      "Loss: \n",
      "Training: 3.2419822501657405e-06 Test: 2.9356347042015896e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1259806128789976e-06 Test: 3.4391180413394907e-06\n",
      "Epoch: 834\n",
      "Loss: \n",
      "Training: 2.8480950006064794e-06 Test: 3.0438256445028757e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1213658289837784e-06 Test: 3.4195233319263848e-06\n",
      "Epoch: 835\n",
      "Loss: \n",
      "Training: 3.2014718939254616e-06 Test: 4.190933236202072e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.095745658569175e-06 Test: 3.4096501304780314e-06\n",
      "Epoch: 836\n",
      "Loss: \n",
      "Training: 2.8790080206882212e-06 Test: 3.7798733343750794e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1493881362326016e-06 Test: 3.488286113164476e-06\n",
      "Epoch: 837\n",
      "Loss: \n",
      "Training: 3.6070766402806416e-06 Test: 3.6505043225209636e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.107726595226333e-06 Test: 3.5105576108238578e-06\n",
      "Epoch: 838\n",
      "Loss: \n",
      "Training: 3.465744060795214e-06 Test: 3.840084043558899e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1579549456312526e-06 Test: 3.5541004315612787e-06\n",
      "Epoch: 839\n",
      "Loss: \n",
      "Training: 2.6917272022800115e-06 Test: 3.500798126483002e-06\n",
      "Rolling mean of Loss (Window is 10): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 3.1682353342107385e-06 Test: 3.6424835724294758e-06\n",
      "Epoch: 840\n",
      "Loss: \n",
      "Training: 3.3798652611013586e-06 Test: 3.655085768180083e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1262822522769866e-06 Test: 3.6539801791940983e-06\n",
      "Epoch: 841\n",
      "Loss: \n",
      "Training: 3.461171833913151e-06 Test: 4.368808762047755e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1544401428335634e-06 Test: 3.6185193078910994e-06\n",
      "Epoch: 842\n",
      "Loss: \n",
      "Training: 3.466680803047707e-06 Test: 3.6402768869957316e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.2341289348398508e-06 Test: 3.678858789886895e-06\n",
      "Epoch: 843\n",
      "Loss: \n",
      "Training: 3.804522341827471e-06 Test: 3.454782037137584e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.2242822966803986e-06 Test: 3.660582482906805e-06\n",
      "Epoch: 844\n",
      "Loss: \n",
      "Training: 3.3288363858429383e-06 Test: 4.34250341687715e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.2805363058465714e-06 Test: 3.7124972162004047e-06\n",
      "Epoch: 845\n",
      "Loss: \n",
      "Training: 4.609287385938353e-06 Test: 4.115008678888437e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3286104443702173e-06 Test: 3.842364993437831e-06\n",
      "Epoch: 846\n",
      "Loss: \n",
      "Training: 2.894441587645179e-06 Test: 3.991280332279368e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.469391993571506e-06 Test: 3.834772537706469e-06\n",
      "Epoch: 847\n",
      "Loss: \n",
      "Training: 2.751898530462126e-06 Test: 4.24518574358568e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4709353502672023e-06 Test: 3.855913237496897e-06\n",
      "Epoch: 848\n",
      "Loss: \n",
      "Training: 4.222039344406057e-06 Test: 4.069263960661602e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.385417539285351e-06 Test: 3.915381379603368e-06\n",
      "Epoch: 849\n",
      "Loss: \n",
      "Training: 4.1969011682039516e-06 Test: 4.454991468248115e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4610470676464354e-06 Test: 3.938299371313639e-06\n",
      "Epoch: 850\n",
      "Loss: \n",
      "Training: 4.352255047346001e-06 Test: 7.728659477794923e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.61156446423883e-06 Test: 4.03371870549015e-06\n",
      "Epoch: 851\n",
      "Loss: \n",
      "Training: 7.4757362056748085e-06 Test: 8.672651467074244e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.708803442863294e-06 Test: 4.441076076451634e-06\n",
      "Epoch: 852\n",
      "Loss: \n",
      "Training: 8.381340083503428e-06 Test: 6.5564559205807826e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.1102598800394595e-06 Test: 4.871460346954283e-06\n",
      "Epoch: 853\n",
      "Loss: \n",
      "Training: 6.31989149639038e-06 Test: 6.2098885962966565e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.601725808085031e-06 Test: 5.163078250312788e-06\n",
      "Epoch: 854\n",
      "Loss: \n",
      "Training: 6.1859356137824685e-06 Test: 6.114319132509267e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.853262723541322e-06 Test: 5.4385889062286965e-06\n",
      "Epoch: 855\n",
      "Loss: \n",
      "Training: 6.106643811493917e-06 Test: 6.276838295442967e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.138972646335275e-06 Test: 5.615770477791907e-06\n",
      "Epoch: 856\n",
      "Loss: \n",
      "Training: 5.479742196843033e-06 Test: 6.6071254686711985e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.288708288890832e-06 Test: 5.831953439447361e-06\n",
      "Epoch: 857\n",
      "Loss: \n",
      "Training: 6.496829941920537e-06 Test: 5.270524405870033e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.5472383498106166e-06 Test: 6.093537953086544e-06\n",
      "Epoch: 858\n",
      "Loss: \n",
      "Training: 5.0526456341270616e-06 Test: 9.118645884668142e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.921731490956459e-06 Test: 6.196071819314979e-06\n",
      "Epoch: 859\n",
      "Loss: \n",
      "Training: 9.73652890977225e-06 Test: 6.841205716551862e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.004792119928559e-06 Test: 6.701010011715633e-06\n",
      "Epoch: 860\n",
      "Loss: \n",
      "Training: 7.3229396763386355e-06 Test: 4.856067858288649e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.558754894085388e-06 Test: 6.939631436546008e-06\n",
      "Epoch: 861\n",
      "Loss: \n",
      "Training: 4.598906943988919e-06 Test: 6.223155888466554e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.855823356984652e-06 Test: 6.6523722745953795e-06\n",
      "Epoch: 862\n",
      "Loss: \n",
      "Training: 6.022362000368715e-06 Test: 4.112930476508729e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.568140430816062e-06 Test: 6.407422716734612e-06\n",
      "Epoch: 863\n",
      "Loss: \n",
      "Training: 3.964386010016304e-06 Test: 5.096317466573072e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.332242622502591e-06 Test: 6.163070172327407e-06\n",
      "Epoch: 864\n",
      "Loss: \n",
      "Training: 5.140205831461316e-06 Test: 3.520428761436812e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 6.096692073865184e-06 Test: 6.0517130593550475e-06\n",
      "Epoch: 865\n",
      "Loss: \n",
      "Training: 4.950099431566962e-06 Test: 3.7791359626082905e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.9921190956330675e-06 Test: 5.792324022247802e-06\n",
      "Epoch: 866\n",
      "Loss: \n",
      "Training: 4.2013932912711975e-06 Test: 3.8423085456057705e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.876464657640372e-06 Test: 5.542553788964334e-06\n",
      "Epoch: 867\n",
      "Loss: \n",
      "Training: 4.040392551611668e-06 Test: 3.908869563279255e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.748629767083189e-06 Test: 5.26607209665779e-06\n",
      "Epoch: 868\n",
      "Loss: \n",
      "Training: 3.868341200297314e-06 Test: 4.201754545665867e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.502986028052302e-06 Test: 5.129906612398713e-06\n",
      "Epoch: 869\n",
      "Loss: \n",
      "Training: 3.6253882741333523e-06 Test: 3.660679473552773e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.384555584669328e-06 Test: 4.638217478498487e-06\n",
      "Epoch: 870\n",
      "Loss: \n",
      "Training: 3.64844892644288e-06 Test: 3.991669969960706e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.773441521105438e-06 Test: 4.320164854198578e-06\n",
      "Epoch: 871\n",
      "Loss: \n",
      "Training: 3.612854901308077e-06 Test: 3.672680451351261e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.405992446115863e-06 Test: 4.233725065365783e-06\n",
      "Epoch: 872\n",
      "Loss: \n",
      "Training: 3.1317377346482245e-06 Test: 3.4377221149443546e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.307387241847779e-06 Test: 3.978677521654253e-06\n",
      "Epoch: 873\n",
      "Loss: \n",
      "Training: 3.895633445483564e-06 Test: 3.2954765116495117e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.01832481527573e-06 Test: 3.911156685497816e-06\n",
      "Epoch: 874\n",
      "Loss: \n",
      "Training: 2.9679110109184386e-06 Test: 2.934002152549232e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.011449558822456e-06 Test: 3.7310725900054596e-06\n",
      "Epoch: 875\n",
      "Loss: \n",
      "Training: 2.70067221115015e-06 Test: 3.5784738270698236e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.794220076768167e-06 Test: 3.672429929116702e-06\n",
      "Epoch: 876\n",
      "Loss: \n",
      "Training: 3.04770465863677e-06 Test: 3.168453117607944e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.5692773547264863e-06 Test: 3.6523637155628552e-06\n",
      "Epoch: 877\n",
      "Loss: \n",
      "Training: 3.2072377952340864e-06 Test: 3.0955903451876814e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4539084914630438e-06 Test: 3.584978172763073e-06\n",
      "Epoch: 878\n",
      "Loss: \n",
      "Training: 3.1820957697111877e-06 Test: 3.654458686131578e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3705930158252855e-06 Test: 3.5036502509539156e-06\n",
      "Epoch: 879\n",
      "Loss: \n",
      "Training: 2.91982975040566e-06 Test: 2.7947061848855946e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3019684727666735e-06 Test: 3.4489206650004862e-06\n",
      "Epoch: 880\n",
      "Loss: \n",
      "Training: 2.6381797015935037e-06 Test: 3.1469259609235273e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.231412620393904e-06 Test: 3.3623233361337685e-06\n",
      "Epoch: 881\n",
      "Loss: \n",
      "Training: 3.0516645106413816e-06 Test: 3.3290387284482538e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1303856979089657e-06 Test: 3.2778489352300507e-06\n",
      "Epoch: 882\n",
      "Loss: \n",
      "Training: 3.307646455067785e-06 Test: 3.842289455494871e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.0742666588422967e-06 Test: 3.24348476293975e-06\n",
      "Epoch: 883\n",
      "Loss: \n",
      "Training: 3.2883894017963864e-06 Test: 2.9806115131782187e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.0918575308842527e-06 Test: 3.283941496994802e-06\n",
      "Epoch: 884\n",
      "Loss: \n",
      "Training: 3.265668358031831e-06 Test: 3.9328564580216894e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.0311331265155353e-06 Test: 3.252454997147672e-06\n",
      "Epoch: 885\n",
      "Loss: \n",
      "Training: 3.2016363854619435e-06 Test: 4.8520739614243216e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.0609088612268744e-06 Test: 3.352340427694918e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 886\n",
      "Loss: \n",
      "Training: 3.691411065647375e-06 Test: 3.6664500104879885e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.111005278658054e-06 Test: 3.479700441130368e-06\n",
      "Epoch: 887\n",
      "Loss: \n",
      "Training: 3.842093419871995e-06 Test: 3.3183770303432997e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1753759193591146e-06 Test: 3.5295001304183725e-06\n",
      "Epoch: 888\n",
      "Loss: \n",
      "Training: 3.425599280105089e-06 Test: 3.206423477575055e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.2388614818229043e-06 Test: 3.551778798933934e-06\n",
      "Epoch: 889\n",
      "Loss: \n",
      "Training: 3.564697349183846e-06 Test: 4.3589360254709245e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.263211832862295e-06 Test: 3.5069752780782823e-06\n",
      "Epoch: 890\n",
      "Loss: \n",
      "Training: 3.5752204927490074e-06 Test: 3.2696270497005257e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.327698592740114e-06 Test: 3.663398262136815e-06\n",
      "Epoch: 891\n",
      "Loss: \n",
      "Training: 3.5557956292607994e-06 Test: 3.930970773104717e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4214026718556642e-06 Test: 3.675668371014515e-06\n",
      "Epoch: 892\n",
      "Loss: \n",
      "Training: 3.056567522094175e-06 Test: 3.4892391934946572e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4718157837176056e-06 Test: 3.7358615754801615e-06\n",
      "Epoch: 893\n",
      "Loss: \n",
      "Training: 3.1961968521278245e-06 Test: 4.406557357072422e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.446707890420245e-06 Test: 3.7005565492801396e-06\n",
      "Epoch: 894\n",
      "Loss: \n",
      "Training: 3.1747792547488622e-06 Test: 4.422204028287131e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.437488635453389e-06 Test: 3.84315113366956e-06\n",
      "Epoch: 895\n",
      "Loss: \n",
      "Training: 3.3049721565350804e-06 Test: 4.867558443677178e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.428399725125092e-06 Test: 3.892085890696104e-06\n",
      "Epoch: 896\n",
      "Loss: \n",
      "Training: 3.5659450326897456e-06 Test: 4.646462363252906e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.438733302232406e-06 Test: 3.89363433892139e-06\n",
      "Epoch: 897\n",
      "Loss: \n",
      "Training: 3.820621559425369e-06 Test: 3.3313574900832326e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4261866989366433e-06 Test: 3.991635574197882e-06\n",
      "Epoch: 898\n",
      "Loss: \n",
      "Training: 3.4556848625586235e-06 Test: 4.3363407037890335e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4240395128919803e-06 Test: 3.992933620171875e-06\n",
      "Epoch: 899\n",
      "Loss: \n",
      "Training: 3.2886704371844314e-06 Test: 4.173717789795119e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4270480711373337e-06 Test: 4.105925342793272e-06\n",
      "Epoch: 900\n",
      "Loss: \n",
      "Training: 3.8474661229618e-06 Test: 5.702163832387879e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.399445379937392e-06 Test: 4.087403519225692e-06\n",
      "Epoch: 901\n",
      "Loss: \n",
      "Training: 5.5560945036026785e-06 Test: 6.494197617091525e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4266699429586704e-06 Test: 4.330657197494427e-06\n",
      "Epoch: 902\n",
      "Loss: \n",
      "Training: 6.722593014604197e-06 Test: 6.0575073818889005e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.6266998303928585e-06 Test: 4.586979881893108e-06\n",
      "Epoch: 903\n",
      "Loss: \n",
      "Training: 6.087208500017131e-06 Test: 5.646606928848453e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.993302379643861e-06 Test: 4.843806700732532e-06\n",
      "Epoch: 904\n",
      "Loss: \n",
      "Training: 5.3406626776131904e-06 Test: 5.20686099099995e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.2824035444327915e-06 Test: 4.967811657910136e-06\n",
      "Epoch: 905\n",
      "Loss: \n",
      "Training: 4.916521823678266e-06 Test: 4.607516351313948e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.498991886719224e-06 Test: 5.046277354181418e-06\n",
      "Epoch: 906\n",
      "Loss: \n",
      "Training: 4.577614205199108e-06 Test: 3.262887701014574e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.660146853433543e-06 Test: 5.020273144945095e-06\n",
      "Epoch: 907\n",
      "Loss: \n",
      "Training: 3.5209050089327705e-06 Test: 4.893320363412593e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.761313770684479e-06 Test: 4.8819156787212605e-06\n",
      "Epoch: 908\n",
      "Loss: \n",
      "Training: 5.186888633977855e-06 Test: 4.42347024794664e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.73134211563522e-06 Test: 5.038111966054196e-06\n",
      "Epoch: 909\n",
      "Loss: \n",
      "Training: 4.305925844888119e-06 Test: 3.281897037480709e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.904462492777143e-06 Test: 5.046824920469958e-06\n",
      "Epoch: 910\n",
      "Loss: \n",
      "Training: 3.25547898642254e-06 Test: 4.54645609938628e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 5.006188033547511e-06 Test: 4.957642845238517e-06\n",
      "Epoch: 911\n",
      "Loss: \n",
      "Training: 4.554549448170015e-06 Test: 2.9506197889053664e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.946989319893586e-06 Test: 4.842072071938357e-06\n",
      "Epoch: 912\n",
      "Loss: \n",
      "Training: 2.757359777595567e-06 Test: 2.8838249622700095e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.8468348143503195e-06 Test: 4.487714289119742e-06\n",
      "Epoch: 913\n",
      "Loss: \n",
      "Training: 2.784232160164657e-06 Test: 3.0342317812376597e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.450311490649457e-06 Test: 4.170346047157853e-06\n",
      "Epoch: 914\n",
      "Loss: \n",
      "Training: 3.308223263384811e-06 Test: 3.906559359190105e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.120013856664208e-06 Test: 3.909108532396773e-06\n",
      "Epoch: 915\n",
      "Loss: \n",
      "Training: 3.7692242053100343e-06 Test: 2.671471874580929e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.91676991524137e-06 Test: 3.779078369215788e-06\n",
      "Epoch: 916\n",
      "Loss: \n",
      "Training: 2.6436194703295476e-06 Test: 3.1988637914296973e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.802040153404548e-06 Test: 3.585473921542486e-06\n",
      "Epoch: 917\n",
      "Loss: \n",
      "Training: 3.0608109728984783e-06 Test: 2.9051276861230673e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.6086406799175916e-06 Test: 3.579071530583999e-06\n",
      "Epoch: 918\n",
      "Loss: \n",
      "Training: 2.6934007743110245e-06 Test: 2.4879611369550375e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.562631276314162e-06 Test: 3.380252262855047e-06\n",
      "Epoch: 919\n",
      "Loss: \n",
      "Training: 2.384880841831921e-06 Test: 2.970444947303695e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.313282490347479e-06 Test: 3.186701351755886e-06\n",
      "Epoch: 920\n",
      "Loss: \n",
      "Training: 2.5771179739947556e-06 Test: 3.0959446254796246e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1211779900418594e-06 Test: 3.1555561427381844e-06\n",
      "Epoch: 921\n",
      "Loss: \n",
      "Training: 2.9317691900049897e-06 Test: 3.351185149618384e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.053341888799081e-06 Test: 3.010504995347519e-06\n",
      "Epoch: 922\n",
      "Loss: \n",
      "Training: 3.251029466981288e-06 Test: 2.9395210622403565e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.891063862982579e-06 Test: 3.050561531418821e-06\n",
      "Epoch: 923\n",
      "Loss: \n",
      "Training: 2.745433634160293e-06 Test: 2.9130901346412464e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.940430831921151e-06 Test: 3.0561311414158555e-06\n",
      "Epoch: 924\n",
      "Loss: \n",
      "Training: 3.0014751503413774e-06 Test: 3.2772681486283697e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.9365509793207143e-06 Test: 3.0440169767562142e-06\n",
      "Epoch: 925\n",
      "Loss: \n",
      "Training: 2.937433745279724e-06 Test: 3.0153033880807965e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.905876168016371e-06 Test: 2.9810878557000404e-06\n",
      "Epoch: 926\n",
      "Loss: \n",
      "Training: 2.616799092183835e-06 Test: 3.0746003010582135e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.82269712201334e-06 Test: 3.015471007050027e-06\n",
      "Epoch: 927\n",
      "Loss: \n",
      "Training: 2.887414010072943e-06 Test: 3.478162080243963e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8200150841987683e-06 Test: 3.003044658012879e-06\n",
      "Epoch: 928\n",
      "Loss: \n",
      "Training: 2.6699808576945448e-06 Test: 2.9817681346126172e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8026753879162153e-06 Test: 3.0603480974249683e-06\n",
      "Epoch: 929\n",
      "Loss: \n",
      "Training: 2.5182106336466065e-06 Test: 3.1700381206473055e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8003333962545674e-06 Test: 3.1097287971907262e-06\n",
      "Epoch: 930\n",
      "Loss: \n",
      "Training: 3.2251803068382297e-06 Test: 3.941277897446334e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.813666375436036e-06 Test: 3.1296881145250873e-06\n",
      "Epoch: 931\n",
      "Loss: \n",
      "Training: 3.7584324671869923e-06 Test: 3.065491717689127e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8784726087203835e-06 Test: 3.2142214417217583e-06\n",
      "Epoch: 932\n",
      "Loss: \n",
      "Training: 3.0500676051237163e-06 Test: 3.359515728620136e-06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.9611389364385836e-06 Test: 3.1856520985288327e-06\n",
      "Epoch: 933\n",
      "Loss: \n",
      "Training: 2.7052821169515666e-06 Test: 3.6758509571463856e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.9410427502528264e-06 Test: 3.2276515651668113e-06\n",
      "Epoch: 934\n",
      "Loss: \n",
      "Training: 3.1366074364503298e-06 Test: 3.221864189526012e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.9370275985319536e-06 Test: 3.3039276474173254e-06\n",
      "Epoch: 935\n",
      "Loss: \n",
      "Training: 3.724273744135182e-06 Test: 3.1441250150780807e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.9505408271428487e-06 Test: 3.2983872515070886e-06\n",
      "Epoch: 936\n",
      "Loss: \n",
      "Training: 3.4820515249261962e-06 Test: 4.321712497858856e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.0292248270283948e-06 Test: 3.3112694142068177e-06\n",
      "Epoch: 937\n",
      "Loss: \n",
      "Training: 3.207867590488007e-06 Test: 3.1850723490272793e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1157500703026307e-06 Test: 3.4359806338868818e-06\n",
      "Epoch: 938\n",
      "Loss: \n",
      "Training: 3.202614643785444e-06 Test: 3.631725774364901e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1477954283441373e-06 Test: 3.4066716607652134e-06\n",
      "Epoch: 939\n",
      "Loss: \n",
      "Training: 4.6298393271583665e-06 Test: 3.3679824179682635e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.2010588069532267e-06 Test: 3.471667424740442e-06\n",
      "Epoch: 940\n",
      "Loss: \n",
      "Training: 3.255388770352027e-06 Test: 3.4604486654192794e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4122216763044033e-06 Test: 3.491461854472538e-06\n",
      "Epoch: 941\n",
      "Loss: \n",
      "Training: 3.374940557612025e-06 Test: 3.85315334192192e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.415242522655783e-06 Test: 3.4433789312698324e-06\n",
      "Epoch: 942\n",
      "Loss: \n",
      "Training: 3.6641815991890563e-06 Test: 4.013024666332283e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.376893331698286e-06 Test: 3.5221450936931115e-06\n",
      "Epoch: 943\n",
      "Loss: \n",
      "Training: 3.476502292245296e-06 Test: 3.847821380221644e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.43830473110482e-06 Test: 3.587495987464326e-06\n",
      "Epoch: 944\n",
      "Loss: \n",
      "Training: 3.826885396278954e-06 Test: 4.763633053697142e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.515426748634193e-06 Test: 3.604693029771852e-06\n",
      "Epoch: 945\n",
      "Loss: \n",
      "Training: 3.3519451417698397e-06 Test: 4.080533077151323e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.5844545446170546e-06 Test: 3.7588699161889644e-06\n",
      "Epoch: 946\n",
      "Loss: \n",
      "Training: 3.358213701578713e-06 Test: 3.4022916288573563e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.5472216843805202e-06 Test: 3.852510722396289e-06\n",
      "Epoch: 947\n",
      "Loss: \n",
      "Training: 4.357019512939325e-06 Test: 3.8042155712162282e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.534837902045773e-06 Test: 3.760568635496139e-06\n",
      "Epoch: 948\n",
      "Loss: \n",
      "Training: 3.6889711787361043e-06 Test: 4.416239299140428e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.6497530942909042e-06 Test: 3.822482957715033e-06\n",
      "Epoch: 949\n",
      "Loss: \n",
      "Training: 3.084765072485757e-06 Test: 3.4338808031968413e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.698388747785971e-06 Test: 3.900934310192586e-06\n",
      "Epoch: 950\n",
      "Loss: \n",
      "Training: 3.2049743381083267e-06 Test: 7.012246643684675e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.5438813223187104e-06 Test: 3.907524148715445e-06\n",
      "Epoch: 951\n",
      "Loss: \n",
      "Training: 6.881911763722401e-06 Test: 7.531455105148995e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.53883987909434e-06 Test: 4.262703946541984e-06\n",
      "Epoch: 952\n",
      "Loss: \n",
      "Training: 7.6289831117112506e-06 Test: 6.17675496316403e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.8895369997053775e-06 Test: 4.630534122864692e-06\n",
      "Epoch: 953\n",
      "Loss: \n",
      "Training: 6.3028946529389825e-06 Test: 4.483132767676924e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.286017150957596e-06 Test: 4.846907152547866e-06\n",
      "Epoch: 954\n",
      "Loss: \n",
      "Training: 4.5596158166214275e-06 Test: 4.430809112224232e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.5686563870269656e-06 Test: 4.910438291293393e-06\n",
      "Epoch: 955\n",
      "Loss: \n",
      "Training: 4.5221633573042725e-06 Test: 3.816300395512886e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.641929429061212e-06 Test: 4.877155897146103e-06\n",
      "Epoch: 956\n",
      "Loss: \n",
      "Training: 3.902050814227113e-06 Test: 4.064056700806344e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.758951250614656e-06 Test: 4.8507326289822586e-06\n",
      "Epoch: 957\n",
      "Loss: \n",
      "Training: 3.7985618302649157e-06 Test: 4.172023726554704e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.813334961879496e-06 Test: 4.916909136177158e-06\n",
      "Epoch: 958\n",
      "Loss: \n",
      "Training: 4.041191831693962e-06 Test: 3.986088410590359e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.757489193612055e-06 Test: 4.9536899517110056e-06\n",
      "Epoch: 959\n",
      "Loss: \n",
      "Training: 3.6599087108028783e-06 Test: 3.7253135400968927e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.7927112589078404e-06 Test: 4.910674862855999e-06\n",
      "Epoch: 960\n",
      "Loss: \n",
      "Training: 3.869669140445459e-06 Test: 3.304066800840727e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.8502256227395535e-06 Test: 4.939818136546004e-06\n",
      "Epoch: 961\n",
      "Loss: \n",
      "Training: 2.9920840551068244e-06 Test: 3.119084717488523e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.916695102973266e-06 Test: 4.569000152261608e-06\n",
      "Epoch: 962\n",
      "Loss: \n",
      "Training: 2.8009506955668555e-06 Test: 3.893728174402937e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.5277123321117085e-06 Test: 4.127763113495562e-06\n",
      "Epoch: 963\n",
      "Loss: \n",
      "Training: 3.4986217173062737e-06 Test: 3.0464084393172888e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 4.044909090497268e-06 Test: 3.899460434619453e-06\n",
      "Epoch: 964\n",
      "Loss: \n",
      "Training: 3.3753403746925064e-06 Test: 2.788662092857769e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.764481796933998e-06 Test: 3.7557880017834895e-06\n",
      "Epoch: 965\n",
      "Loss: \n",
      "Training: 3.5486718820797887e-06 Test: 3.2162321654935897e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.6460542527411066e-06 Test: 3.591573299846843e-06\n",
      "Epoch: 966\n",
      "Loss: \n",
      "Training: 2.753192739965191e-06 Test: 3.0701345409539768e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.548705105218659e-06 Test: 3.5315664768449134e-06\n",
      "Epoch: 967\n",
      "Loss: \n",
      "Training: 3.0615675012345707e-06 Test: 3.0877026077818715e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.433819297792465e-06 Test: 3.4321742608596768e-06\n",
      "Epoch: 968\n",
      "Loss: \n",
      "Training: 3.939944827204431e-06 Test: 3.3334007931398705e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.360119864889431e-06 Test: 3.323742148982393e-06\n",
      "Epoch: 969\n",
      "Loss: \n",
      "Training: 2.7928046985145887e-06 Test: 3.1798420577357176e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.349995164440478e-06 Test: 3.2584733872373445e-06\n",
      "Epoch: 970\n",
      "Loss: \n",
      "Training: 3.0283621005685305e-06 Test: 4.0602424260261395e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.263284763211649e-06 Test: 3.203926239001227e-06\n",
      "Epoch: 971\n",
      "Loss: \n",
      "Training: 3.3031840653712834e-06 Test: 3.534270921783226e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.179154059223956e-06 Test: 3.2795438015197687e-06\n",
      "Epoch: 972\n",
      "Loss: \n",
      "Training: 3.4746869931582665e-06 Test: 3.837218575003145e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.2102640602504016e-06 Test: 3.3210624219492387e-06\n",
      "Epoch: 973\n",
      "Loss: \n",
      "Training: 3.418593116098287e-06 Test: 2.9445181328341e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.277637690009543e-06 Test: 3.31541146200926e-06\n",
      "Epoch: 974\n",
      "Loss: \n",
      "Training: 3.192689154687506e-06 Test: 4.311513375082149e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.2696348298887447e-06 Test: 3.305222431360941e-06\n",
      "Epoch: 975\n",
      "Loss: \n",
      "Training: 2.9991132298079447e-06 Test: 3.307242988203795e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.2513697078882443e-06 Test: 3.457507559583379e-06\n",
      "Epoch: 976\n",
      "Loss: \n",
      "Training: 4.201890598473142e-06 Test: 3.700416743890785e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.19641384266106e-06 Test: 3.4666086418543995e-06\n",
      "Epoch: 977\n",
      "Loss: \n",
      "Training: 3.8661550796038495e-06 Test: 3.4343261391642676e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3412836285118544e-06 Test: 3.52963686214808e-06\n",
      "Epoch: 978\n",
      "Loss: \n",
      "Training: 3.31735845860153e-06 Test: 2.9374012452380575e-06\n",
      "Rolling mean of Loss (Window is 10): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 3.4217423863487836e-06 Test: 3.5642992152863193e-06\n",
      "Epoch: 979\n",
      "Loss: \n",
      "Training: 2.7846577629986566e-06 Test: 3.113207386170507e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.359483749488493e-06 Test: 3.5246992604961387e-06\n",
      "Epoch: 980\n",
      "Loss: \n",
      "Training: 3.1348169001915255e-06 Test: 3.5491785661250003e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.358669055936899e-06 Test: 3.518035793339617e-06\n",
      "Epoch: 981\n",
      "Loss: \n",
      "Training: 3.342831341531973e-06 Test: 3.044902211658249e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.369314535899199e-06 Test: 3.466929407349504e-06\n",
      "Epoch: 982\n",
      "Loss: \n",
      "Training: 4.1389917542732436e-06 Test: 4.014883319572818e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3732792635152677e-06 Test: 3.4179925363370058e-06\n",
      "Epoch: 983\n",
      "Loss: \n",
      "Training: 3.776841937434318e-06 Test: 3.2819494992060225e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4397097396267656e-06 Test: 3.435759010793973e-06\n",
      "Epoch: 984\n",
      "Loss: \n",
      "Training: 2.759620952204289e-06 Test: 3.319243918890802e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.475534621760369e-06 Test: 3.4695021474311654e-06\n",
      "Epoch: 985\n",
      "Loss: \n",
      "Training: 3.1557803993399364e-06 Test: 3.5772765930293604e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4322278015120474e-06 Test: 3.3702752018120305e-06\n",
      "Epoch: 986\n",
      "Loss: \n",
      "Training: 3.1970505898703065e-06 Test: 3.7527945570779617e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4478945184652467e-06 Test: 3.3972785622945866e-06\n",
      "Epoch: 987\n",
      "Loss: \n",
      "Training: 3.17828384814189e-06 Test: 3.869646957723589e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.347410517604963e-06 Test: 3.402516343613305e-06\n",
      "Epoch: 988\n",
      "Loss: \n",
      "Training: 3.7761879954110186e-06 Test: 3.77497422900896e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.278623394458767e-06 Test: 3.4460484254692367e-06\n",
      "Epoch: 989\n",
      "Loss: \n",
      "Training: 3.4564972456535252e-06 Test: 4.293150305534065e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.324506348139716e-06 Test: 3.529805723846327e-06\n",
      "Epoch: 990\n",
      "Loss: \n",
      "Training: 2.982123370516568e-06 Test: 4.402416159080984e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3916902964052024e-06 Test: 3.6478000157826828e-06\n",
      "Epoch: 991\n",
      "Loss: \n",
      "Training: 3.0902154662646585e-06 Test: 3.3471701421094576e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3764209434377066e-06 Test: 3.7331237750782818e-06\n",
      "Epoch: 992\n",
      "Loss: \n",
      "Training: 3.7312434738079652e-06 Test: 3.470156748982442e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3511593559109753e-06 Test: 3.7633505681234026e-06\n",
      "Epoch: 993\n",
      "Loss: \n",
      "Training: 3.202688863015888e-06 Test: 3.639107651715713e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3103845278644475e-06 Test: 3.7088779110643645e-06\n",
      "Epoch: 994\n",
      "Loss: \n",
      "Training: 3.9754386583882675e-06 Test: 3.048694157473453e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.252969220422605e-06 Test: 3.744593726315333e-06\n",
      "Epoch: 995\n",
      "Loss: \n",
      "Training: 3.3928914450430487e-06 Test: 3.431254472441853e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.374550991041002e-06 Test: 3.7175387501735983e-06\n",
      "Epoch: 996\n",
      "Loss: \n",
      "Training: 3.3635160095331408e-06 Test: 3.0868945736979473e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3982620956113134e-06 Test: 3.7029365381148474e-06\n",
      "Epoch: 997\n",
      "Loss: \n",
      "Training: 3.6154444084571037e-06 Test: 4.169219762137177e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4149086375775973e-06 Test: 3.6363465397768463e-06\n",
      "Epoch: 998\n",
      "Loss: \n",
      "Training: 3.654262244509407e-06 Test: 3.822514451214354e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4586246936091182e-06 Test: 3.6663038202182057e-06\n",
      "Epoch: 999\n",
      "Loss: \n",
      "Training: 3.6872010428287716e-06 Test: 4.53642309513696e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4464321185189576e-06 Test: 3.671057842438745e-06\n",
      "Epoch: 1000\n",
      "Loss: \n",
      "Training: 2.994511934483113e-06 Test: 8.080940439333354e-06\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.4695024982364822e-06 Test: 3.695385121399034e-06\n",
      "Best params are saved.\n",
      "end. \n"
     ]
    }
   ],
   "source": [
    "nn.learn(observed_arr=observed_arr, target_arr=observed_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "_ = plt.figure(figsize=(20, 10))\n",
    "plt.plot(nn.verificatable_result.logs_df.train_loss.values, label=\"Train errors.\")\n",
    "plt.plot(nn.verificatable_result.logs_df.test_loss.values, label=\"Test errors.\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
