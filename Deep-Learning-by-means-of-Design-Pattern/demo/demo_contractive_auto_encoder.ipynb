{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pydbm.nn.simpleautoencoder.contractive_auto_encoder import ContractiveAutoEncoder\n",
    "from pydbm.nn.neural_network import NeuralNetwork as Encoder\n",
    "from pydbm.nn.neural_network import NeuralNetwork as Decoder\n",
    "from pydbm.nn.nn_layer import NNLayer as EncoderLayer\n",
    "from pydbm.nn.nn_layer import NNLayer as DecoderLayer\n",
    "from pydbm.activation.relu_function import ReLuFunction\n",
    "from pydbm.activation.tanh_function import TanhFunction\n",
    "from pydbm.activation.identity_function import IdentityFunction\n",
    "from pydbm.activation.logistic_function import LogisticFunction\n",
    "from pydbm.loss.mean_squared_error import MeanSquaredError\n",
    "from pydbm.optimization.optparams.adam import Adam\n",
    "from pydbm.synapse.nn_graph import NNGraph as EncoderGraph\n",
    "from pydbm.synapse.nn_graph import NNGraph as DecoderGraph\n",
    "from pydbm.verification.verificate_function_approximation import VerificateFunctionApproximation\n",
    "from pydbm.optimization.batch_norm import BatchNorm\n",
    "\n",
    "from logging import getLogger, StreamHandler, NullHandler, DEBUG, ERROR\n",
    "\n",
    "logger = getLogger(\"pydbm\")\n",
    "handler = StreamHandler()\n",
    "handler.setLevel(DEBUG)\n",
    "logger.setLevel(DEBUG)\n",
    "logger.addHandler(handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1000\n",
    "batch_size = 20\n",
    "dim1 = 100\n",
    "dim2 = 500\n",
    "scale = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_activation_function = LogisticFunction()\n",
    "#encoder_activation_function.batch_norm = BatchNorm()\n",
    "decoder_activation_function = IdentityFunction()\n",
    "#decoder_activation_function.batch_norm = BatchNorm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setup NN layers and the parameters.\n"
     ]
    }
   ],
   "source": [
    "encoder_layer = EncoderLayer(\n",
    "    EncoderGraph(\n",
    "        activation_function=encoder_activation_function,\n",
    "        hidden_neuron_count=dim1,\n",
    "        output_neuron_count=dim2,\n",
    "        scale=scale,\n",
    "    )\n",
    ")\n",
    "\n",
    "opt_params = Adam()\n",
    "#opt_params.dropout_rate = 0.0\n",
    "\n",
    "encoder = Encoder(\n",
    "    nn_layer_list=[\n",
    "        encoder_layer, \n",
    "    ],\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=1e-01,\n",
    "    learning_attenuate_rate=0.1,\n",
    "    attenuate_epoch=50,\n",
    "    computable_loss=MeanSquaredError(grad_clip_threshold=1e+10),\n",
    "    opt_params=opt_params,\n",
    "    verificatable_result=VerificateFunctionApproximation(),\n",
    "    test_size_rate=0.3,\n",
    "    tol=1e-15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setup NN layers and the parameters.\n"
     ]
    }
   ],
   "source": [
    "decoder_layer = DecoderLayer(\n",
    "    DecoderGraph(\n",
    "        activation_function=decoder_activation_function,\n",
    "        hidden_neuron_count=dim2,\n",
    "        output_neuron_count=dim1,\n",
    "        scale=scale,\n",
    "    )\n",
    ")\n",
    "\n",
    "opt_params = Adam()\n",
    "#opt_params.dropout_rate = 0.0\n",
    "\n",
    "decoder = Decoder(\n",
    "    nn_layer_list=[\n",
    "        decoder_layer, \n",
    "    ],\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=1e-01,\n",
    "    learning_attenuate_rate=0.1,\n",
    "    attenuate_epoch=50,\n",
    "    computable_loss=MeanSquaredError(grad_clip_threshold=1e+10),\n",
    "    opt_params=opt_params,\n",
    "    verificatable_result=VerificateFunctionApproximation(),\n",
    "    test_size_rate=0.3,\n",
    "    tol=1e-15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setup NN layers and the parameters.\n"
     ]
    }
   ],
   "source": [
    "auto_encoder = ContractiveAutoEncoder(\n",
    "    encoder=encoder,\n",
    "    decoder=decoder,\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    learning_rate=1e-01,\n",
    "    learning_attenuate_rate=0.1,\n",
    "    attenuate_epoch=50,\n",
    "    computable_loss=MeanSquaredError(grad_clip_threshold=1e+10),\n",
    "    verificatable_result=VerificateFunctionApproximation(),\n",
    "    test_size_rate=0.3,\n",
    "    tol=1e-15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "observed_arr = np.random.normal(loc=0.0, scale=1.0, size=(1000, dim1))\n",
    "observed_arr = (observed_arr - observed_arr.mean()) / (observed_arr.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive hyperparameter that controls the strength of the regularization.\n",
    "auto_encoder.penalty_lambda = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NN starts learning.\n",
      "Best params are updated.\n",
      "Epoch: 1\n",
      "Loss: \n",
      "Training: 1.0109637921539332 Test: 2.9988740503081046\n",
      "Epoch: 2\n",
      "Loss: \n",
      "Training: 4.8112667216549765 Test: 1.6078176565910307\n",
      "Epoch: 3\n",
      "Loss: \n",
      "Training: 2.2875213321193444 Test: 2.727648948782597\n",
      "Epoch: 4\n",
      "Loss: \n",
      "Training: 3.926163679265387 Test: 3.1552533100205555\n",
      "Epoch: 5\n",
      "Loss: \n",
      "Training: 3.717500885842884 Test: 2.440209328633132\n",
      "Epoch: 6\n",
      "Loss: \n",
      "Training: 4.175081186522586 Test: 2.3039100425678987\n",
      "Epoch: 7\n",
      "Loss: \n",
      "Training: 4.256334290505235 Test: 1.602721989016256\n",
      "Epoch: 8\n",
      "Loss: \n",
      "Training: 2.2895441933656975 Test: 2.2033187316992917\n",
      "Epoch: 9\n",
      "Loss: \n",
      "Training: 3.8474977824596133 Test: 2.08558579231004\n",
      "Epoch: 10\n",
      "Loss: \n",
      "Training: 2.765938322777338 Test: 1.8249645490259994\n",
      "Epoch: 11\n",
      "Loss: \n",
      "Training: 3.3369826813695393 Test: 1.7583570357291538\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3087812186666996 Test: 2.2950304398954904\n",
      "Epoch: 12\n",
      "Loss: \n",
      "Training: 2.3017921391392226 Test: 2.177493446197474\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.5413831075882607 Test: 2.170978738437596\n",
      "Epoch: 13\n",
      "Loss: \n",
      "Training: 3.9065682692856414 Test: 2.190177899810806\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.290435649336685 Test: 2.22794631739824\n",
      "Epoch: 14\n",
      "Loss: \n",
      "Training: 3.3714665956309045 Test: 1.8740277932438025\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.452340343053314 Test: 2.1741992125010605\n",
      "Epoch: 15\n",
      "Loss: \n",
      "Training: 2.891007851557168 Test: 1.5671836882376815\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.3968706346898663 Test: 2.046076660823385\n",
      "Epoch: 16\n",
      "Loss: \n",
      "Training: 2.4796215464752103 Test: 1.635298131792811\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.314221331261295 Test: 1.95877409678384\n",
      "Epoch: 17\n",
      "Loss: \n",
      "Training: 2.2057235602339516 Test: 1.7929179425110642\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.1446753672565575 Test: 1.8919129057063315\n",
      "Epoch: 18\n",
      "Loss: \n",
      "Training: 3.336116657463654 Test: 1.5907126813279766\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.939614294229429 Test: 1.9109325010558122\n",
      "Epoch: 19\n",
      "Loss: \n",
      "Training: 2.6541525640629127 Test: 1.4801428061558077\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 3.044271540639225 Test: 1.8496718960186809\n",
      "Epoch: 20\n",
      "Loss: \n",
      "Training: 2.483002692591931 Test: 1.6386945688940737\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.9249370187995547 Test: 1.7891275974032577\n",
      "Epoch: 21\n",
      "Loss: \n",
      "Training: 2.617017774062702 Test: 1.7256006311161176\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.896643455781014 Test: 1.7705005993900655\n",
      "Epoch: 22\n",
      "Loss: \n",
      "Training: 2.7342170279179183 Test: 1.6819255253080512\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.82464696505033 Test: 1.7672249589287616\n",
      "Epoch: 23\n",
      "Loss: \n",
      "Training: 2.360570781421792 Test: 1.860252268593242\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.8678894539281994 Test: 1.7176681668398195\n",
      "Epoch: 24\n",
      "Loss: \n",
      "Training: 3.2218578403593163 Test: 1.8039464526893163\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7132897051418143 Test: 1.684675603718063\n",
      "Epoch: 25\n",
      "Loss: \n",
      "Training: 2.734454362887756 Test: 1.4135166751979547\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.6983288296146553 Test: 1.6776674696626142\n",
      "Epoch: 26\n",
      "Loss: \n",
      "Training: 2.141028341728849 Test: 1.5798182905783311\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.6826734807477144 Test: 1.6623007683586415\n",
      "Epoch: 27\n",
      "Loss: \n",
      "Training: 2.597245930824113 Test: 1.531271894086528\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.6488141602730786 Test: 1.6567527842371939\n",
      "Epoch: 28\n",
      "Loss: \n",
      "Training: 2.4730830009717084 Test: 1.583515991651724\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.687966397332094 Test: 1.6305881793947399\n",
      "Epoch: 29\n",
      "Loss: \n",
      "Training: 2.471127041777714 Test: 1.5542937197257383\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.6016630316828997 Test: 1.6298685104271147\n",
      "Epoch: 30\n",
      "Loss: \n",
      "Training: 2.995208257604796 Test: 1.563363908846899\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.58336047945438 Test: 1.6372836017841077\n",
      "Epoch: 31\n",
      "Loss: \n",
      "Training: 2.8821653330033294 Test: 1.32777247045956\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.6345810359556667 Test: 1.6297505357793902\n",
      "Epoch: 32\n",
      "Loss: \n",
      "Training: 2.4879226897513416 Test: 1.430738947868018\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.6610957918497293 Test: 1.5899677197137345\n",
      "Epoch: 33\n",
      "Loss: \n",
      "Training: 2.522822686236669 Test: 1.6501228905532606\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.636466358033071 Test: 1.5648490619697313\n",
      "Epoch: 34\n",
      "Loss: \n",
      "Training: 2.845615409967539 Test: 1.605364024480909\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.652691548514559 Test: 1.543836124165733\n",
      "Epoch: 35\n",
      "Loss: \n",
      "Training: 2.527418946382462 Test: 1.7186698420648985\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.6150673054753817 Test: 1.5239778813448923\n",
      "Epoch: 36\n",
      "Loss: \n",
      "Training: 2.6448935394294475 Test: 1.941144205662146\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.5943637638248527 Test: 1.5544931980315868\n",
      "Epoch: 37\n",
      "Loss: \n",
      "Training: 3.3451886827062154 Test: 1.4272866818271672\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.644750283594912 Test: 1.5906257895399682\n",
      "Epoch: 38\n",
      "Loss: \n",
      "Training: 2.748922062771569 Test: 1.2536035773675893\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.719544558783122 Test: 1.5802272683140322\n",
      "Epoch: 39\n",
      "Loss: \n",
      "Training: 2.209006642909728 Test: 1.3986698634400874\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.747128464963108 Test: 1.5472360268856185\n",
      "Epoch: 40\n",
      "Loss: \n",
      "Training: 2.1951401170293803 Test: 1.7263570941282425\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7209164250763096 Test: 1.5316736412570535\n",
      "Epoch: 41\n",
      "Loss: \n",
      "Training: 2.5191528688340377 Test: 1.5931121048780066\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.640909611018768 Test: 1.547972959785188\n",
      "Epoch: 42\n",
      "Loss: \n",
      "Training: 3.254212789772105 Test: 1.4551901957223736\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.604608364601839 Test: 1.5745069232270326\n",
      "Epoch: 43\n",
      "Loss: \n",
      "Training: 2.4252660973892755 Test: 1.6268271518304673\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.6812373746039153 Test: 1.5769520480124684\n",
      "Epoch: 44\n",
      "Loss: \n",
      "Training: 2.7982126187317835 Test: 1.5184476259745985\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.6714817157191755 Test: 1.5746224741401886\n",
      "Epoch: 45\n",
      "Loss: \n",
      "Training: 2.784209999341604 Test: 1.5308239239965309\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.6667414365956006 Test: 1.5659308342895577\n",
      "Epoch: 46\n",
      "Loss: \n",
      "Training: 2.734650389127157 Test: 1.4122521066382188\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.692420541891515 Test: 1.547146242482721\n",
      "Epoch: 47\n",
      "Loss: \n",
      "Training: 2.420916726275216 Test: 1.2662250979529592\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.701396226861286 Test: 1.4942570325803282\n",
      "Epoch: 48\n",
      "Loss: \n",
      "Training: 3.0645046465082038 Test: 1.498607383105932\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.6089690312181855 Test: 1.4781508741929072\n",
      "Epoch: 49\n",
      "Loss: \n",
      "Training: 2.5030635755007307 Test: 1.5321774242702169\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.640527289591849 Test: 1.5026512547667417\n",
      "Epoch: 50\n",
      "Loss: \n",
      "Training: 2.488560274866497 Test: 1.4150434668524374\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.6699329828509493 Test: 1.5160020108497547\n",
      "Epoch: 51\n",
      "Loss: \n",
      "Training: 3.3945111950976115 Test: 1.5778476274000526\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.699274998634661 Test: 1.4848706481221743\n",
      "Epoch: 52\n",
      "Loss: \n",
      "Training: 3.1456842161660914 Test: 1.337018941422445\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7868108312610183 Test: 1.4833442003743786\n",
      "Epoch: 53\n",
      "Loss: \n",
      "Training: 2.253888042815659 Test: 1.1771395648090652\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.775957973900417 Test: 1.4715270749443856\n",
      "Epoch: 54\n",
      "Loss: \n",
      "Training: 2.1745624174494065 Test: 1.1197191320510338\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.7588201684430556 Test: 1.4265583162422453\n",
      "Epoch: 55\n",
      "Loss: \n",
      "Training: 1.8253153974096352 Test: 1.2302074951945254\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.6964551483148176 Test: 1.386685466849889\n",
      "Epoch: 56\n",
      "Loss: \n",
      "Training: 2.092755139035159 Test: 1.0993355469769814\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.6005656881216215 Test: 1.3566238239696884\n",
      "Epoch: 57\n",
      "Loss: \n",
      "Training: 2.166900544785753 Test: 1.1896353096707235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.536376163112421 Test: 1.3253321680035648\n",
      "Epoch: 58\n",
      "Loss: \n",
      "Training: 1.8316827798743927 Test: 1.215012860126588\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.5109745449634753 Test: 1.3176731891753413\n",
      "Epoch: 59\n",
      "Loss: \n",
      "Training: 2.1440900138069083 Test: 1.2516446795284324\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.387692358300094 Test: 1.2893137368774068\n",
      "Epoch: 60\n",
      "Loss: \n",
      "Training: 2.4820760765050065 Test: 1.2866037670093837\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.3517950021307117 Test: 1.2612604624032286\n",
      "Epoch: 61\n",
      "Loss: \n",
      "Training: 2.1002945552809416 Test: 1.1994002946318663\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.3511465822945623 Test: 1.2484164924189232\n",
      "Epoch: 62\n",
      "Loss: \n",
      "Training: 2.091824189350946 Test: 1.2236930163190145\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.2217249183128955 Test: 1.2105717591421046\n",
      "Epoch: 63\n",
      "Loss: \n",
      "Training: 2.394440962116331 Test: 1.1611455608993142\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.1163389156313808 Test: 1.1992391666317614\n",
      "Epoch: 64\n",
      "Loss: \n",
      "Training: 2.1267452438180303 Test: 1.2018464865950127\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.130394207561448 Test: 1.1976397662407863\n",
      "Epoch: 65\n",
      "Loss: \n",
      "Training: 1.9870896431870402 Test: 1.132469214312952\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.12561249019831 Test: 1.2058525016951842\n",
      "Epoch: 66\n",
      "Loss: \n",
      "Training: 1.9512496071866683 Test: 1.1446736052897122\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.1417899147760506 Test: 1.1960786736070268\n",
      "Epoch: 67\n",
      "Loss: \n",
      "Training: 1.680872223978617 Test: 1.1145072270717105\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.1276393615912017 Test: 1.2006124794383\n",
      "Epoch: 68\n",
      "Loss: \n",
      "Training: 2.078250887263892 Test: 1.0898196606164288\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.0790365295104882 Test: 1.1930996711783988\n",
      "Epoch: 69\n",
      "Loss: \n",
      "Training: 1.7836161432229978 Test: 1.1305442976469817\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.103693340249438 Test: 1.1805803512273827\n",
      "Epoch: 70\n",
      "Loss: \n",
      "Training: 2.1125842309453593 Test: 1.3315067550646862\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.0676459531910467 Test: 1.1684703130392378\n",
      "Epoch: 71\n",
      "Loss: \n",
      "Training: 2.3191114793293695 Test: 1.1760809696394208\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.030696768635082 Test: 1.172960611844768\n",
      "Epoch: 72\n",
      "Loss: \n",
      "Training: 2.1999331997115212 Test: 1.1554889036141722\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.052578461039925 Test: 1.1706286793455232\n",
      "Epoch: 73\n",
      "Loss: \n",
      "Training: 2.0380539165363283 Test: 1.1919248149017212\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.0633893620759824 Test: 1.163808268075039\n",
      "Epoch: 74\n",
      "Loss: \n",
      "Training: 1.9724363367219198 Test: 1.1166576069864083\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.027750657517982 Test: 1.1668861934752797\n",
      "Epoch: 75\n",
      "Loss: \n",
      "Training: 1.8803859168289991 Test: 1.1903218145175078\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.012319766808371 Test: 1.1583673055144195\n",
      "Epoch: 76\n",
      "Loss: \n",
      "Training: 1.8758363438395 Test: 1.1801990675214464\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.0016493941725675 Test: 1.164152565534875\n",
      "Epoch: 77\n",
      "Loss: \n",
      "Training: 2.151760865491724 Test: 1.2251010415107493\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9941080678378504 Test: 1.1677051117580484\n",
      "Epoch: 78\n",
      "Loss: \n",
      "Training: 2.123249593810902 Test: 1.1558584141470751\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.041196931989161 Test: 1.1787644932019523\n",
      "Epoch: 79\n",
      "Loss: \n",
      "Training: 1.9956557021083872 Test: 1.1531309689688227\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.0456968026438616 Test: 1.185368368555017\n",
      "Epoch: 80\n",
      "Loss: \n",
      "Training: 1.915567404047101 Test: 1.1413649847519372\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.066900758532401 Test: 1.1876270356872012\n",
      "Epoch: 81\n",
      "Loss: \n",
      "Training: 1.8176456090750073 Test: 1.1366825639832\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 2.0471990758425753 Test: 1.168612858655926\n",
      "Epoch: 82\n",
      "Loss: \n",
      "Training: 1.8137417579794228 Test: 1.1733042300055208\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.997052488817139 Test: 1.1646730180903038\n",
      "Epoch: 83\n",
      "Loss: \n",
      "Training: 1.8473980484191124 Test: 1.1071478715702952\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9584333446439288 Test: 1.1664545507294388\n",
      "Epoch: 84\n",
      "Loss: \n",
      "Training: 1.9929123753912237 Test: 1.1321304459710169\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9393677578322077 Test: 1.1579768563962962\n",
      "Epoch: 85\n",
      "Loss: \n",
      "Training: 1.6345606425108254 Test: 1.150140364553709\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.941415361699138 Test: 1.159524140294757\n",
      "Epoch: 86\n",
      "Loss: \n",
      "Training: 2.2521124516651536 Test: 1.0884698295607989\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9168328342673207 Test: 1.1555059952983773\n",
      "Epoch: 87\n",
      "Loss: \n",
      "Training: 1.767915062673746 Test: 1.1041524413846715\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.954460445049886 Test: 1.1463330715023123\n",
      "Epoch: 88\n",
      "Loss: \n",
      "Training: 2.3283247958056754 Test: 1.1739044168857018\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9160758647680882 Test: 1.1342382114897047\n",
      "Epoch: 89\n",
      "Loss: \n",
      "Training: 1.9051963221470911 Test: 1.1666721512498162\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9365833849675655 Test: 1.1360428117635675\n",
      "Epoch: 90\n",
      "Loss: \n",
      "Training: 1.8336609336651333 Test: 1.2325111506939925\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9275374469714357 Test: 1.1373969299916666\n",
      "Epoch: 91\n",
      "Loss: \n",
      "Training: 1.9407434679401332 Test: 1.0578350325300494\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9193467999332388 Test: 1.1465115465858724\n",
      "Epoch: 92\n",
      "Loss: \n",
      "Training: 1.6973176213067778 Test: 1.1593667967479446\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9316565858197516 Test: 1.1386267934405572\n",
      "Epoch: 93\n",
      "Loss: \n",
      "Training: 1.973644208338706 Test: 1.181067454464414\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9200141721524873 Test: 1.1372330501147996\n",
      "Epoch: 94\n",
      "Loss: \n",
      "Training: 1.8964008357787885 Test: 1.1850735275613893\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9326387881444465 Test: 1.1446250084042113\n",
      "Epoch: 95\n",
      "Loss: \n",
      "Training: 1.9885581463555955 Test: 1.1079027293972876\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9229876341832033 Test: 1.1499193165632486\n",
      "Epoch: 96\n",
      "Loss: \n",
      "Training: 1.8428830559100333 Test: 1.2320891888265235\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9583873845676798 Test: 1.1456955530476065\n",
      "Epoch: 97\n",
      "Loss: \n",
      "Training: 1.9304895476591637 Test: 1.1468735023562555\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9174644449921683 Test: 1.1600574889741793\n",
      "Epoch: 98\n",
      "Loss: \n",
      "Training: 1.7896385707062532 Test: 1.1030809006186078\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9337218934907099 Test: 1.1643295950713375\n",
      "Epoch: 99\n",
      "Loss: \n",
      "Training: 2.0960545259113355 Test: 1.1311426512444467\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8798532709807674 Test: 1.1572472434446281\n",
      "Epoch: 100\n",
      "Loss: \n",
      "Training: 1.9384741581873295 Test: 1.1908658025255805\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8989390913571917 Test: 1.1536942934440912\n",
      "Epoch: 101\n",
      "Loss: \n",
      "Training: 1.911083542311609 Test: 1.1122316822400193\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9094204138094117 Test: 1.14952975862725\n",
      "Epoch: 102\n",
      "Loss: \n",
      "Training: 1.8567633424899312 Test: 1.0952025714451556\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.906454421246559 Test: 1.154969423598247\n",
      "Epoch: 103\n",
      "Loss: \n",
      "Training: 1.7416547218327187 Test: 1.086182129078783\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9223989933648746 Test: 1.1485530010679679\n",
      "Epoch: 104\n",
      "Loss: \n",
      "Training: 1.8994332736044717 Test: 1.1486410840997856\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8992000447142758 Test: 1.1390644685294045\n",
      "Epoch: 105\n",
      "Loss: \n",
      "Training: 2.0084117742683594 Test: 1.0951422050238429\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8995032884968441 Test: 1.1354212241832446\n",
      "Epoch: 106\n",
      "Loss: \n",
      "Training: 1.658810875147226 Test: 1.1780143417230624\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9014886512881204 Test: 1.1341451717459\n",
      "Epoch: 107\n",
      "Loss: \n",
      "Training: 2.016354857454718 Test: 1.2207439211674396\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8830814332118397 Test: 1.128737687035554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 108\n",
      "Loss: \n",
      "Training: 1.8147922259325577 Test: 1.1712400805784113\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8916679641913952 Test: 1.1361247289166723\n",
      "Epoch: 109\n",
      "Loss: \n",
      "Training: 1.7541763778877244 Test: 1.1680133149185568\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8941833297140256 Test: 1.1429406469126526\n",
      "Epoch: 110\n",
      "Loss: \n",
      "Training: 1.6835905795468287 Test: 1.074901265967227\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.859995514911665 Test: 1.1466277132800635\n",
      "Epoch: 111\n",
      "Loss: \n",
      "Training: 1.73350397756325 Test: 1.0478176072744654\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8345071570476144 Test: 1.1350312596242285\n",
      "Epoch: 112\n",
      "Loss: \n",
      "Training: 2.063961493594944 Test: 1.1777072670484408\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8167492005727783 Test: 1.1285898521276732\n",
      "Epoch: 113\n",
      "Loss: \n",
      "Training: 1.84107275776106 Test: 1.1839979461539927\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8374690156832798 Test: 1.1368403216880014\n",
      "Epoch: 114\n",
      "Loss: \n",
      "Training: 1.5563303238247788 Test: 1.0961896208647564\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8474108192761143 Test: 1.1466219033955225\n",
      "Epoch: 115\n",
      "Loss: \n",
      "Training: 1.8988614249975035 Test: 1.0491504629288992\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8131005242981448 Test: 1.1413767570720195\n",
      "Epoch: 116\n",
      "Loss: \n",
      "Training: 1.9603946627857705 Test: 1.1467641710518834\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8021454893710591 Test: 1.1367775828625253\n",
      "Epoch: 117\n",
      "Loss: \n",
      "Training: 2.1555100253894723 Test: 1.092280151909361\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8323038681349135 Test: 1.1336525657954073\n",
      "Epoch: 118\n",
      "Loss: \n",
      "Training: 1.9896045113622236 Test: 1.117530150404797\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8462193849283888 Test: 1.1208061888695993\n",
      "Epoch: 119\n",
      "Loss: \n",
      "Training: 1.727047418930143 Test: 1.0792745568790578\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8637006134713556 Test: 1.1154351958522377\n",
      "Epoch: 120\n",
      "Loss: \n",
      "Training: 1.7238008193467895 Test: 1.08315601402233\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8609877175755976 Test: 1.106561320048288\n",
      "Epoch: 121\n",
      "Loss: \n",
      "Training: 2.0136464999421997 Test: 1.146460875535996\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8650087415555934 Test: 1.1073867948537985\n",
      "Epoch: 122\n",
      "Loss: \n",
      "Training: 1.7839140827904734 Test: 1.0391626002462655\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8930229937934886 Test: 1.1172511216799517\n",
      "Epoch: 123\n",
      "Loss: \n",
      "Training: 2.0622182746804447 Test: 1.173259092440592\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8650182527130414 Test: 1.103396654999734\n",
      "Epoch: 124\n",
      "Loss: \n",
      "Training: 1.9011880819030473 Test: 1.1802142194781469\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8871328044049798 Test: 1.102322769628394\n",
      "Epoch: 125\n",
      "Loss: \n",
      "Training: 1.8615873805579084 Test: 1.095390785013244\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9216185802128067 Test: 1.110725229489733\n",
      "Epoch: 126\n",
      "Loss: \n",
      "Training: 1.7163127765070578 Test: 1.0665655392950462\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9178911757688468 Test: 1.1153492616981673\n",
      "Epoch: 127\n",
      "Loss: \n",
      "Training: 1.6355516024353842 Test: 1.2135732959053416\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8934829871409757 Test: 1.1073293985224837\n",
      "Epoch: 128\n",
      "Loss: \n",
      "Training: 1.8094224455501775 Test: 1.2157662106939737\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.841487144845567 Test: 1.1194587129220817\n",
      "Epoch: 129\n",
      "Loss: \n",
      "Training: 1.7984128474123349 Test: 1.1125020432163866\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8234689382643623 Test: 1.1292823189509993\n",
      "Epoch: 130\n",
      "Loss: \n",
      "Training: 1.7492518170118616 Test: 1.1279140548240694\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8306054811125818 Test: 1.1326050675847321\n",
      "Epoch: 131\n",
      "Loss: \n",
      "Training: 1.7975320606011942 Test: 1.0476521388855167\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8331505808790887 Test: 1.1370808716649061\n",
      "Epoch: 132\n",
      "Loss: \n",
      "Training: 2.10242501590978 Test: 1.0900159438152857\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8115391369449885 Test: 1.1271999979998584\n",
      "Epoch: 133\n",
      "Loss: \n",
      "Training: 1.8640777208427926 Test: 1.0707835038008071\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8433902302569192 Test: 1.1322853323567603\n",
      "Epoch: 134\n",
      "Loss: \n",
      "Training: 2.0038285601487997 Test: 1.1206357559497016\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8235761748731538 Test: 1.122037773492782\n",
      "Epoch: 135\n",
      "Loss: \n",
      "Training: 1.9462552683591412 Test: 1.1183801018987074\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.833840222697729 Test: 1.1160799271399373\n",
      "Epoch: 136\n",
      "Loss: \n",
      "Training: 1.7812777424518145 Test: 1.0918769645383801\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8423070114778526 Test: 1.1183788588284838\n",
      "Epoch: 137\n",
      "Loss: \n",
      "Training: 1.8302211005080102 Test: 1.184712570608906\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8488035080723282 Test: 1.120910001352817\n",
      "Epoch: 138\n",
      "Loss: \n",
      "Training: 1.7112351658234608 Test: 1.123524957506744\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8682704578795906 Test: 1.1180239288231735\n",
      "Epoch: 139\n",
      "Loss: \n",
      "Training: 2.113961555517749 Test: 1.025109596029337\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.858451729906919 Test: 1.1087998035044504\n",
      "Epoch: 140\n",
      "Loss: \n",
      "Training: 1.8437450041012566 Test: 1.1071529717233\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8900066007174607 Test: 1.1000605587857453\n",
      "Epoch: 141\n",
      "Loss: \n",
      "Training: 1.7970041384506583 Test: 1.188747012618989\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8994559194264 Test: 1.0979844504756686\n",
      "Epoch: 142\n",
      "Loss: \n",
      "Training: 1.619770038702327 Test: 1.0882684858162488\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.899403127211346 Test: 1.1120939378490158\n",
      "Epoch: 143\n",
      "Loss: \n",
      "Training: 1.8432644554865343 Test: 1.0741381782325614\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8511376294906008 Test: 1.1119191920491123\n",
      "Epoch: 144\n",
      "Loss: \n",
      "Training: 1.825659556094497 Test: 1.0791205729230031\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8490563029549751 Test: 1.1122546594922875\n",
      "Epoch: 145\n",
      "Loss: \n",
      "Training: 1.6836891539653172 Test: 1.048188670784103\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8312394025495446 Test: 1.1081031411896176\n",
      "Epoch: 146\n",
      "Loss: \n",
      "Training: 1.5644710403419138 Test: 1.0687918458933021\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8049827911101626 Test: 1.1010839980781573\n",
      "Epoch: 147\n",
      "Loss: \n",
      "Training: 1.7412150375715743 Test: 1.1413382645330266\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7833021208991724 Test: 1.0987754862136494\n",
      "Epoch: 148\n",
      "Loss: \n",
      "Training: 1.828341838796363 Test: 1.074588650955188\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.774401514605529 Test: 1.0944380556060616\n",
      "Epoch: 149\n",
      "Loss: \n",
      "Training: 1.7989443822949733 Test: 1.0645799688400148\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7861121819028192 Test: 1.0895444249509059\n",
      "Epoch: 150\n",
      "Loss: \n",
      "Training: 2.0539420458885482 Test: 1.105665170595691\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7546104645805414 Test: 1.0934914622319738\n",
      "Epoch: 151\n",
      "Loss: \n",
      "Training: 1.8796809731968436 Test: 1.1105619122992598\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7756301687592704 Test: 1.093342682119213\n",
      "Epoch: 152\n",
      "Loss: \n",
      "Training: 1.899375206231901 Test: 1.0653361716914413\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.783897852233889 Test: 1.08552417208724\n",
      "Epoch: 153\n",
      "Loss: \n",
      "Training: 1.8506978244368502 Test: 1.0761907234951542\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8118583689868466 Test: 1.0832309406747591\n",
      "Epoch: 154\n",
      "Loss: \n",
      "Training: 1.8828454757906956 Test: 1.1082561712717673\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8126017058818782 Test: 1.0834361952010185\n",
      "Epoch: 155\n",
      "Loss: \n",
      "Training: 1.870505044431808 Test: 1.140941058535853\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.818320297851498 Test: 1.0863497550358947\n",
      "Epoch: 156\n",
      "Loss: \n",
      "Training: 1.8951844710953707 Test: 1.0911293552767334\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8370018868981473 Test: 1.0956249938110698\n",
      "Epoch: 157\n",
      "Loss: \n",
      "Training: 1.6374639721125017 Test: 1.0538861198156115\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8700732299734928 Test: 1.0978587447494128\n",
      "Epoch: 158\n",
      "Loss: \n",
      "Training: 1.7425357652524665 Test: 1.0674679626014363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8596981234275856 Test: 1.0891135302776713\n",
      "Epoch: 159\n",
      "Loss: \n",
      "Training: 1.8188581676406939 Test: 1.0250638390228528\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8511175160731959 Test: 1.0884014614422963\n",
      "Epoch: 160\n",
      "Loss: \n",
      "Training: 1.5191998281295505 Test: 1.0332622963462805\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.853108894607768 Test: 1.08444984846058\n",
      "Epoch: 161\n",
      "Loss: \n",
      "Training: 1.7553170197431043 Test: 1.1053048762290152\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7996346728318682 Test: 1.0772095610356391\n",
      "Epoch: 162\n",
      "Loss: \n",
      "Training: 1.7934275719229094 Test: 1.0715907761901862\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7871982774864938 Test: 1.0766838574286146\n",
      "Epoch: 163\n",
      "Loss: \n",
      "Training: 1.7862795728549061 Test: 1.155845471353581\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7766035140555954 Test: 1.077309317878489\n",
      "Epoch: 164\n",
      "Loss: \n",
      "Training: 1.6833870607933965 Test: 1.1296240710217773\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7701616888974008 Test: 1.085274792664332\n",
      "Epoch: 165\n",
      "Loss: \n",
      "Training: 1.7969426557234396 Test: 1.1538614657739261\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.750215847397671 Test: 1.0874115826393325\n",
      "Epoch: 166\n",
      "Loss: \n",
      "Training: 1.6045250690863886 Test: 1.105688120838334\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.742859608526834 Test: 1.08870362336314\n",
      "Epoch: 167\n",
      "Loss: \n",
      "Training: 2.028802526578494 Test: 1.043962052819701\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7137936683259354 Test: 1.0901594999193\n",
      "Epoch: 168\n",
      "Loss: \n",
      "Training: 1.751862940780203 Test: 1.143004570884089\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7529275237725348 Test: 1.089167093219709\n",
      "Epoch: 169\n",
      "Loss: \n",
      "Training: 1.7553347575375629 Test: 1.16272792963513\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7538602413253088 Test: 1.0967207540479744\n",
      "Epoch: 170\n",
      "Loss: \n",
      "Training: 1.9297259535700737 Test: 1.121889285411208\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7475079003149954 Test: 1.1104871631092021\n",
      "Epoch: 171\n",
      "Loss: \n",
      "Training: 1.809568160515756 Test: 1.1028533107952405\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7885605128590476 Test: 1.1193498620156948\n",
      "Epoch: 172\n",
      "Loss: \n",
      "Training: 1.7972279528668467 Test: 1.1681502630045362\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.793985626936313 Test: 1.119104705472317\n",
      "Epoch: 173\n",
      "Loss: \n",
      "Training: 1.5053957362957098 Test: 1.0887439703480923\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.794365665030707 Test: 1.1287606541537523\n",
      "Epoch: 174\n",
      "Loss: \n",
      "Training: 1.9760291536368608 Test: 1.1468751263711419\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7662772813747871 Test: 1.1220505040532034\n",
      "Epoch: 175\n",
      "Loss: \n",
      "Training: 1.7414401308933065 Test: 1.0568879525146058\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7955414906591336 Test: 1.12377560958814\n",
      "Epoch: 176\n",
      "Loss: \n",
      "Training: 1.7562093393745177 Test: 1.0511229315229764\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.78999123817612 Test: 1.1140782582622077\n",
      "Epoch: 177\n",
      "Loss: \n",
      "Training: 1.6724407615701657 Test: 1.053193681065728\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.805159665204933 Test: 1.108621739330672\n",
      "Epoch: 178\n",
      "Loss: \n",
      "Training: 1.9991383754343244 Test: 1.0873452068349836\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7695234887041 Test: 1.109544902155275\n",
      "Epoch: 179\n",
      "Loss: \n",
      "Training: 1.8185084309478536 Test: 1.0691560069936255\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7942510321695124 Test: 1.1039789657503642\n",
      "Epoch: 180\n",
      "Loss: \n",
      "Training: 1.9979960057420671 Test: 1.0985862132825845\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8005683995105415 Test: 1.0946217734862138\n",
      "Epoch: 181\n",
      "Loss: \n",
      "Training: 1.7800611775115103 Test: 1.06230572932747\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8073954047277407 Test: 1.0922914662733514\n",
      "Epoch: 182\n",
      "Loss: \n",
      "Training: 1.9211613143084798 Test: 1.0672267648398488\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8044447064273161 Test: 1.0882367081265745\n",
      "Epoch: 183\n",
      "Loss: \n",
      "Training: 1.9574296046521322 Test: 1.1520977960461296\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8168380425714798 Test: 1.0781443583101056\n",
      "Epoch: 184\n",
      "Loss: \n",
      "Training: 2.067584997606036 Test: 1.0785456310196222\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8620414294071217 Test: 1.0844797408799094\n",
      "Epoch: 185\n",
      "Loss: \n",
      "Training: 1.629576771095043 Test: 1.0822047452267807\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8711970138040392 Test: 1.0776467913447574\n",
      "Epoch: 186\n",
      "Loss: \n",
      "Training: 1.7115046666354046 Test: 1.0526897640764727\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.860010677824213 Test: 1.080178470615975\n",
      "Epoch: 187\n",
      "Loss: \n",
      "Training: 1.8707095188171032 Test: 1.0960328375663229\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8555402105503016 Test: 1.0803351538713246\n",
      "Epoch: 188\n",
      "Loss: \n",
      "Training: 1.6934022165030622 Test: 1.0538379878133102\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8753670862749956 Test: 1.0846190695213842\n",
      "Epoch: 189\n",
      "Loss: \n",
      "Training: 1.582956135084914 Test: 1.0772073336759742\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8447934703818691 Test: 1.0812683476192169\n",
      "Epoch: 190\n",
      "Loss: \n",
      "Training: 1.656888041534614 Test: 1.0451545027707154\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8212382407955752 Test: 1.0820734802874514\n",
      "Epoch: 191\n",
      "Loss: \n",
      "Training: 1.7403990273179581 Test: 1.2055452731496024\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7871274443748297 Test: 1.0767303092362648\n",
      "Epoch: 192\n",
      "Loss: \n",
      "Training: 1.557070201296833 Test: 1.0431031116849694\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7831612293554748 Test: 1.091054263618478\n",
      "Epoch: 193\n",
      "Loss: \n",
      "Training: 1.7546190319565946 Test: 1.1456654705704281\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7467521180543097 Test: 1.08864189830299\n",
      "Epoch: 194\n",
      "Loss: \n",
      "Training: 1.6251195806848333 Test: 1.0721606468565583\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7264710607847562 Test: 1.0879986657554197\n",
      "Epoch: 195\n",
      "Loss: \n",
      "Training: 2.0637128932902415 Test: 1.0577953786803795\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.682224519092636 Test: 1.0873601673391133\n",
      "Epoch: 196\n",
      "Loss: \n",
      "Training: 1.8221500340478096 Test: 0.9703595848803972\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7256381313121558 Test: 1.084919230684473\n",
      "Epoch: 197\n",
      "Loss: \n",
      "Training: 1.6479144034786983 Test: 1.1325056775271292\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7367026680533963 Test: 1.0766862127648658\n",
      "Epoch: 198\n",
      "Loss: \n",
      "Training: 1.5850637494992534 Test: 1.0541427013532378\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7144231565195558 Test: 1.0803334967609464\n",
      "Epoch: 199\n",
      "Loss: \n",
      "Training: 1.8069831476911082 Test: 1.0752739809990821\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7035893098191746 Test: 1.080363968114939\n",
      "Epoch: 200\n",
      "Loss: \n",
      "Training: 1.786892094705478 Test: 1.0011515849955184\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7259920110797942 Test: 1.08017063284725\n",
      "Epoch: 201\n",
      "Loss: \n",
      "Training: 1.7230700188672312 Test: 1.1282719636288883\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7389924163968806 Test: 1.0757703410697304\n",
      "Epoch: 202\n",
      "Loss: \n",
      "Training: 1.6619428038637405 Test: 1.0501478031422482\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7372595155518085 Test: 1.0680430101176588\n",
      "Epoch: 203\n",
      "Loss: \n",
      "Training: 1.92721387055903 Test: 1.0864141195117103\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7477467758084988 Test: 1.0687474792633869\n",
      "Epoch: 204\n",
      "Loss: \n",
      "Training: 1.8059128382752896 Test: 1.1334506560549977\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7650062596687424 Test: 1.062822344157515\n",
      "Epoch: 205\n",
      "Loss: \n",
      "Training: 1.6748680553924544 Test: 1.0942574468985977\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7830855854277883 Test: 1.068951345077359\n",
      "Epoch: 206\n",
      "Loss: \n",
      "Training: 1.6128857329694726 Test: 1.054948895026042\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7442011016380092 Test: 1.0725975518991808\n",
      "Epoch: 207\n",
      "Loss: \n",
      "Training: 2.01407424926621 Test: 1.1188969892405198\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7232746715301759 Test: 1.0810564829137452\n",
      "Epoch: 208\n",
      "Loss: \n",
      "Training: 1.712662121558376 Test: 1.1679104147410007\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.759890656108927 Test: 1.0796956140850844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 209\n",
      "Loss: \n",
      "Training: 1.901031299795968 Test: 1.1033507395839441\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.772650493314839 Test: 1.0910723854238604\n",
      "Epoch: 210\n",
      "Loss: \n",
      "Training: 1.8236190555799547 Test: 1.1052749915302302\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7820553085253252 Test: 1.0938800612823467\n",
      "Epoch: 211\n",
      "Loss: \n",
      "Training: 1.741453703063936 Test: 1.030108819286197\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7857280046127726 Test: 1.1042924019358178\n",
      "Epoch: 212\n",
      "Loss: \n",
      "Training: 1.9250920391587885 Test: 1.1205816251725351\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.787566373032443 Test: 1.094476087501549\n",
      "Epoch: 213\n",
      "Loss: \n",
      "Training: 1.759332222681889 Test: 1.050444877819446\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.813881296561948 Test: 1.1015194697045776\n",
      "Epoch: 214\n",
      "Loss: \n",
      "Training: 1.690472481988618 Test: 1.033935603071346\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7970931317742334 Test: 1.0979225455353512\n",
      "Epoch: 215\n",
      "Loss: \n",
      "Training: 1.8138843014958144 Test: 1.1335353944044706\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7855490961455665 Test: 1.0879710402369858\n",
      "Epoch: 216\n",
      "Loss: \n",
      "Training: 1.832075515463347 Test: 1.0788130397359805\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7994507207559027 Test: 1.0918988349875731\n",
      "Epoch: 217\n",
      "Loss: \n",
      "Training: 1.7289119010797982 Test: 1.0257754775597865\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8213696990052903 Test: 1.0942852494585669\n",
      "Epoch: 218\n",
      "Loss: \n",
      "Training: 1.6996407401294773 Test: 1.0851374681965646\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7928534641866487 Test: 1.0849730982904937\n",
      "Epoch: 219\n",
      "Loss: \n",
      "Training: 1.746073640011431 Test: 1.0666543854743817\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7915513260437592 Test: 1.0766958036360499\n",
      "Epoch: 220\n",
      "Loss: \n",
      "Training: 1.8777099778725814 Test: 1.1106433537191516\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7760555600653052 Test: 1.073026168225094\n",
      "Epoch: 221\n",
      "Loss: \n",
      "Training: 1.8933693661327278 Test: 1.1098476659225625\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7814646522945679 Test: 1.0735630044439861\n",
      "Epoch: 222\n",
      "Loss: \n",
      "Training: 1.8666766610847512 Test: 1.0455890480836894\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7966562186014472 Test: 1.0815368891076225\n",
      "Epoch: 223\n",
      "Loss: \n",
      "Training: 1.746598294933571 Test: 1.1446066558435621\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7908146807940433 Test: 1.0740376313987379\n",
      "Epoch: 224\n",
      "Loss: \n",
      "Training: 1.6126613406661112 Test: 1.086841368454262\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7895412880192114 Test: 1.0834538092011496\n",
      "Epoch: 225\n",
      "Loss: \n",
      "Training: 1.687797174558 Test: 1.103398989100035\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7817601738869613 Test: 1.0887443857394412\n",
      "Epoch: 226\n",
      "Loss: \n",
      "Training: 1.7189287907626376 Test: 1.0446287586367453\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7691514611931798 Test: 1.0857307452089977\n",
      "Epoch: 227\n",
      "Loss: \n",
      "Training: 1.666595953445132 Test: 1.1348515944168893\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7578367887231088 Test: 1.0823123170990743\n",
      "Epoch: 228\n",
      "Loss: \n",
      "Training: 1.9402098291034835 Test: 1.0643848377572176\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7516051939596422 Test: 1.0932199287847844\n",
      "Epoch: 229\n",
      "Loss: \n",
      "Training: 1.592852635070018 Test: 1.0454195452368549\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7756621028570425 Test: 1.0911446657408497\n",
      "Epoch: 230\n",
      "Loss: \n",
      "Training: 1.6516382501456788 Test: 1.1191484349593965\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.760340002362901 Test: 1.089021181717097\n",
      "Epoch: 231\n",
      "Loss: \n",
      "Training: 1.5152017319999236 Test: 1.113684429477492\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7377328295902115 Test: 1.0898716898411216\n",
      "Epoch: 232\n",
      "Loss: \n",
      "Training: 1.6495072743055466 Test: 1.091777968599345\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.6999160661769306 Test: 1.0902553661966146\n",
      "Epoch: 233\n",
      "Loss: \n",
      "Training: 1.7621548986962308 Test: 1.036720292576179\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.6781991274990102 Test: 1.0948742582481799\n",
      "Epoch: 234\n",
      "Loss: \n",
      "Training: 1.649360579107001 Test: 1.05397874014098\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.6797547878752763 Test: 1.0840856219214419\n",
      "Epoch: 235\n",
      "Loss: \n",
      "Training: 1.7078307406270363 Test: 1.154108286713386\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.6834247117193653 Test: 1.0807993590901135\n",
      "Epoch: 236\n",
      "Loss: \n",
      "Training: 1.7909149121864676 Test: 1.1316733407008575\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.6854280683262686 Test: 1.0858702888514487\n",
      "Epoch: 237\n",
      "Loss: \n",
      "Training: 1.787259859301829 Test: 1.0489351099907431\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.692626680468652 Test: 1.0945747470578597\n",
      "Epoch: 238\n",
      "Loss: \n",
      "Training: 1.709236146128812 Test: 1.0137584558630988\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7046930710543216 Test: 1.0859830986152452\n",
      "Epoch: 239\n",
      "Loss: \n",
      "Training: 1.6396093806699723 Test: 1.1450807270081673\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.6815957027568544 Test: 1.0809204604258333\n",
      "Epoch: 240\n",
      "Loss: \n",
      "Training: 1.6291985336454584 Test: 1.1409906009974495\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.6862713773168498 Test: 1.0908865786029647\n",
      "Epoch: 241\n",
      "Loss: \n",
      "Training: 1.6245887877645047 Test: 1.0991929927050361\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.6840274056668278 Test: 1.0930707952067698\n",
      "Epoch: 242\n",
      "Loss: \n",
      "Training: 1.6959176847069461 Test: 1.0866635554802069\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.694966111243286 Test: 1.0916216515295243\n",
      "Epoch: 243\n",
      "Loss: \n",
      "Training: 1.59908182975326 Test: 1.1146497568462368\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.6996071522834257 Test: 1.0911102102176105\n",
      "Epoch: 244\n",
      "Loss: \n",
      "Training: 1.87924393913637 Test: 1.0423864544744375\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.6832998453891288 Test: 1.0989031566446164\n",
      "Epoch: 245\n",
      "Loss: \n",
      "Training: 1.7701932409821766 Test: 1.0724821364131467\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7062881813920658 Test: 1.097743928077962\n",
      "Epoch: 246\n",
      "Loss: \n",
      "Training: 1.7385349881712604 Test: 1.1097279503329263\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7125244314275796 Test: 1.0895813130479381\n",
      "Epoch: 247\n",
      "Loss: \n",
      "Training: 1.9473461439002022 Test: 1.0732214467625796\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7072864390260591 Test: 1.087386774011145\n",
      "Epoch: 248\n",
      "Loss: \n",
      "Training: 1.9222402725084162 Test: 1.0792661999632758\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7232950674858962 Test: 1.0898154076883286\n",
      "Epoch: 249\n",
      "Loss: \n",
      "Training: 1.7756495393011278 Test: 1.0978163491284354\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7445954801238563 Test: 1.0963661820983461\n",
      "Epoch: 250\n",
      "Loss: \n",
      "Training: 1.9540192006225425 Test: 1.1140801398810667\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7581994959869722 Test: 1.091639744310373\n",
      "Epoch: 251\n",
      "Loss: \n",
      "Training: 1.661127853999475 Test: 1.0933914480544626\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7906815626846808 Test: 1.0889486981987349\n",
      "Epoch: 252\n",
      "Loss: \n",
      "Training: 1.8764190469938666 Test: 1.1251422257839432\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7943354693081777 Test: 1.0883685437336774\n",
      "Epoch: 253\n",
      "Loss: \n",
      "Training: 1.8662997587103316 Test: 1.1280203933386523\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.81238560553687 Test: 1.092216410764051\n",
      "Epoch: 254\n",
      "Loss: \n",
      "Training: 1.7387023729953355 Test: 1.0603435641204668\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8391073984325772 Test: 1.0935534744132924\n",
      "Epoch: 255\n",
      "Loss: \n",
      "Training: 1.6725432723376388 Test: 1.0420964335822969\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8250532418184733 Test: 1.0953491853778956\n",
      "Epoch: 256\n",
      "Loss: \n",
      "Training: 1.7003055251196415 Test: 1.0918641896618164\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8152882449540193 Test: 1.0923106150948105\n",
      "Epoch: 257\n",
      "Loss: \n",
      "Training: 2.024969463077034 Test: 1.0853034723994939\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.811465298648858 Test: 1.0905242390276995\n",
      "Epoch: 258\n",
      "Loss: \n",
      "Training: 1.7206523872482258 Test: 1.1481197906801262\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8192276305665414 Test: 1.091732441591391\n",
      "Epoch: 259\n",
      "Loss: \n",
      "Training: 1.9048457434696646 Test: 1.096252301276785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.799068842040522 Test: 1.0986178006630762\n",
      "Epoch: 260\n",
      "Loss: \n",
      "Training: 1.6723813421910663 Test: 1.0785861530645593\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8119884624573757 Test: 1.098461395877911\n",
      "Epoch: 261\n",
      "Loss: \n",
      "Training: 1.8606576574873788 Test: 1.0244952736875357\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.783824676614228 Test: 1.0949119971962602\n",
      "Epoch: 262\n",
      "Loss: \n",
      "Training: 1.9606966711125755 Test: 1.0377485976732719\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8037776569630186 Test: 1.0880223797595676\n",
      "Epoch: 263\n",
      "Loss: \n",
      "Training: 1.6444110589712377 Test: 1.1093672568881099\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.812205419374889 Test: 1.0792830169485004\n",
      "Epoch: 264\n",
      "Loss: \n",
      "Training: 1.7535182578696904 Test: 1.0283427576562263\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7900165494009794 Test: 1.0774177033034462\n",
      "Epoch: 265\n",
      "Loss: \n",
      "Training: 1.7564373280274734 Test: 1.0739428843365222\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7914981378884154 Test: 1.0742176226570221\n",
      "Epoch: 266\n",
      "Loss: \n",
      "Training: 1.745888778303352 Test: 1.0479228830058234\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7998875434573989 Test: 1.0774022677324449\n",
      "Epoch: 267\n",
      "Loss: \n",
      "Training: 1.6371065953209487 Test: 1.116889982020559\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.80444586877577 Test: 1.0730081370668454\n",
      "Epoch: 268\n",
      "Loss: \n",
      "Training: 1.529730344942146 Test: 1.0880069478747687\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7656595820001613 Test: 1.0761667880289518\n",
      "Epoch: 269\n",
      "Loss: \n",
      "Training: 1.7072186995616538 Test: 1.0601147779011586\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7465673777695532 Test: 1.0701555037484163\n",
      "Epoch: 270\n",
      "Loss: \n",
      "Training: 1.8200964067789414 Test: 1.0809857855178457\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.726804673378752 Test: 1.0665417514108535\n",
      "Epoch: 271\n",
      "Loss: \n",
      "Training: 1.9289148535067884 Test: 1.0873765325064697\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.74157617983754 Test: 1.0667817146561822\n",
      "Epoch: 272\n",
      "Loss: \n",
      "Training: 1.6597714166429358 Test: 1.0784439786336344\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.748401899439481 Test: 1.0730698405380754\n",
      "Epoch: 273\n",
      "Loss: \n",
      "Training: 1.742359836119589 Test: 1.0937937824804953\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7183093739925166 Test: 1.077139378634112\n",
      "Epoch: 274\n",
      "Loss: \n",
      "Training: 1.713022723109566 Test: 1.0790116640084917\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.728104251707352 Test: 1.0755820311933502\n",
      "Epoch: 275\n",
      "Loss: \n",
      "Training: 1.8535438178237371 Test: 1.0612174286161797\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7240546982313394 Test: 1.0806489218285766\n",
      "Epoch: 276\n",
      "Loss: \n",
      "Training: 1.776103064157936 Test: 1.0884795242761254\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7337653472109658 Test: 1.0793763762565427\n",
      "Epoch: 277\n",
      "Loss: \n",
      "Training: 1.8396910292344688 Test: 1.095087640829607\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7367867757964242 Test: 1.0834320403835729\n",
      "Epoch: 278\n",
      "Loss: \n",
      "Training: 1.902136230478131 Test: 1.1306452219552419\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7570452191877763 Test: 1.0812518062644778\n",
      "Epoch: 279\n",
      "Loss: \n",
      "Training: 1.6055048794622477 Test: 1.1355197169465856\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7942858077413746 Test: 1.0855156336725251\n",
      "Epoch: 280\n",
      "Loss: \n",
      "Training: 1.6306665812256156 Test: 1.030807915475754\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7841144257314343 Test: 1.0930561275770676\n",
      "Epoch: 281\n",
      "Loss: \n",
      "Training: 1.7250155261408422 Test: 1.1591208712269396\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7651714431761019 Test: 1.0880383405728584\n",
      "Epoch: 282\n",
      "Loss: \n",
      "Training: 1.6531417789937888 Test: 1.074582021684175\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7447815104395068 Test: 1.0952127744449052\n",
      "Epoch: 283\n",
      "Loss: \n",
      "Training: 1.7694476709316864 Test: 1.0313820637658004\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.744118546674592 Test: 1.0948265787499594\n",
      "Epoch: 284\n",
      "Loss: \n",
      "Training: 1.7416065728157542 Test: 1.0959346808942854\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7468273301558017 Test: 1.0885854068784901\n",
      "Epoch: 285\n",
      "Loss: \n",
      "Training: 1.7772170223233166 Test: 1.1056591106525344\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7496857151264205 Test: 1.0902777085670694\n",
      "Epoch: 286\n",
      "Loss: \n",
      "Training: 1.7145326833062406 Test: 1.0237014322676745\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7420530355763788 Test: 1.094721876770705\n",
      "Epoch: 287\n",
      "Loss: \n",
      "Training: 1.8550850977525595 Test: 1.0986116501024903\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7358959974912094 Test: 1.0882440675698597\n",
      "Epoch: 288\n",
      "Loss: \n",
      "Training: 1.751439819666515 Test: 1.135115120798811\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7374354043430185 Test: 1.0885964684971483\n",
      "Epoch: 289\n",
      "Loss: \n",
      "Training: 1.7112452988353262 Test: 1.1010778909783137\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7223657632618565 Test: 1.0890434583815052\n",
      "Epoch: 290\n",
      "Loss: \n",
      "Training: 1.75906735238039 Test: 1.0374283697508386\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7329398051991647 Test: 1.085599275784678\n",
      "Epoch: 291\n",
      "Loss: \n",
      "Training: 1.6507421115749357 Test: 1.085844705096448\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.745779882314642 Test: 1.0862613212121863\n",
      "Epoch: 292\n",
      "Loss: \n",
      "Training: 1.8218850501262984 Test: 1.060653961221348\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7383525408580514 Test: 1.078933704599137\n",
      "Epoch: 293\n",
      "Loss: \n",
      "Training: 1.8348836724465134 Test: 1.1162985488873696\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7552268679713023 Test: 1.0775408985528545\n",
      "Epoch: 294\n",
      "Loss: \n",
      "Training: 2.080360255479096 Test: 1.1077238094325774\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7617704681227848 Test: 1.0860325470650114\n",
      "Epoch: 295\n",
      "Loss: \n",
      "Training: 1.7634578901169524 Test: 1.046934335390341\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.795645836389119 Test: 1.0872114599188405\n",
      "Epoch: 296\n",
      "Loss: \n",
      "Training: 1.7525432412011934 Test: 1.0897665577715943\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7942699231684827 Test: 1.0813389823926212\n",
      "Epoch: 297\n",
      "Loss: \n",
      "Training: 1.6493749571481882 Test: 1.107630212602578\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7980709789579776 Test: 1.0879454949430134\n",
      "Epoch: 298\n",
      "Loss: \n",
      "Training: 1.8548995366255077 Test: 1.0677468787965902\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.777499964897541 Test: 1.0888473511930221\n",
      "Epoch: 299\n",
      "Loss: \n",
      "Training: 1.7569205342756524 Test: 1.1141764109073016\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.78784593659344 Test: 1.0821105269928\n",
      "Epoch: 300\n",
      "Loss: \n",
      "Training: 1.7781723923670465 Test: 1.1546419735895281\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7924134601374728 Test: 1.0834203789856989\n",
      "Epoch: 301\n",
      "Loss: \n",
      "Training: 1.6114991574389372 Test: 1.0696082795040989\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7943239641361384 Test: 1.0951417393695677\n",
      "Epoch: 302\n",
      "Loss: \n",
      "Training: 1.7457179812810997 Test: 1.112656902181745\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7903996687225388 Test: 1.0935180968103329\n",
      "Epoch: 303\n",
      "Loss: \n",
      "Training: 1.987163429489278 Test: 1.1016441520458944\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7827829618380189 Test: 1.0987183909063725\n",
      "Epoch: 304\n",
      "Loss: \n",
      "Training: 1.7382289784193792 Test: 1.1090786855941728\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7980109375422952 Test: 1.097252951222225\n",
      "Epoch: 305\n",
      "Loss: \n",
      "Training: 1.6985205706676056 Test: 1.078779554371512\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7637978098363234 Test: 1.0973884388383843\n",
      "Epoch: 306\n",
      "Loss: \n",
      "Training: 1.6684798641233678 Test: 1.0782047819656155\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7573040778913889 Test: 1.1005729607365016\n",
      "Epoch: 307\n",
      "Loss: \n",
      "Training: 1.61621460859316 Test: 1.0208117668066572\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7488977401836063 Test: 1.0994167831559034\n",
      "Epoch: 308\n",
      "Loss: \n",
      "Training: 1.630281508000991 Test: 1.088106714193036\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7455817053281035 Test: 1.0907349385763117\n",
      "Epoch: 309\n",
      "Loss: \n",
      "Training: 2.0644546874570144 Test: 1.0864273966414748\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7231199024656518 Test: 1.092770922115956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 310\n",
      "Loss: \n",
      "Training: 2.00958642820937 Test: 1.101825194248539\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.753873317783788 Test: 1.0899960206893735\n",
      "Epoch: 311\n",
      "Loss: \n",
      "Training: 1.8210013065146986 Test: 1.1002116378721125\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7770147213680203 Test: 1.0847143427552746\n",
      "Epoch: 312\n",
      "Loss: \n",
      "Training: 2.031250174924403 Test: 1.084830046961591\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7979649362755965 Test: 1.0877746785920759\n",
      "Epoch: 313\n",
      "Loss: \n",
      "Training: 1.66468985601773 Test: 1.1067802292233155\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8265181556399266 Test: 1.0849919930700604\n",
      "Epoch: 314\n",
      "Loss: \n",
      "Training: 1.705114288839175 Test: 1.028031733115436\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7942707982927721 Test: 1.0855056007878026\n",
      "Epoch: 315\n",
      "Loss: \n",
      "Training: 1.950741538463761 Test: 1.088533588494833\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7909593293347517 Test: 1.0774009055399287\n",
      "Epoch: 316\n",
      "Loss: \n",
      "Training: 1.7307115215219004 Test: 1.1275597321531285\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8161814261143672 Test: 1.078376308952261\n",
      "Epoch: 317\n",
      "Loss: \n",
      "Training: 1.5914033297381895 Test: 1.0875647410911407\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8224045918542202 Test: 1.0833118039710123\n",
      "Epoch: 318\n",
      "Loss: \n",
      "Training: 1.96863372665948 Test: 1.0967631123539756\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8199234639687234 Test: 1.0899871013994606\n",
      "Epoch: 319\n",
      "Loss: \n",
      "Training: 1.5462485237971686 Test: 1.1025419168299517\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8537586858345723 Test: 1.0908527412155549\n",
      "Epoch: 320\n",
      "Loss: \n",
      "Training: 1.8940512076566085 Test: 1.079227001982018\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8019380694685878 Test: 1.0924641932344024\n",
      "Epoch: 321\n",
      "Loss: \n",
      "Training: 1.8926055787520613 Test: 1.0131896303571555\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7903845474133118 Test: 1.0902043740077503\n",
      "Epoch: 322\n",
      "Loss: \n",
      "Training: 1.9458446081281369 Test: 1.134395224994158\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.797544974637048 Test: 1.0815021732562546\n",
      "Epoch: 323\n",
      "Loss: \n",
      "Training: 1.8244888862541262 Test: 1.0522401934467256\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7890044179574212 Test: 1.0864586910595115\n",
      "Epoch: 324\n",
      "Loss: \n",
      "Training: 1.7371425578353141 Test: 1.1004499376801928\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.804984320981061 Test: 1.0810046874818524\n",
      "Epoch: 325\n",
      "Loss: \n",
      "Training: 1.8116559302217912 Test: 1.1574918731234052\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8081871478806746 Test: 1.0882465079383281\n",
      "Epoch: 326\n",
      "Loss: \n",
      "Training: 1.9667150456959728 Test: 1.0633098104726637\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7942785870564777 Test: 1.0951423364011852\n",
      "Epoch: 327\n",
      "Loss: \n",
      "Training: 1.5733544837195326 Test: 1.1184243743105957\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8178789394738852 Test: 1.0887173442331386\n",
      "Epoch: 328\n",
      "Loss: \n",
      "Training: 1.6922975498221757 Test: 1.1106634148098806\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8160740548720196 Test: 1.0918033075550841\n",
      "Epoch: 329\n",
      "Loss: \n",
      "Training: 1.9577045806057367 Test: 1.0978698689332627\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7884404371882887 Test: 1.0931933378006746\n",
      "Epoch: 330\n",
      "Loss: \n",
      "Training: 2.115347630917473 Test: 1.081453229301229\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8295860428691455 Test: 1.0927261330110059\n",
      "Epoch: 331\n",
      "Loss: \n",
      "Training: 1.6712871515522252 Test: 1.026592356675018\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8517156851952319 Test: 1.092948755742927\n",
      "Epoch: 332\n",
      "Loss: \n",
      "Training: 1.654008940419178 Test: 1.0711333708395792\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8295838424752486 Test: 1.094289028374713\n",
      "Epoch: 333\n",
      "Loss: \n",
      "Training: 1.8964608360505846 Test: 1.091623429704265\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8004002757043527 Test: 1.0879628429592552\n",
      "Epoch: 334\n",
      "Loss: \n",
      "Training: 1.655431748983516 Test: 1.0418737085603744\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8075974706839986 Test: 1.0919011665850091\n",
      "Epoch: 335\n",
      "Loss: \n",
      "Training: 1.7920357417960855 Test: 1.168725049260523\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7994263897988187 Test: 1.0860435436730271\n",
      "Epoch: 336\n",
      "Loss: \n",
      "Training: 1.5716160124369207 Test: 1.081581850304764\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.797464370956248 Test: 1.0871668612867391\n",
      "Epoch: 337\n",
      "Loss: \n",
      "Training: 1.874539464287553 Test: 1.097727464839193\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7579544676303425 Test: 1.088994065269949\n",
      "Epoch: 338\n",
      "Loss: \n",
      "Training: 1.7297037092792866 Test: 1.1387147525180903\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7880729656871448 Test: 1.086924374322809\n",
      "Epoch: 339\n",
      "Loss: \n",
      "Training: 1.795695881817541 Test: 1.1157148188708557\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7918135816328558 Test: 1.08972950809363\n",
      "Epoch: 340\n",
      "Loss: \n",
      "Training: 1.6753236599566261 Test: 1.092504012516059\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7756127117540366 Test: 1.0915140030873893\n",
      "Epoch: 341\n",
      "Loss: \n",
      "Training: 1.9324688305555229 Test: 1.0577224074687739\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7316103146579516 Test: 1.092619081408872\n",
      "Epoch: 342\n",
      "Loss: \n",
      "Training: 1.5781708914909751 Test: 1.0831496744981888\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7577284825582815 Test: 1.0957320864882478\n",
      "Epoch: 343\n",
      "Loss: \n",
      "Training: 1.5810360892878252 Test: 1.0993313615392095\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.750144677665461 Test: 1.096933716854109\n",
      "Epoch: 344\n",
      "Loss: \n",
      "Training: 2.00477866362551 Test: 0.9997740870866841\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7186022029891852 Test: 1.097704510037603\n",
      "Epoch: 345\n",
      "Loss: \n",
      "Training: 1.7746060252986067 Test: 1.0752919168931838\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7535368944533851 Test: 1.0934945478902343\n",
      "Epoch: 346\n",
      "Loss: \n",
      "Training: 1.7129438392632428 Test: 1.0962582132680445\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7517939228036368 Test: 1.0841512346535003\n",
      "Epoch: 347\n",
      "Loss: \n",
      "Training: 1.9325372097175533 Test: 1.0403854105209283\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7659267054862688 Test: 1.0856188709498282\n",
      "Epoch: 348\n",
      "Loss: \n",
      "Training: 1.641575905343695 Test: 1.1927978797429328\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.771726480029269 Test: 1.0798846655180019\n",
      "Epoch: 349\n",
      "Loss: \n",
      "Training: 1.5870298296283045 Test: 1.0920962011702326\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.76291369963571 Test: 1.085292978240486\n",
      "Epoch: 350\n",
      "Loss: \n",
      "Training: 1.928227898142722 Test: 1.0670622864895594\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.742047094416786 Test: 1.0829311164704236\n",
      "Epoch: 351\n",
      "Loss: \n",
      "Training: 1.8626661988899864 Test: 1.0466525593352645\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7673375182353959 Test: 1.0803869438677736\n",
      "Epoch: 352\n",
      "Loss: \n",
      "Training: 1.7944038687875281 Test: 1.1347148629699448\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7603572550688422 Test: 1.0792799590544226\n",
      "Epoch: 353\n",
      "Loss: \n",
      "Training: 1.766956984448958 Test: 1.154951817569711\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7819805527984975 Test: 1.0844364779015983\n",
      "Epoch: 354\n",
      "Loss: \n",
      "Training: 1.65556761760738 Test: 1.1428641822233836\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8005726423146104 Test: 1.0899985235046485\n",
      "Epoch: 355\n",
      "Loss: \n",
      "Training: 1.895456585688304 Test: 1.088832324393898\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7656515377127975 Test: 1.1043075330183185\n",
      "Epoch: 356\n",
      "Loss: \n",
      "Training: 1.6332990514169792 Test: 1.0821053092345896\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7777365937517675 Test: 1.1056615737683901\n",
      "Epoch: 357\n",
      "Loss: \n",
      "Training: 1.6369307350270401 Test: 1.1156739936314093\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7697721149671413 Test: 1.1042462833650446\n",
      "Epoch: 358\n",
      "Loss: \n",
      "Training: 1.9806736032766312 Test: 1.0287798876241032\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7402114674980897 Test: 1.1117751416760926\n",
      "Epoch: 359\n",
      "Loss: \n",
      "Training: 1.9036614317807374 Test: 1.1585369453919554\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7741212372913833 Test: 1.0953733424642096\n",
      "Epoch: 360\n",
      "Loss: \n",
      "Training: 1.9070032818308778 Test: 1.0311238157644604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8057843975066266 Test: 1.1020174168863819\n",
      "Epoch: 361\n",
      "Loss: \n",
      "Training: 1.6004549221358377 Test: 1.0882883207421832\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8036619358754422 Test: 1.0984235698138718\n",
      "Epoch: 362\n",
      "Loss: \n",
      "Training: 2.060141322697203 Test: 1.107006684580343\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7774408082000275 Test: 1.1025871459545638\n",
      "Epoch: 363\n",
      "Loss: \n",
      "Training: 1.8279668075304643 Test: 1.1349927951580985\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.804014553590995 Test: 1.0998163281156037\n",
      "Epoch: 364\n",
      "Loss: \n",
      "Training: 1.970620988147369 Test: 1.088162926582116\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8101155358991456 Test: 1.0978204258744424\n",
      "Epoch: 365\n",
      "Loss: \n",
      "Training: 1.912100869771965 Test: 1.1492329451163452\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8416208729531447 Test: 1.0923503003103157\n",
      "Epoch: 366\n",
      "Loss: \n",
      "Training: 1.7782108662400216 Test: 1.0429537678775207\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8432853013615105 Test: 1.0983903623825604\n",
      "Epoch: 367\n",
      "Loss: \n",
      "Training: 1.7163829738392073 Test: 1.0415719054432535\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8577764828438148 Test: 1.0944752082468536\n",
      "Epoch: 368\n",
      "Loss: \n",
      "Training: 1.4675325790624911 Test: 1.1161758554126153\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8657217067250311 Test: 1.0870649994280381\n",
      "Epoch: 369\n",
      "Loss: \n",
      "Training: 1.6492112787045534 Test: 1.0787261168258182\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8144076043036175 Test: 1.0958045962068892\n",
      "Epoch: 370\n",
      "Loss: \n",
      "Training: 2.0487628068973547 Test: 1.0764397976269346\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.788962588995999 Test: 1.0878235133502756\n",
      "Epoch: 371\n",
      "Loss: \n",
      "Training: 1.9750801973815386 Test: 1.02012337793348\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8031385415026466 Test: 1.0923551115365229\n",
      "Epoch: 372\n",
      "Loss: \n",
      "Training: 1.937681084742554 Test: 1.0760579811136861\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8406010690272168 Test: 1.0855386172556525\n",
      "Epoch: 373\n",
      "Loss: \n",
      "Training: 1.928975804998714 Test: 1.03013556916261\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8283550452317516 Test: 1.082443746908987\n",
      "Epoch: 374\n",
      "Loss: \n",
      "Training: 1.8462507815085858 Test: 1.0531844220095437\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.838455944978577 Test: 1.071958024309438\n",
      "Epoch: 375\n",
      "Loss: \n",
      "Training: 1.648822803761173 Test: 1.0659490970376468\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8260189243146985 Test: 1.0684601738521808\n",
      "Epoch: 376\n",
      "Loss: \n",
      "Training: 1.8113573405365404 Test: 1.1065651906602443\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7996911177136194 Test: 1.060131789044311\n",
      "Epoch: 377\n",
      "Loss: \n",
      "Training: 1.8994763644139108 Test: 0.9998834849303756\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8030057651432714 Test: 1.0664929313225833\n",
      "Epoch: 378\n",
      "Loss: \n",
      "Training: 1.921764434428188 Test: 1.1462493144479846\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8213151042007414 Test: 1.0623240892712955\n",
      "Epoch: 379\n",
      "Loss: \n",
      "Training: 1.9502985847533407 Test: 1.0934027456196602\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8667382897373113 Test: 1.0653314351748324\n",
      "Epoch: 380\n",
      "Loss: \n",
      "Training: 1.6842374696539963 Test: 1.0628950739638825\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8968470203421899 Test: 1.0667990980542166\n",
      "Epoch: 381\n",
      "Loss: \n",
      "Training: 1.577048376577993 Test: 1.0505624326201155\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8603944866178541 Test: 1.0654446256879113\n",
      "Epoch: 382\n",
      "Loss: \n",
      "Training: 1.7179758903151965 Test: 1.1345682105056745\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8205913045374995 Test: 1.0684885311565748\n",
      "Epoch: 383\n",
      "Loss: \n",
      "Training: 1.8105380523567007 Test: 1.0982425568549383\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7986207850947635 Test: 1.0743395540957739\n",
      "Epoch: 384\n",
      "Loss: \n",
      "Training: 1.8823365234483478 Test: 1.0869298125168443\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7867770098305626 Test: 1.0811502528650068\n",
      "Epoch: 385\n",
      "Loss: \n",
      "Training: 1.7012183565666918 Test: 1.1558747501278201\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7903855840245388 Test: 1.0845247919157366\n",
      "Epoch: 386\n",
      "Loss: \n",
      "Training: 1.7762494914930074 Test: 1.1626917111222852\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7956251393050906 Test: 1.093517357224754\n",
      "Epoch: 387\n",
      "Loss: \n",
      "Training: 1.8756521686912933 Test: 1.0513566107826435\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7921143544007374 Test: 1.0991300092709582\n",
      "Epoch: 388\n",
      "Loss: \n",
      "Training: 1.749513605546143 Test: 1.0897280841549295\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7897319348284757 Test: 1.104277321856185\n",
      "Epoch: 389\n",
      "Loss: \n",
      "Training: 1.940395897080292 Test: 1.1397032628869952\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7725068519402711 Test: 1.0986251988268794\n",
      "Epoch: 390\n",
      "Loss: \n",
      "Training: 1.6310393370627958 Test: 1.046110660888795\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7715165831729665 Test: 1.1032552505536128\n",
      "Epoch: 391\n",
      "Loss: \n",
      "Training: 1.747709043620675 Test: 1.0919620372807273\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.766196769913846 Test: 1.101576809246104\n",
      "Epoch: 392\n",
      "Loss: \n",
      "Training: 2.0233844642601215 Test: 1.083710155313728\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.783262836618114 Test: 1.1057167697121653\n",
      "Epoch: 393\n",
      "Loss: \n",
      "Training: 1.998992709540361 Test: 1.086286758688092\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8138036940126068 Test: 1.1006309641929706\n",
      "Epoch: 394\n",
      "Loss: \n",
      "Training: 1.9802107495068126 Test: 1.1408241942109616\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8326491597309726 Test: 1.0994353843762859\n",
      "Epoch: 395\n",
      "Loss: \n",
      "Training: 1.6320398547323678 Test: 1.083808494020363\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8424365823368194 Test: 1.1048248225456976\n",
      "Epoch: 396\n",
      "Loss: \n",
      "Training: 1.8527430315231583 Test: 0.9918297473895049\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8355187321533872 Test: 1.097618196934952\n",
      "Epoch: 397\n",
      "Loss: \n",
      "Training: 1.7665762399717782 Test: 1.040330992291786\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8431680861564022 Test: 1.080532000561674\n",
      "Epoch: 398\n",
      "Loss: \n",
      "Training: 1.8175415154414085 Test: 1.0389272064820962\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8322604932844506 Test: 1.0794294387125882\n",
      "Epoch: 399\n",
      "Loss: \n",
      "Training: 1.779731783984348 Test: 1.04173007279223\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.839063284273977 Test: 1.0743493509453048\n",
      "Epoch: 400\n",
      "Loss: \n",
      "Training: 1.6255374881519338 Test: 1.1123650803772775\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8229968729643826 Test: 1.0645520319358286\n",
      "Epoch: 401\n",
      "Loss: \n",
      "Training: 1.6112515501693063 Test: 1.0967350621253573\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8224466880732966 Test: 1.0711774738846767\n",
      "Epoch: 402\n",
      "Loss: \n",
      "Training: 2.0139647232909845 Test: 1.062528560416096\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8088009387281594 Test: 1.0716547763691397\n",
      "Epoch: 403\n",
      "Loss: \n",
      "Training: 1.7163895121819988 Test: 1.1578100179105668\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.807858964631246 Test: 1.0695366168793765\n",
      "Epoch: 404\n",
      "Loss: \n",
      "Training: 1.900754093683902 Test: 1.1003613600080075\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7795986448954095 Test: 1.076688942801624\n",
      "Epoch: 405\n",
      "Loss: \n",
      "Training: 1.770849994968275 Test: 1.0723551964197533\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7716529793131186 Test: 1.0726426593813285\n",
      "Epoch: 406\n",
      "Loss: \n",
      "Training: 1.9463708358174936 Test: 1.108264879571725\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7855339933367091 Test: 1.0714973296212675\n",
      "Epoch: 407\n",
      "Loss: \n",
      "Training: 1.9474999800291515 Test: 1.0605707796840853\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.794896773766143 Test: 1.0831408428394895\n",
      "Epoch: 408\n",
      "Loss: \n",
      "Training: 1.7744295822401 Test: 1.0870275268666552\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.81298914777188 Test: 1.0851648215787193\n",
      "Epoch: 409\n",
      "Loss: \n",
      "Training: 2.193480932761251 Test: 1.0774857293528703\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8086779544517495 Test: 1.0899748536171754\n",
      "Epoch: 410\n",
      "Loss: \n",
      "Training: 1.8127430078813422 Test: 1.0650077827202868\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8500528693294396 Test: 1.0935504192732393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 411\n",
      "Loss: \n",
      "Training: 1.557186096853089 Test: 1.0853882501419334\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8687734213023801 Test: 1.0888146895075403\n",
      "Epoch: 412\n",
      "Loss: \n",
      "Training: 1.6496093795823699 Test: 1.1110439089096065\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.863366875970759 Test: 1.087680008309198\n",
      "Epoch: 413\n",
      "Loss: \n",
      "Training: 1.9641183271496516 Test: 1.1590321837223982\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8269313415998973 Test: 1.092531543158549\n",
      "Epoch: 414\n",
      "Loss: \n",
      "Training: 1.6772167523725996 Test: 1.014268190135233\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8517042230966627 Test: 1.0926537597397323\n",
      "Epoch: 415\n",
      "Loss: \n",
      "Training: 1.5854274459859925 Test: 1.0886555724472486\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8293504889655328 Test: 1.0840444427524547\n",
      "Epoch: 416\n",
      "Loss: \n",
      "Training: 1.7732671734894923 Test: 1.0383803776487357\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8108082340673044 Test: 1.085674480355204\n",
      "Epoch: 417\n",
      "Loss: \n",
      "Training: 1.8822624700069746 Test: 1.0418046531421303\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7934978678345044 Test: 1.0786860301629053\n",
      "Epoch: 418\n",
      "Loss: \n",
      "Training: 1.8031276663063136 Test: 1.171995039501061\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7869741168322861 Test: 1.0768094175087097\n",
      "Epoch: 419\n",
      "Loss: \n",
      "Training: 1.8954101439296727 Test: 1.1267039336757372\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7898439252389076 Test: 1.0853061687721504\n",
      "Epoch: 420\n",
      "Loss: \n",
      "Training: 1.9028179927979358 Test: 1.0709885346345616\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7600368463557499 Test: 1.090227989204437\n",
      "Epoch: 421\n",
      "Loss: \n",
      "Training: 1.9106684891708068 Test: 1.1943043517196796\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.769044344847409 Test: 1.0908260643958647\n",
      "Epoch: 422\n",
      "Loss: \n",
      "Training: 1.8278720839319982 Test: 1.0579163942831733\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8043925840791808 Test: 1.1017176745536392\n",
      "Epoch: 423\n",
      "Loss: \n",
      "Training: 1.7065314707935677 Test: 1.0959639000306123\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8222188545141436 Test: 1.096404923090996\n",
      "Epoch: 424\n",
      "Loss: \n",
      "Training: 1.9525692596657973 Test: 1.0820539233098305\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.796460168878535 Test: 1.0900980947218173\n",
      "Epoch: 425\n",
      "Loss: \n",
      "Training: 1.822465061011162 Test: 1.1278895700648865\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8239954196078554 Test: 1.096876668039277\n",
      "Epoch: 426\n",
      "Loss: \n",
      "Training: 1.7579684107161577 Test: 1.0714856765142122\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.847699181110372 Test: 1.1008000678010408\n",
      "Epoch: 427\n",
      "Loss: \n",
      "Training: 1.6712889094462688 Test: 1.1118144852325356\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8461693048330385 Test: 1.1041105976875885\n",
      "Epoch: 428\n",
      "Loss: \n",
      "Training: 1.6029728872782902 Test: 1.0612891583951787\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.825071948776968 Test: 1.1111115808966292\n",
      "Epoch: 429\n",
      "Loss: \n",
      "Training: 2.0001005551104987 Test: 1.1241270749889405\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8050564708741657 Test: 1.1000409927860408\n",
      "Epoch: 430\n",
      "Loss: \n",
      "Training: 1.7101415634108406 Test: 1.1322589669011358\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8155255119922482 Test: 1.099783306917361\n",
      "Epoch: 431\n",
      "Loss: \n",
      "Training: 1.8676546144178874 Test: 1.0446419418258923\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7962578690535387 Test: 1.1059103501440184\n",
      "Epoch: 432\n",
      "Loss: \n",
      "Training: 1.7472345356008072 Test: 1.081643008858402\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.791956481578247 Test: 1.09094410915464\n",
      "Epoch: 433\n",
      "Loss: \n",
      "Training: 1.8163296155570479 Test: 1.0613139683986514\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7838927267451279 Test: 1.0933167706121627\n",
      "Epoch: 434\n",
      "Loss: \n",
      "Training: 1.6943596429682921 Test: 1.1711508396712917\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7948725412214759 Test: 1.0898517774489664\n",
      "Epoch: 435\n",
      "Loss: \n",
      "Training: 1.656467207558743 Test: 1.0847653580486243\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.769051579551725 Test: 1.0987614690851126\n",
      "Epoch: 436\n",
      "Loss: \n",
      "Training: 1.6916332677091175 Test: 1.0696279963496704\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7524517942064837 Test: 1.0944490478834865\n",
      "Epoch: 437\n",
      "Loss: \n",
      "Training: 1.7346445784167128 Test: 1.085656290762144\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7458182799057795 Test: 1.0942632798670322\n",
      "Epoch: 438\n",
      "Loss: \n",
      "Training: 1.8031286856604074 Test: 1.1143612392272002\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.752153846802824 Test: 1.0916474604199928\n",
      "Epoch: 439\n",
      "Loss: \n",
      "Training: 1.5538104731844309 Test: 1.0952421906399894\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7721694266410357 Test: 1.0969546685031952\n",
      "Epoch: 440\n",
      "Loss: \n",
      "Training: 1.835700848812938 Test: 1.0414381106236188\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7275404184484286 Test: 1.0940661800683\n",
      "Epoch: 441\n",
      "Loss: \n",
      "Training: 1.6119670354560554 Test: 1.1003282885822487\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7400963469886386 Test: 1.0849840944405484\n",
      "Epoch: 442\n",
      "Loss: \n",
      "Training: 1.7498923822351165 Test: 1.1244502256732762\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7145275890924552 Test: 1.090552729116184\n",
      "Epoch: 443\n",
      "Loss: \n",
      "Training: 1.9840116250974724 Test: 1.1586843790313088\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7147933737558863 Test: 1.0948334507976716\n",
      "Epoch: 444\n",
      "Loss: \n",
      "Training: 1.861358240347923 Test: 1.0206115996172251\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7315615747099287 Test: 1.1045704918609371\n",
      "Epoch: 445\n",
      "Loss: \n",
      "Training: 1.6033077219663556 Test: 1.0756695523011057\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7482614344478917 Test: 1.0895165678555307\n",
      "Epoch: 446\n",
      "Loss: \n",
      "Training: 2.0096809039277668 Test: 1.0378711251686372\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.742945485888653 Test: 1.0886069872807789\n",
      "Epoch: 447\n",
      "Loss: \n",
      "Training: 1.9945485198750375 Test: 1.0625134300796226\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7747502495105176 Test: 1.0854313001626754\n",
      "Epoch: 448\n",
      "Loss: \n",
      "Training: 1.8164109083275213 Test: 0.9822829267819361\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8007406436563502 Test: 1.0831170140944233\n",
      "Epoch: 449\n",
      "Loss: \n",
      "Training: 1.9582980375265993 Test: 1.1161352509485427\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.802068865923062 Test: 1.0699091828498968\n",
      "Epoch: 450\n",
      "Loss: \n",
      "Training: 1.7519180371285443 Test: 1.1081377917637252\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8425176223572783 Test: 1.0719984888807523\n",
      "Epoch: 451\n",
      "Loss: \n",
      "Training: 1.6298542538856595 Test: 1.056209946655581\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.834139341188839 Test: 1.0786684569947629\n",
      "Epoch: 452\n",
      "Loss: \n",
      "Training: 1.7174070704882285 Test: 1.0398756264496045\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8359280630317998 Test: 1.0742566228020962\n",
      "Epoch: 453\n",
      "Loss: \n",
      "Training: 1.6772683363225394 Test: 1.0348329386287647\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8326795318571107 Test: 1.065799162879729\n",
      "Epoch: 454\n",
      "Loss: \n",
      "Training: 1.8006912582424306 Test: 1.1651704980354802\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8020052029796176 Test: 1.0534140188394745\n",
      "Epoch: 455\n",
      "Loss: \n",
      "Training: 1.7283467784238118 Test: 1.0421615680558098\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7959385047690681 Test: 1.0678699086812997\n",
      "Epoch: 456\n",
      "Loss: \n",
      "Training: 2.0650605369604516 Test: 1.050388888453336\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8084424104148138 Test: 1.0645191102567704\n",
      "Epoch: 457\n",
      "Loss: \n",
      "Training: 1.7230553538693456 Test: 1.084274142193779\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8139803737180824 Test: 1.0657708865852404\n",
      "Epoch: 458\n",
      "Loss: \n",
      "Training: 2.0417146046339187 Test: 1.1675262354031806\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7868310571175132 Test: 1.0679469577966558\n",
      "Epoch: 459\n",
      "Loss: \n",
      "Training: 1.6809582166622177 Test: 1.102831114856586\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8093614267481528 Test: 1.0864712886587804\n",
      "Epoch: 460\n",
      "Loss: \n",
      "Training: 1.6491218618083363 Test: 1.0180959912296732\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.781627444661715 Test: 1.0851408750495846\n",
      "Epoch: 461\n",
      "Loss: \n",
      "Training: 1.844983699604189 Test: 1.1276236885234465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7713478271296939 Test: 1.0761366949961795\n",
      "Epoch: 462\n",
      "Loss: \n",
      "Training: 1.6817032022946048 Test: 1.0702924452100118\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7928607717015468 Test: 1.083278069182966\n",
      "Epoch: 463\n",
      "Loss: \n",
      "Training: 1.99761290593598 Test: 1.120131044611122\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7892903848821846 Test: 1.0863197510590066\n",
      "Epoch: 464\n",
      "Loss: \n",
      "Training: 1.5937448675772672 Test: 1.0947179905849571\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8213248418435284 Test: 1.0948495616572425\n",
      "Epoch: 465\n",
      "Loss: \n",
      "Training: 1.855841502980421 Test: 0.962099800079047\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8006302027770122 Test: 1.0878043109121902\n",
      "Epoch: 466\n",
      "Loss: \n",
      "Training: 1.8140876587132198 Test: 1.1124280340873605\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8133796752326732 Test: 1.079798134114514\n",
      "Epoch: 467\n",
      "Loss: \n",
      "Training: 1.8009491050931445 Test: 1.0261567334745065\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7882823874079503 Test: 1.086002048677916\n",
      "Epoch: 468\n",
      "Loss: \n",
      "Training: 1.9555686331860975 Test: 1.1078663039550205\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7960717625303304 Test: 1.0801903078059891\n",
      "Epoch: 469\n",
      "Loss: \n",
      "Training: 1.8997676884412114 Test: 1.0666538557903151\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.787457165385548 Test: 1.0742243146611732\n",
      "Epoch: 470\n",
      "Loss: \n",
      "Training: 1.6574331873763322 Test: 1.141694488105976\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8093381125634473 Test: 1.070606588754546\n",
      "Epoch: 471\n",
      "Loss: \n",
      "Training: 1.800327041674128 Test: 1.0328263612086768\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8101692451202465 Test: 1.0829664384421762\n",
      "Epoch: 472\n",
      "Loss: \n",
      "Training: 1.7132568452913015 Test: 1.1198701960202697\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8057035793272402 Test: 1.0734867057106994\n",
      "Epoch: 473\n",
      "Loss: \n",
      "Training: 1.8626682482008188 Test: 1.122993622244058\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8088589436269102 Test: 1.0784444807917253\n",
      "Epoch: 474\n",
      "Loss: \n",
      "Training: 1.8340112771384052 Test: 1.1724636306533938\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7953644778533941 Test: 1.0787307385550187\n",
      "Epoch: 475\n",
      "Loss: \n",
      "Training: 1.8968054299828236 Test: 1.1403491367561187\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.819391118809508 Test: 1.0865053025618623\n",
      "Epoch: 476\n",
      "Loss: \n",
      "Training: 1.8902831522871943 Test: 1.0985134397385854\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8234875115097484 Test: 1.1043302362295695\n",
      "Epoch: 477\n",
      "Loss: \n",
      "Training: 1.5234946453812077 Test: 1.083169013573394\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8311070608671458 Test: 1.102938776794692\n",
      "Epoch: 478\n",
      "Loss: \n",
      "Training: 1.8082446511520167 Test: 1.0509903425917761\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8033616148959521 Test: 1.1086400048045808\n",
      "Epoch: 479\n",
      "Loss: \n",
      "Training: 1.9479136176499443 Test: 1.00809489941323\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.788629216692544 Test: 1.1029524086682563\n",
      "Epoch: 480\n",
      "Loss: \n",
      "Training: 1.9506686806120217 Test: 0.9965636021770562\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7934438096134169 Test: 1.097096513030548\n",
      "Epoch: 481\n",
      "Loss: \n",
      "Training: 1.975936687868732 Test: 1.0868263146595696\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8227673589369862 Test: 1.082583424437656\n",
      "Epoch: 482\n",
      "Loss: \n",
      "Training: 1.7768216859699881 Test: 1.1269450468895057\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8403283235564465 Test: 1.0879834197827454\n",
      "Epoch: 483\n",
      "Loss: \n",
      "Training: 1.7841507913878432 Test: 1.0955605181147172\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8466848076243152 Test: 1.0886909048696687\n",
      "Epoch: 484\n",
      "Loss: \n",
      "Training: 1.8829795013290098 Test: 1.056345513944846\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8388330619430178 Test: 1.0859475944567343\n",
      "Epoch: 485\n",
      "Loss: \n",
      "Training: 1.736549002567863 Test: 1.0606236639657554\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8437298843620784 Test: 1.07433578278588\n",
      "Epoch: 486\n",
      "Loss: \n",
      "Training: 1.8360051128462256 Test: 1.0474511623310896\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.827704241620582 Test: 1.0663632355068435\n",
      "Epoch: 487\n",
      "Loss: \n",
      "Training: 1.8443030317449465 Test: 1.0706419128470348\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8222764376764853 Test: 1.0612570077660939\n",
      "Epoch: 488\n",
      "Loss: \n",
      "Training: 1.8046667835219536 Test: 1.0044127668392389\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.854357276312859 Test: 1.060004297693458\n",
      "Epoch: 489\n",
      "Loss: \n",
      "Training: 1.8559521336350877 Test: 1.0616167762865507\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8539994895498526 Test: 1.0553465401182045\n",
      "Epoch: 490\n",
      "Loss: \n",
      "Training: 1.763392698938051 Test: 1.1780599970381396\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.844803341148367 Test: 1.0606987278055366\n",
      "Epoch: 491\n",
      "Loss: \n",
      "Training: 2.0280755266772412 Test: 1.1087296533802282\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.82607574298097 Test: 1.0788483672916447\n",
      "Epoch: 492\n",
      "Loss: \n",
      "Training: 2.047953918302246 Test: 1.0503749642449025\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.831289626861821 Test: 1.0810387011637106\n",
      "Epoch: 493\n",
      "Loss: \n",
      "Training: 1.7368163211695602 Test: 1.0701793445828045\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8584028500950467 Test: 1.0733816928992503\n",
      "Epoch: 494\n",
      "Loss: \n",
      "Training: 1.7619561848969179 Test: 1.0680631965461758\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8536694030732181 Test: 1.070843575546059\n",
      "Epoch: 495\n",
      "Loss: \n",
      "Training: 1.7452478465635395 Test: 1.125410951575587\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8415670714300092 Test: 1.072015343806192\n",
      "Epoch: 496\n",
      "Loss: \n",
      "Training: 1.716635087217418 Test: 1.1225105976766583\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.842436955829577 Test: 1.078494072567175\n",
      "Epoch: 497\n",
      "Loss: \n",
      "Training: 1.6090691958123162 Test: 1.000067428693404\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8304999532666961 Test: 1.086000016101732\n",
      "Epoch: 498\n",
      "Loss: \n",
      "Training: 1.6853475252861208 Test: 1.0825809706080596\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8069765696734332 Test: 1.078942567686369\n",
      "Epoch: 499\n",
      "Loss: \n",
      "Training: 1.6961058060109182 Test: 1.0234764415711939\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.79504464384985 Test: 1.0867593880632511\n",
      "Epoch: 500\n",
      "Loss: \n",
      "Training: 1.9065711353167731 Test: 1.0967786801242732\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.779060011087433 Test: 1.0829453545917154\n",
      "Epoch: 501\n",
      "Loss: \n",
      "Training: 1.8685110718363676 Test: 1.0253084066137161\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7933778547253052 Test: 1.0748172229003288\n",
      "Epoch: 502\n",
      "Loss: \n",
      "Training: 1.784045995409071 Test: 1.0826220104994968\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7774214092412173 Test: 1.0664750982236775\n",
      "Epoch: 503\n",
      "Loss: \n",
      "Training: 1.7750739209296573 Test: 1.0907105570310904\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7510306169519 Test: 1.069699802849137\n",
      "Epoch: 504\n",
      "Loss: \n",
      "Training: 1.7654596747693858 Test: 1.0605964401925807\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.75485637692791 Test: 1.0717529240939656\n",
      "Epoch: 505\n",
      "Loss: \n",
      "Training: 1.6973235121755075 Test: 1.1197562326947759\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7552067259151567 Test: 1.071006248458606\n",
      "Epoch: 506\n",
      "Loss: \n",
      "Training: 1.875180723261527 Test: 1.1098314322621836\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7504142924763535 Test: 1.070440776570525\n",
      "Epoch: 507\n",
      "Loss: \n",
      "Training: 1.8867070113932096 Test: 1.109483005657595\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7662688560807644 Test: 1.0691728600290775\n",
      "Epoch: 508\n",
      "Loss: \n",
      "Training: 1.887301894222622 Test: 1.0948393541547743\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7940326376388538 Test: 1.0801144177254964\n",
      "Epoch: 509\n",
      "Loss: \n",
      "Training: 1.8426825851310555 Test: 1.0867971230521352\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.814228074532504 Test: 1.0813402560801681\n",
      "Epoch: 510\n",
      "Loss: \n",
      "Training: 1.6830308436569603 Test: 1.0586484553965825\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8288857524445175 Test: 1.087672324228262\n",
      "Epoch: 511\n",
      "Loss: \n",
      "Training: 1.6884077157101989 Test: 1.0598771199361454\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8065317232785365 Test: 1.083859301755493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 512\n",
      "Loss: \n",
      "Training: 1.704014891390913 Test: 1.1374540331842673\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7885213876659196 Test: 1.0873161730877359\n",
      "Epoch: 513\n",
      "Loss: \n",
      "Training: 1.7282292278838163 Test: 1.0959404741326686\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7805182772641035 Test: 1.092799375356213\n",
      "Epoch: 514\n",
      "Loss: \n",
      "Training: 1.9104428490615493 Test: 1.1233353649633953\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7758338079595195 Test: 1.0933223670663708\n",
      "Epoch: 515\n",
      "Loss: \n",
      "Training: 1.8921670708004996 Test: 1.0550447251276196\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7903321253887359 Test: 1.0995962595434523\n",
      "Epoch: 516\n",
      "Loss: \n",
      "Training: 1.750505707054911 Test: 1.0648971065955655\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8098164812512352 Test: 1.0931251087867366\n",
      "Epoch: 517\n",
      "Loss: \n",
      "Training: 1.7011456122193624 Test: 1.10263116248417\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7973489796305735 Test: 1.088631676220075\n",
      "Epoch: 518\n",
      "Loss: \n",
      "Training: 1.863267334535285 Test: 1.160033438962591\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7787928397131894 Test: 1.0879464919027326\n",
      "Epoch: 519\n",
      "Loss: \n",
      "Training: 1.7596187538804253 Test: 1.0921332726067516\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7763893837444553 Test: 1.0944659003835142\n",
      "Epoch: 520\n",
      "Loss: \n",
      "Training: 1.792260849841382 Test: 1.1506139075219288\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7680830006193922 Test: 1.0949995153389758\n",
      "Epoch: 521\n",
      "Loss: \n",
      "Training: 1.627260183482923 Test: 1.0922895810498656\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7790060012378341 Test: 1.1041960605515104\n",
      "Epoch: 522\n",
      "Loss: \n",
      "Training: 1.798363198691979 Test: 1.100510699257483\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7728912480151067 Test: 1.1074373066628822\n",
      "Epoch: 523\n",
      "Loss: \n",
      "Training: 1.7932114564497132 Test: 1.03068079401014\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7823260787452135 Test: 1.1037429732702038\n",
      "Epoch: 524\n",
      "Loss: \n",
      "Training: 1.7493943526655849 Test: 1.089783166735259\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7888243016018035 Test: 1.0972170052579509\n",
      "Epoch: 525\n",
      "Loss: \n",
      "Training: 1.656538208368322 Test: 1.1013154887132715\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7727194519622067 Test: 1.0938617854351373\n",
      "Epoch: 526\n",
      "Loss: \n",
      "Training: 1.6389882423101911 Test: 1.1968118836604857\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7491565657189887 Test: 1.0984888617937028\n",
      "Epoch: 527\n",
      "Loss: \n",
      "Training: 1.5806962427261597 Test: 1.211807095205123\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7380048192445166 Test: 1.1116803395001946\n",
      "Epoch: 528\n",
      "Loss: \n",
      "Training: 1.7324223750850252 Test: 1.0712176339564772\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7259598822951965 Test: 1.12259793277229\n",
      "Epoch: 529\n",
      "Loss: \n",
      "Training: 1.7304861674463332 Test: 1.1691262954269512\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7128753863501704 Test: 1.1137163522716784\n",
      "Epoch: 530\n",
      "Loss: \n",
      "Training: 1.8484694116552713 Test: 1.0906963646289973\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7099621277067611 Test: 1.1214156545536984\n",
      "Epoch: 531\n",
      "Loss: \n",
      "Training: 1.848058416340854 Test: 1.0586445717176836\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7155829838881502 Test: 1.1154239002644053\n",
      "Epoch: 532\n",
      "Loss: \n",
      "Training: 1.7664280158036092 Test: 1.1393161136463303\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7376628071739435 Test: 1.1120593993311871\n",
      "Epoch: 533\n",
      "Loss: \n",
      "Training: 1.9251350794293463 Test: 1.0884724286588205\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7344692888851063 Test: 1.1159399407700719\n",
      "Epoch: 534\n",
      "Loss: \n",
      "Training: 1.6650913941775625 Test: 1.1497706208937037\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7476616511830696 Test: 1.12171910423494\n",
      "Epoch: 535\n",
      "Loss: \n",
      "Training: 1.5926326080148734 Test: 1.0739319961679852\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.739231355334267 Test: 1.1277178496507845\n",
      "Epoch: 536\n",
      "Loss: \n",
      "Training: 1.6117800901161923 Test: 1.097231410199061\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7328407952989224 Test: 1.1249795003962557\n",
      "Epoch: 537\n",
      "Loss: \n",
      "Training: 1.8331964081413057 Test: 1.0817620571672082\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7301199800795224 Test: 1.1150214530501135\n",
      "Epoch: 538\n",
      "Loss: \n",
      "Training: 1.8735693007447836 Test: 1.0615176839530927\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.755369996621037 Test: 1.1020169492463219\n",
      "Epoch: 539\n",
      "Loss: \n",
      "Training: 2.0390862051721963 Test: 1.04843045252664\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.769484689187013 Test: 1.1010469542459833\n",
      "Epoch: 540\n",
      "Loss: \n",
      "Training: 1.857019849780368 Test: 1.0618013890765796\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8003446929595994 Test: 1.0889773699559522\n",
      "Epoch: 541\n",
      "Loss: \n",
      "Training: 1.6883642833839207 Test: 1.0795892960682223\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.801199736772109 Test: 1.0860878724007104\n",
      "Epoch: 542\n",
      "Loss: \n",
      "Training: 1.670316090726195 Test: 1.0130276731761172\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7852303234764157 Test: 1.0881823448357644\n",
      "Epoch: 543\n",
      "Loss: \n",
      "Training: 1.8384790045281474 Test: 1.0933737417358864\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7756191309686744 Test: 1.0755535007887431\n",
      "Epoch: 544\n",
      "Loss: \n",
      "Training: 1.8728201002512492 Test: 1.051258089719597\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7669535234785545 Test: 1.0760436320964497\n",
      "Epoch: 545\n",
      "Loss: \n",
      "Training: 1.9841634465706548 Test: 1.0974005007107013\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.787726394085923 Test: 1.066192378979039\n",
      "Epoch: 546\n",
      "Loss: \n",
      "Training: 1.9007444623782908 Test: 1.0457768286678935\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8268794779415014 Test: 1.0685392294333107\n",
      "Epoch: 547\n",
      "Loss: \n",
      "Training: 1.8117963816000269 Test: 1.007970315221165\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8557759151677111 Test: 1.063393771280194\n",
      "Epoch: 548\n",
      "Loss: \n",
      "Training: 1.9471456116874222 Test: 1.0327998910230907\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.853635912513583 Test: 1.0560145970855894\n",
      "Epoch: 549\n",
      "Loss: \n",
      "Training: 1.8624920430023444 Test: 1.0787111180322675\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8609935436078469 Test: 1.0531428177925892\n",
      "Epoch: 550\n",
      "Loss: \n",
      "Training: 1.9415453497087125 Test: 1.0760182433040475\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.843334127390862 Test: 1.0561708843431519\n",
      "Epoch: 551\n",
      "Loss: \n",
      "Training: 1.8408938345653099 Test: 1.0325304815900067\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8517866773836964 Test: 1.0575925697658988\n",
      "Epoch: 552\n",
      "Loss: \n",
      "Training: 2.025594578036314 Test: 1.067275189784898\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8670396325018352 Test: 1.052886688318077\n",
      "Epoch: 553\n",
      "Loss: \n",
      "Training: 1.654416145079773 Test: 1.1347011135909726\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.9025674812328468 Test: 1.0583114399789553\n",
      "Epoch: 554\n",
      "Loss: \n",
      "Training: 1.7251619889234975 Test: 1.15564195386669\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8841611952880097 Test: 1.0624441771644642\n",
      "Epoch: 555\n",
      "Loss: \n",
      "Training: 1.6977817765314072 Test: 1.1200716026865094\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8693953841552342 Test: 1.0728825635791732\n",
      "Epoch: 556\n",
      "Loss: \n",
      "Training: 1.7109178472030344 Test: 1.057705521879714\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8407572171513098 Test: 1.075149673776754\n",
      "Epoch: 557\n",
      "Loss: \n",
      "Training: 1.7634598147183296 Test: 1.1326189653971859\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8217745556337843 Test: 1.076342543097936\n",
      "Epoch: 558\n",
      "Loss: \n",
      "Training: 1.9878573994144737 Test: 1.0601776223822625\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8169408989456148 Test: 1.0888074081155381\n",
      "Epoch: 559\n",
      "Loss: \n",
      "Training: 1.850111940760565 Test: 1.1451152868169727\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8210120777183196 Test: 1.0915451812514554\n",
      "Epoch: 560\n",
      "Loss: \n",
      "Training: 1.7186520888337318 Test: 1.110096693108976\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8197740674941418 Test: 1.0981855981299258\n",
      "Epoch: 561\n",
      "Loss: \n",
      "Training: 1.7577543674822858 Test: 1.060030213872285\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7974847414066435 Test: 1.1015934431104188\n",
      "Epoch: 562\n",
      "Loss: \n",
      "Training: 1.8938494121337004 Test: 1.0569751784105108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7891707946983408 Test: 1.1043434163386465\n",
      "Epoch: 563\n",
      "Loss: \n",
      "Training: 1.656537782122269 Test: 1.1190841300774228\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7759962781080798 Test: 1.1033134152012078\n",
      "Epoch: 564\n",
      "Loss: \n",
      "Training: 1.9387782668143192 Test: 1.08468119338384\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7762084418123294 Test: 1.101751716849853\n",
      "Epoch: 565\n",
      "Loss: \n",
      "Training: 1.6630746182776825 Test: 1.0645767691920711\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7975700696014116 Test: 1.094655640801568\n",
      "Epoch: 566\n",
      "Loss: \n",
      "Training: 1.80263301089568 Test: 1.0882901900499677\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7940993537760392 Test: 1.0891061574521241\n",
      "Epoch: 567\n",
      "Loss: \n",
      "Training: 1.932933760242922 Test: 1.1398665894424287\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.803270870145304 Test: 1.0921646242691492\n",
      "Epoch: 568\n",
      "Loss: \n",
      "Training: 1.782995180316733 Test: 1.1629895467200844\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.820218264697763 Test: 1.0928893866736737\n",
      "Epoch: 569\n",
      "Loss: \n",
      "Training: 1.613614957677546 Test: 1.055721497841375\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7997320427879888 Test: 1.103170579107456\n",
      "Epoch: 570\n",
      "Loss: \n",
      "Training: 1.6964831373542575 Test: 1.1562819584313342\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7760823444796867 Test: 1.0942312002098962\n",
      "Epoch: 571\n",
      "Loss: \n",
      "Training: 1.773619321623151 Test: 1.1648608688279156\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7738654493317394 Test: 1.098849726742132\n",
      "Epoch: 572\n",
      "Loss: \n",
      "Training: 1.814990524418758 Test: 1.0618929149884033\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7754519447458261 Test: 1.109332792237695\n",
      "Epoch: 573\n",
      "Loss: \n",
      "Training: 1.4925088144504206 Test: 1.1336041478617866\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7675660559743318 Test: 1.1098245658954844\n",
      "Epoch: 574\n",
      "Loss: \n",
      "Training: 1.8021231139791394 Test: 1.0714346354799378\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.751163159207147 Test: 1.1112765676739207\n",
      "Epoch: 575\n",
      "Loss: \n",
      "Training: 1.8228678601147585 Test: 1.167421133295818\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.737497643923629 Test: 1.1099519118835306\n",
      "Epoch: 576\n",
      "Loss: \n",
      "Training: 1.7115999459174525 Test: 1.0526895735703463\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7534769681073368 Test: 1.120236348293905\n",
      "Epoch: 577\n",
      "Loss: \n",
      "Training: 1.807766549906809 Test: 1.1014146237418019\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7443736616095138 Test: 1.116676286645943\n",
      "Epoch: 578\n",
      "Loss: \n",
      "Training: 1.789239623793467 Test: 1.0397973576938266\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7318569405759026 Test: 1.1128310900758802\n",
      "Epoch: 579\n",
      "Loss: \n",
      "Training: 1.6080312992166998 Test: 1.1141541211355763\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.732481384923576 Test: 1.1005118711732547\n",
      "Epoch: 580\n",
      "Loss: \n",
      "Training: 1.7540817165336973 Test: 1.1288154653415545\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7319230190774912 Test: 1.106355133502675\n",
      "Epoch: 581\n",
      "Loss: \n",
      "Training: 1.829624355387959 Test: 1.1741436364207514\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7376828769954353 Test: 1.1036084841936966\n",
      "Epoch: 582\n",
      "Loss: \n",
      "Training: 1.8749979517504174 Test: 1.0629061853115964\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7432833803719163 Test: 1.1045367609529804\n",
      "Epoch: 583\n",
      "Loss: \n",
      "Training: 1.6501083572226625 Test: 1.1612309393660654\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7492841231050817 Test: 1.1046380879852997\n",
      "Epoch: 584\n",
      "Loss: \n",
      "Training: 1.8011697840722962 Test: 1.1229460696686229\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.765044077382306 Test: 1.1074007671357275\n",
      "Epoch: 585\n",
      "Loss: \n",
      "Training: 1.5859307491774552 Test: 1.1291487456688805\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7649487443916219 Test: 1.1125519105545962\n",
      "Epoch: 586\n",
      "Loss: \n",
      "Training: 1.8480121974066905 Test: 0.9833381432348858\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7412550332978913 Test: 1.1087246717919021\n",
      "Epoch: 587\n",
      "Loss: \n",
      "Training: 1.9693983696543782 Test: 1.0346862136028936\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7548962584468153 Test: 1.1017895287583561\n",
      "Epoch: 588\n",
      "Loss: \n",
      "Training: 1.7411933776517767 Test: 1.0586409551994242\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7710594404215723 Test: 1.0951166877444654\n",
      "Epoch: 589\n",
      "Loss: \n",
      "Training: 1.4914372087392354 Test: 1.0551811324523965\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7662548158074034 Test: 1.097001047495025\n",
      "Epoch: 590\n",
      "Loss: \n",
      "Training: 1.7435056982801411 Test: 1.0523948494037803\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7545954067596568 Test: 1.0911037486267072\n",
      "Epoch: 591\n",
      "Loss: \n",
      "Training: 1.6923115220797047 Test: 1.1008203140042996\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7535378049343013 Test: 1.0834616870329297\n",
      "Epoch: 592\n",
      "Loss: \n",
      "Training: 1.832106190954048 Test: 1.0794284726866454\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.739806521603476 Test: 1.0761293547912847\n",
      "Epoch: 593\n",
      "Loss: \n",
      "Training: 1.7319049399717668 Test: 0.9962894451554664\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.735517345523839 Test: 1.0777815835287894\n",
      "Epoch: 594\n",
      "Loss: \n",
      "Training: 1.6563147465646406 Test: 1.093052503156884\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7436970037987494 Test: 1.0612874341077294\n",
      "Epoch: 595\n",
      "Loss: \n",
      "Training: 1.7477635176975788 Test: 1.1030670254399098\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7292115000479835 Test: 1.0582980774565558\n",
      "Epoch: 596\n",
      "Loss: \n",
      "Training: 2.060971862125286 Test: 1.1364741486550538\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.745394776899996 Test: 1.0556899054336584\n",
      "Epoch: 597\n",
      "Loss: \n",
      "Training: 1.8495210936312365 Test: 1.0345301703526668\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7666907433718557 Test: 1.0710035059756753\n",
      "Epoch: 598\n",
      "Loss: \n",
      "Training: 1.9192264565357995 Test: 1.044329109889368\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7547030157695414 Test: 1.0709879016506527\n",
      "Epoch: 599\n",
      "Loss: \n",
      "Training: 1.794520264369129 Test: 1.0935022183069532\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7725063236579437 Test: 1.0695567171196472\n",
      "Epoch: 600\n",
      "Loss: \n",
      "Training: 1.6817555623785507 Test: 1.013195793054713\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8028146292209333 Test: 1.073388825705103\n",
      "Epoch: 601\n",
      "Loss: \n",
      "Training: 2.0126923353350157 Test: 1.0812342099805092\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7966396156307742 Test: 1.0694689200701961\n",
      "Epoch: 602\n",
      "Loss: \n",
      "Training: 1.79290674395298 Test: 1.0560728473309016\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.828677696956305 Test: 1.0675103096678171\n",
      "Epoch: 603\n",
      "Loss: \n",
      "Training: 1.5948393469306277 Test: 1.1750814357768686\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8247577522561982 Test: 1.0651747471322426\n",
      "Epoch: 604\n",
      "Loss: \n",
      "Training: 1.7213470074884454 Test: 1.1118451912021907\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8110511929520847 Test: 1.0830539461943827\n",
      "Epoch: 605\n",
      "Loss: \n",
      "Training: 1.7141334939876836 Test: 1.1290071604804386\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.817554419044465 Test: 1.0849332149989135\n",
      "Epoch: 606\n",
      "Loss: \n",
      "Training: 1.9886843608771934 Test: 1.0989978154845612\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8141914166734758 Test: 1.0875272285029665\n",
      "Epoch: 607\n",
      "Loss: \n",
      "Training: 1.9626970735209353 Test: 1.01414818778356\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.806962666548666 Test: 1.083779595185917\n",
      "Epoch: 608\n",
      "Loss: \n",
      "Training: 2.056412563231623 Test: 1.146881679946439\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.818280264537636 Test: 1.0817413969290064\n",
      "Epoch: 609\n",
      "Loss: \n",
      "Training: 2.0199191905344267 Test: 1.0365423903947024\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8319988752072185 Test: 1.0919966539347135\n",
      "Epoch: 610\n",
      "Loss: \n",
      "Training: 1.7282336130464993 Test: 1.1736998205402693\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8545387678237482 Test: 1.0863006711434884\n",
      "Epoch: 611\n",
      "Loss: \n",
      "Training: 1.8553250939303925 Test: 1.076853033133405\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8591865728905428 Test: 1.102351073892044\n",
      "Epoch: 612\n",
      "Loss: \n",
      "Training: 1.8881068596879595 Test: 1.099459537563871\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8434498487500808 Test: 1.1019129562073338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 613\n",
      "Loss: \n",
      "Training: 1.7851326003221932 Test: 1.0580317156733974\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8529698603235787 Test: 1.1062516252306305\n",
      "Epoch: 614\n",
      "Loss: \n",
      "Training: 1.9292864382971335 Test: 1.1249609799818654\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8719991856627352 Test: 1.0945466532202834\n",
      "Epoch: 615\n",
      "Loss: \n",
      "Training: 1.7389983238168643 Test: 1.1384637316887405\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.892793128743604 Test: 1.095858232098251\n",
      "Epoch: 616\n",
      "Loss: \n",
      "Training: 1.859300640317495 Test: 1.0434842023430464\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8952796117265218 Test: 1.0968038892190812\n",
      "Epoch: 617\n",
      "Loss: \n",
      "Training: 1.8034713629897288 Test: 1.0759851434636223\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8823412396705526 Test: 1.0912525279049297\n",
      "Epoch: 618\n",
      "Loss: \n",
      "Training: 1.6388247649935006 Test: 1.0598354425987464\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8664186686174316 Test: 1.097436223472936\n",
      "Epoch: 619\n",
      "Loss: \n",
      "Training: 1.6267577178252208 Test: 1.0467092421897808\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8246598887936192 Test: 1.0887315997381666\n",
      "Epoch: 620\n",
      "Loss: \n",
      "Training: 1.755398995300377 Test: 1.027378416922893\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7853437415226985 Test: 1.0897482849176745\n",
      "Epoch: 621\n",
      "Loss: \n",
      "Training: 1.6365825199182122 Test: 1.1009348079639638\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7880602797480865 Test: 1.075116144555937\n",
      "Epoch: 622\n",
      "Loss: \n",
      "Training: 1.684160966614771 Test: 1.1193057062009601\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7661860223468686 Test: 1.0775243220389927\n",
      "Epoch: 623\n",
      "Loss: \n",
      "Training: 2.0425394991478703 Test: 1.0873284999348658\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7457914330395496 Test: 1.0795089389027017\n",
      "Epoch: 624\n",
      "Loss: \n",
      "Training: 1.9351221493430848 Test: 1.1095851512255517\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7715321229221175 Test: 1.0824386173288487\n",
      "Epoch: 625\n",
      "Loss: \n",
      "Training: 1.9124402641464415 Test: 1.0646218954278253\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7721156940267122 Test: 1.0809010344532173\n",
      "Epoch: 626\n",
      "Loss: \n",
      "Training: 1.6798582060515241 Test: 1.0582452626346515\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7894598880596704 Test: 1.0735168508271256\n",
      "Epoch: 627\n",
      "Loss: \n",
      "Training: 1.6357560699212248 Test: 1.238259379007845\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.771515644633073 Test: 1.0749929568562862\n",
      "Epoch: 628\n",
      "Loss: \n",
      "Training: 1.9257837051448918 Test: 1.01720834181185\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7547441153262227 Test: 1.0912203804107083\n",
      "Epoch: 629\n",
      "Loss: \n",
      "Training: 1.7267347040643544 Test: 1.033052794379699\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7834400093413616 Test: 1.0869576703320187\n",
      "Epoch: 630\n",
      "Loss: \n",
      "Training: 1.5668494336766758 Test: 1.0737279177476624\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7934377079652752 Test: 1.0855920255510105\n",
      "Epoch: 631\n",
      "Loss: \n",
      "Training: 1.6788204058651348 Test: 0.987081819448305\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7745827518029054 Test: 1.0902269756334875\n",
      "Epoch: 632\n",
      "Loss: \n",
      "Training: 1.8397963090497378 Test: 1.0614696715380885\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.778806540397597 Test: 1.0788416767819216\n",
      "Epoch: 633\n",
      "Loss: \n",
      "Training: 1.5970433941871687 Test: 1.0821936838474813\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.794370074641094 Test: 1.0730580733156343\n",
      "Epoch: 634\n",
      "Loss: \n",
      "Training: 1.9316679398102665 Test: 1.1352721730562925\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.749820464145024 Test: 1.072544591706896\n",
      "Epoch: 635\n",
      "Loss: \n",
      "Training: 1.8551565276991515 Test: 1.1331045482880215\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7494750431917425 Test: 1.0751132938899701\n",
      "Epoch: 636\n",
      "Loss: \n",
      "Training: 1.7246229646559 Test: 0.9603550116167361\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7437466695470132 Test: 1.0819615591759895\n",
      "Epoch: 637\n",
      "Loss: \n",
      "Training: 1.6617156864561329 Test: 1.0973625155447624\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7482231454074508 Test: 1.072172534074198\n",
      "Epoch: 638\n",
      "Loss: \n",
      "Training: 1.8483617740323748 Test: 1.063470579991576\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7508191070609413 Test: 1.0580828477278899\n",
      "Epoch: 639\n",
      "Loss: \n",
      "Training: 1.6896480880807525 Test: 1.0944896766460592\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7430769139496896 Test: 1.0627090715458625\n",
      "Epoch: 640\n",
      "Loss: \n",
      "Training: 1.7777918331704945 Test: 1.1497807266223021\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7393682523513294 Test: 1.0688527597724984\n",
      "Epoch: 641\n",
      "Loss: \n",
      "Training: 1.7096051912844041 Test: 1.0558452278627324\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7604624923007113 Test: 1.0764580406599624\n",
      "Epoch: 642\n",
      "Loss: \n",
      "Training: 1.9592138192145876 Test: 1.1097408270653917\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7635409708426386 Test: 1.0833343815014052\n",
      "Epoch: 643\n",
      "Loss: \n",
      "Training: 1.7214642328712708 Test: 0.9959922074588892\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7754827218591234 Test: 1.0881614970541356\n",
      "Epoch: 644\n",
      "Loss: \n",
      "Training: 1.9146308560617853 Test: 1.0886393953285125\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7879248057275334 Test: 1.0795413494152764\n",
      "Epoch: 645\n",
      "Loss: \n",
      "Training: 2.012530829643857 Test: 1.065648496170446\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7862210973526853 Test: 1.0748780716424982\n",
      "Epoch: 646\n",
      "Loss: \n",
      "Training: 1.7446133355497084 Test: 1.115106684745343\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.801958527547156 Test: 1.068132466430741\n",
      "Epoch: 647\n",
      "Loss: \n",
      "Training: 1.8186618987634275 Test: 1.1335990181893068\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8039575646365367 Test: 1.0836076337436016\n",
      "Epoch: 648\n",
      "Loss: \n",
      "Training: 1.7210910122191985 Test: 1.0993195629944446\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8196521858672665 Test: 1.0872312840080558\n",
      "Epoch: 649\n",
      "Loss: \n",
      "Training: 1.9625487105816324 Test: 1.0544392790671675\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8069251096859489 Test: 1.0908161823083427\n",
      "Epoch: 650\n",
      "Loss: \n",
      "Training: 1.6762557777335154 Test: 1.0778183468487463\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8342151719360367 Test: 1.0868111425504536\n",
      "Epoch: 651\n",
      "Loss: \n",
      "Training: 1.8512216630403309 Test: 1.0787894953433452\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.824061566392339 Test: 1.079614904573098\n",
      "Epoch: 652\n",
      "Loss: \n",
      "Training: 1.6780359098057365 Test: 1.0812064394497944\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8382232135679313 Test: 1.0819093313211592\n",
      "Epoch: 653\n",
      "Loss: \n",
      "Training: 1.8867113988913622 Test: 1.087155288545875\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8101054226270463 Test: 1.0790558925595994\n",
      "Epoch: 654\n",
      "Loss: \n",
      "Training: 1.9979313890053225 Test: 1.1009819018748908\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8266301392290554 Test: 1.088172200668298\n",
      "Epoch: 655\n",
      "Loss: \n",
      "Training: 1.9057424566427599 Test: 1.0564360783533588\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8349601925234094 Test: 1.0894064513229358\n",
      "Epoch: 656\n",
      "Loss: \n",
      "Training: 1.5494779398152145 Test: 1.0591644875908328\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8242813552232995 Test: 1.0884852095412272\n",
      "Epoch: 657\n",
      "Loss: \n",
      "Training: 1.5658325076593647 Test: 1.122430926513049\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.80476781564985 Test: 1.0828909898257764\n",
      "Epoch: 658\n",
      "Loss: \n",
      "Training: 2.0376379177723525 Test: 1.0793627367465437\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7794848765394438 Test: 1.0817741806581505\n",
      "Epoch: 659\n",
      "Loss: \n",
      "Training: 1.753463959252229 Test: 1.1002617926133054\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8111395670947594 Test: 1.0797784980333605\n",
      "Epoch: 660\n",
      "Loss: \n",
      "Training: 1.9685671790911865 Test: 1.1234847330593603\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7902310919618187 Test: 1.084360749387974\n",
      "Epoch: 661\n",
      "Loss: \n",
      "Training: 1.6652458188234072 Test: 1.0376575028425725\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.819462232097586 Test: 1.0889273880090358\n",
      "Epoch: 662\n",
      "Loss: \n",
      "Training: 1.5957517928937623 Test: 1.0642997428559224\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8008646476758936 Test: 1.0848141887589582\n",
      "Epoch: 663\n",
      "Loss: \n",
      "Training: 1.7236874531296362 Test: 1.0591617629203751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7926362359846961 Test: 1.0831235190995712\n",
      "Epoch: 664\n",
      "Loss: \n",
      "Training: 1.724449210663679 Test: 0.9991512125106149\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7763338414085237 Test: 1.0803241665370211\n",
      "Epoch: 665\n",
      "Loss: \n",
      "Training: 1.89702551620251 Test: 1.0358613201854618\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7489856235743595 Test: 1.0701410976005934\n",
      "Epoch: 666\n",
      "Loss: \n",
      "Training: 1.737238782847009 Test: 1.0848612917374503\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7481139295303343 Test: 1.068083621783804\n",
      "Epoch: 667\n",
      "Loss: \n",
      "Training: 1.9219193021513963 Test: 1.0693703323395596\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7668900138335135 Test: 1.0706533021984654\n",
      "Epoch: 668\n",
      "Loss: \n",
      "Training: 1.9658404229143198 Test: 1.1605215573100882\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.802498693282717 Test: 1.0653472427811166\n",
      "Epoch: 669\n",
      "Loss: \n",
      "Training: 1.6645210541010191 Test: 1.1981871990806112\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7953189437969133 Test: 1.073463124837471\n",
      "Epoch: 670\n",
      "Loss: \n",
      "Training: 1.6552517318949207 Test: 1.0807898127840563\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7864246532817927 Test: 1.0832556654842018\n",
      "Epoch: 671\n",
      "Loss: \n",
      "Training: 1.6707904311895454 Test: 1.081676210242696\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7550931085621664 Test: 1.0789861734566712\n",
      "Epoch: 672\n",
      "Loss: \n",
      "Training: 1.6583491351218003 Test: 1.1311133045608508\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.75564756979878 Test: 1.0833880441966834\n",
      "Epoch: 673\n",
      "Loss: \n",
      "Training: 1.7889245011532262 Test: 1.0896084179797654\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7619073040215838 Test: 1.0900694003671763\n",
      "Epoch: 674\n",
      "Loss: \n",
      "Training: 1.72144973414252 Test: 0.980105803743938\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7684310088239426 Test: 1.0931140658731153\n",
      "Epoch: 675\n",
      "Loss: \n",
      "Training: 1.7299800297165353 Test: 1.0999025339528548\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7681310611718266 Test: 1.0912095249964477\n",
      "Epoch: 676\n",
      "Loss: \n",
      "Training: 1.6921555890491322 Test: 1.0637835155052422\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7514265125232291 Test: 1.097613646373187\n",
      "Epoch: 677\n",
      "Loss: \n",
      "Training: 1.6948338867504813 Test: 1.0804799510402272\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7469181931434417 Test: 1.0955058687499664\n",
      "Epoch: 678\n",
      "Loss: \n",
      "Training: 1.954054151873911 Test: 1.097093294114867\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7242096516033503 Test: 1.096616830620033\n",
      "Epoch: 679\n",
      "Loss: \n",
      "Training: 1.6780500752587892 Test: 1.1262249492526162\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7230310244993092 Test: 1.0902740043005108\n",
      "Epoch: 680\n",
      "Loss: \n",
      "Training: 1.8623183074460818 Test: 1.0895262475468008\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.724383926615086 Test: 1.0830777793177113\n",
      "Epoch: 681\n",
      "Loss: \n",
      "Training: 1.8437504908666957 Test: 1.1168688587417883\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.745090584170202 Test: 1.083951422793986\n",
      "Epoch: 682\n",
      "Loss: \n",
      "Training: 1.848680930809867 Test: 1.021961481207565\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7623865901379172 Test: 1.0874706876438949\n",
      "Epoch: 683\n",
      "Loss: \n",
      "Training: 1.861238511133748 Test: 1.0939823648647926\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.781419769706724 Test: 1.0765555053085665\n",
      "Epoch: 684\n",
      "Loss: \n",
      "Training: 1.7074551163553222 Test: 1.1000143737612118\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7886511707047763 Test: 1.0769928999970693\n",
      "Epoch: 685\n",
      "Loss: \n",
      "Training: 1.6638594659180808 Test: 1.1311790068190166\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7872517089260564 Test: 1.0889837569987966\n",
      "Epoch: 686\n",
      "Loss: \n",
      "Training: 1.8062669300145158 Test: 1.0278811055317374\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.780639652546211 Test: 1.0921114042854128\n",
      "Epoch: 687\n",
      "Loss: \n",
      "Training: 1.6709251016350748 Test: 1.0849161676222927\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7920507866427493 Test: 1.0885211632880623\n",
      "Epoch: 688\n",
      "Loss: \n",
      "Training: 1.7357824909469828 Test: 1.070534267687639\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7896599081312086 Test: 1.088964784946269\n",
      "Epoch: 689\n",
      "Loss: \n",
      "Training: 1.5744680314828396 Test: 1.1643888202232444\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7678327420385158 Test: 1.086308882303546\n",
      "Epoch: 690\n",
      "Loss: \n",
      "Training: 1.5904581781001714 Test: 1.1145058502693348\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.757474537660921 Test: 1.090125269400609\n",
      "Epoch: 691\n",
      "Loss: \n",
      "Training: 1.8369071165803694 Test: 1.0759783091884645\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7302885247263298 Test: 1.0926232296728624\n",
      "Epoch: 692\n",
      "Loss: \n",
      "Training: 1.784244474665494 Test: 1.0647661247420102\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.729604187297697 Test: 1.08853417471753\n",
      "Epoch: 693\n",
      "Loss: \n",
      "Training: 1.9217334522138403 Test: 1.1429380005463572\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.72316054168326 Test: 1.0928146390709745\n",
      "Epoch: 694\n",
      "Loss: \n",
      "Training: 1.7455765289631373 Test: 1.0881771356552148\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7292100357912692 Test: 1.097710202639131\n",
      "Epoch: 695\n",
      "Loss: \n",
      "Training: 1.692822842542902 Test: 1.0380945171404632\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7330221770520506 Test: 1.0965264788285312\n",
      "Epoch: 696\n",
      "Loss: \n",
      "Training: 1.792829341090332 Test: 1.0288405688265951\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7359185147145328 Test: 1.087218029860676\n",
      "Epoch: 697\n",
      "Loss: \n",
      "Training: 1.5496823879217596 Test: 1.0082154258751235\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7345747558221145 Test: 1.0873139761901616\n",
      "Epoch: 698\n",
      "Loss: \n",
      "Training: 1.7589113636777678 Test: 1.1262282306372917\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.722450484450783 Test: 1.0796439020154447\n",
      "Epoch: 699\n",
      "Loss: \n",
      "Training: 1.980313063695381 Test: 0.9975287808682185\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7247633717238613 Test: 1.08521329831041\n",
      "Epoch: 700\n",
      "Loss: \n",
      "Training: 1.5486729778090182 Test: 1.0884652555970689\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7653478749451157 Test: 1.0685272943749076\n",
      "Epoch: 701\n",
      "Loss: \n",
      "Training: 1.7903982672021697 Test: 1.0908797568848245\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7611693549160001 Test: 1.0659232349076806\n",
      "Epoch: 702\n",
      "Loss: \n",
      "Training: 1.8634881039093452 Test: 1.0933742122711154\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.75651846997818 Test: 1.0674133796773166\n",
      "Epoch: 703\n",
      "Loss: \n",
      "Training: 1.893568035933139 Test: 1.122584509078907\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.764442832902565 Test: 1.0702741884302271\n",
      "Epoch: 704\n",
      "Loss: \n",
      "Training: 1.951540358994581 Test: 1.1118985093212088\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.761626291274495 Test: 1.0682388392834823\n",
      "Epoch: 705\n",
      "Loss: \n",
      "Training: 1.8576010451901888 Test: 1.0963367266774284\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7822226742776395 Test: 1.0706109766500818\n",
      "Epoch: 706\n",
      "Loss: \n",
      "Training: 1.7373236859966323 Test: 1.145421305866076\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7987004945423686 Test: 1.0764351976037783\n",
      "Epoch: 707\n",
      "Loss: \n",
      "Training: 1.893751280356791 Test: 1.0285365353360918\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7931499290329984 Test: 1.0880932713077263\n",
      "Epoch: 708\n",
      "Loss: \n",
      "Training: 1.6758270645100968 Test: 1.09172448524358\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8275568182765014 Test: 1.090125382253823\n",
      "Epoch: 709\n",
      "Loss: \n",
      "Training: 1.7450324965675212 Test: 1.0830557283903406\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8192483883597341 Test: 1.0866750077144518\n",
      "Epoch: 710\n",
      "Loss: \n",
      "Training: 1.5838272962711053 Test: 1.1378895036351222\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7957203316469486 Test: 1.095227702466664\n",
      "Epoch: 711\n",
      "Loss: \n",
      "Training: 1.794117858176055 Test: 1.0566145527091018\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7992357634931568 Test: 1.1001701272704696\n",
      "Epoch: 712\n",
      "Loss: \n",
      "Training: 1.6849304629531117 Test: 1.109659215280273\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7996077225905456 Test: 1.0967436068528973\n",
      "Epoch: 713\n",
      "Loss: \n",
      "Training: 1.689155495489573 Test: 1.033019334846252\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.781751958494922 Test: 1.0983721071538128\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 714\n",
      "Loss: \n",
      "Training: 1.7639915441494296 Test: 1.1541566791794815\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7613107044505658 Test: 1.0894155897305473\n",
      "Epoch: 715\n",
      "Loss: \n",
      "Training: 1.6629790906110222 Test: 1.0414639395662975\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7425558229660503 Test: 1.0936414067163747\n",
      "Epoch: 716\n",
      "Loss: \n",
      "Training: 1.8646702551647911 Test: 1.0689341251571454\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7230936275081337 Test: 1.0881541280052613\n",
      "Epoch: 717\n",
      "Loss: \n",
      "Training: 1.8385906646928978 Test: 1.106928865152841\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7358282844249497 Test: 1.0805054099343683\n",
      "Epoch: 718\n",
      "Loss: \n",
      "Training: 1.918826367669353 Test: 1.090108681839728\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7303122228585603 Test: 1.0883446429160435\n",
      "Epoch: 719\n",
      "Loss: \n",
      "Training: 1.698660260245268 Test: 1.09425883400328\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7546121531744858 Test: 1.0881830625756583\n",
      "Epoch: 720\n",
      "Loss: \n",
      "Training: 1.8212971668640003 Test: 1.127749189785391\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.749974929542261 Test: 1.0893033731369524\n",
      "Epoch: 721\n",
      "Loss: \n",
      "Training: 1.7187587528523447 Test: 1.050232046809896\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7737219166015499 Test: 1.088289341751979\n",
      "Epoch: 722\n",
      "Loss: \n",
      "Training: 1.8737980614875391 Test: 1.0052928997642372\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.766186006069179 Test: 1.0876510911620585\n",
      "Epoch: 723\n",
      "Loss: \n",
      "Training: 1.7252272744834722 Test: 1.051169649799552\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.785072765922622 Test: 1.077214459610455\n",
      "Epoch: 724\n",
      "Loss: \n",
      "Training: 1.700578892786768 Test: 1.1608894651910038\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7886799438220116 Test: 1.0790294911057852\n",
      "Epoch: 725\n",
      "Loss: \n",
      "Training: 1.6614977351968787 Test: 1.0779432488266776\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7823386786857458 Test: 1.079702769706937\n",
      "Epoch: 726\n",
      "Loss: \n",
      "Training: 1.8615902856163384 Test: 1.0400095104834894\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7821905431443312 Test: 1.0833507006329752\n",
      "Epoch: 727\n",
      "Loss: \n",
      "Training: 1.7465460516316165 Test: 1.0428061197243814\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.781882546189486 Test: 1.0804582391656097\n",
      "Epoch: 728\n",
      "Loss: \n",
      "Training: 1.909985850589444 Test: 1.0292782037058843\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7726780848833577 Test: 1.0740459646227638\n",
      "Epoch: 729\n",
      "Loss: \n",
      "Training: 1.7300109910456944 Test: 1.0975813739461482\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.771794033175367 Test: 1.0679629168093794\n",
      "Epoch: 730\n",
      "Loss: \n",
      "Training: 1.9394477450144525 Test: 1.1224836882221905\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7749291062554096 Test: 1.068295170803666\n",
      "Epoch: 731\n",
      "Loss: \n",
      "Training: 1.8293824579750055 Test: 0.9782791465921503\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7867441640704549 Test: 1.0677686206473462\n",
      "Epoch: 732\n",
      "Loss: \n",
      "Training: 1.7111482569674477 Test: 1.0350424487997025\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7978065345827208 Test: 1.0605733306255716\n",
      "Epoch: 733\n",
      "Loss: \n",
      "Training: 1.5669908369024974 Test: 1.1593091538021427\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7815415541307118 Test: 1.063548285529118\n",
      "Epoch: 734\n",
      "Loss: \n",
      "Training: 1.7326375254522532 Test: 0.9848908523744578\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7657179103726146 Test: 1.074362235929377\n",
      "Epoch: 735\n",
      "Loss: \n",
      "Training: 1.84199650299988 Test: 1.0861777101993197\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7689237736391632 Test: 1.0567623746477226\n",
      "Epoch: 736\n",
      "Loss: \n",
      "Training: 1.933662023108412 Test: 1.0923133735421913\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.786973650419463 Test: 1.0575858207849866\n",
      "Epoch: 737\n",
      "Loss: \n",
      "Training: 1.6516270555926573 Test: 1.1073123312254065\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.79418082416867 Test: 1.062816207090857\n",
      "Epoch: 738\n",
      "Loss: \n",
      "Training: 1.5839338848764897 Test: 1.1779249413552242\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7846889245647746 Test: 1.0692668282409596\n",
      "Epoch: 739\n",
      "Loss: \n",
      "Training: 1.6419982611647195 Test: 1.0795444720938203\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.752083727993479 Test: 1.0841315020058935\n",
      "Epoch: 740\n",
      "Loss: \n",
      "Training: 1.814345772107981 Test: 1.1224805965381386\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7432824550053816 Test: 1.0823278118206605\n",
      "Epoch: 741\n",
      "Loss: \n",
      "Training: 1.987894126112294 Test: 0.9922604617115703\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7307722577147344 Test: 1.0823275026522556\n",
      "Epoch: 742\n",
      "Loss: \n",
      "Training: 1.6515685070786927 Test: 1.1087085563702404\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.746623424528463 Test: 1.0837256341641974\n",
      "Epoch: 743\n",
      "Loss: \n",
      "Training: 1.9642150910221008 Test: 0.9968990658949992\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7406654495395877 Test: 1.0910922449212512\n",
      "Epoch: 744\n",
      "Loss: \n",
      "Training: 1.8752132314173608 Test: 1.0659157222925306\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.780387874951548 Test: 1.0748512361305367\n",
      "Epoch: 745\n",
      "Loss: \n",
      "Training: 1.9386691822768742 Test: 1.0775291389747355\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7946454455480587 Test: 1.0829537231223438\n",
      "Epoch: 746\n",
      "Loss: \n",
      "Training: 1.8221129017924438 Test: 1.0656330438678838\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8043127134757584 Test: 1.0820888659998857\n",
      "Epoch: 747\n",
      "Loss: \n",
      "Training: 1.803128317204432 Test: 1.0753426538755357\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7931578013441616 Test: 1.0794208330324548\n",
      "Epoch: 748\n",
      "Loss: \n",
      "Training: 2.1367094561684916 Test: 1.120811198086024\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8083079275053386 Test: 1.0762238652974678\n",
      "Epoch: 749\n",
      "Loss: \n",
      "Training: 1.8578444582445826 Test: 1.1349146546650013\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8635854846345392 Test: 1.070512490970548\n",
      "Epoch: 750\n",
      "Loss: \n",
      "Training: 1.5473153079233843 Test: 1.0649488883455627\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8851701043425255 Test: 1.076049509227666\n",
      "Epoch: 751\n",
      "Loss: \n",
      "Training: 2.0423528163611886 Test: 1.0589111984747788\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8584670579240654 Test: 1.0702963384084083\n",
      "Epoch: 752\n",
      "Loss: \n",
      "Training: 1.6072278048223738 Test: 1.006929964156865\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8639129269489552 Test: 1.076961412084729\n",
      "Epoch: 753\n",
      "Loss: \n",
      "Training: 1.9044684202032862 Test: 0.9740645761815461\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8594788567233231 Test: 1.0667835528633915\n",
      "Epoch: 754\n",
      "Loss: \n",
      "Training: 1.7695589541668255 Test: 1.1500154609933753\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8535041896414417 Test: 1.0645001038920463\n",
      "Epoch: 755\n",
      "Loss: \n",
      "Training: 1.7327783285790195 Test: 1.0915416760145926\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.842938761916388 Test: 1.0729100777621308\n",
      "Epoch: 756\n",
      "Loss: \n",
      "Training: 1.768309283146823 Test: 1.2014866096963968\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8223496765466027 Test: 1.0743113314661166\n",
      "Epoch: 757\n",
      "Loss: \n",
      "Training: 1.7797910970266144 Test: 1.1300327077872634\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8169693146820407 Test: 1.087896688048968\n",
      "Epoch: 758\n",
      "Loss: \n",
      "Training: 1.9209283676905093 Test: 1.0312979454865354\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8146355926642588 Test: 1.0933656934401408\n",
      "Epoch: 759\n",
      "Loss: \n",
      "Training: 1.854369720947051 Test: 1.13686637747406\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.793057483816461 Test: 1.0844143681801919\n",
      "Epoch: 760\n",
      "Loss: \n",
      "Training: 2.08279406245893 Test: 1.1032806591239694\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7927100100867075 Test: 1.0846095404610978\n",
      "Epoch: 761\n",
      "Loss: \n",
      "Training: 1.6235052474056495 Test: 1.1158245193024332\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8462578855402623 Test: 1.0884427175389384\n",
      "Epoch: 762\n",
      "Loss: \n",
      "Training: 1.6113561306657418 Test: 1.1098737691002265\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.804373128644708 Test: 1.0941340496217038\n",
      "Epoch: 763\n",
      "Loss: \n",
      "Training: 1.7953847150892521 Test: 1.1371430066770045\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8047859612290449 Test: 1.1044284301160399\n",
      "Epoch: 764\n",
      "Loss: \n",
      "Training: 1.845544171664221 Test: 1.0783807801777041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7938775907176416 Test: 1.1207362731655857\n",
      "Epoch: 765\n",
      "Loss: \n",
      "Training: 1.998422123834212 Test: 1.0509178612160308\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.801476112467381 Test: 1.1135728050840186\n",
      "Epoch: 766\n",
      "Loss: \n",
      "Training: 1.8510269229809482 Test: 1.0747196846488687\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8280404919929005 Test: 1.1095104236041622\n",
      "Epoch: 767\n",
      "Loss: \n",
      "Training: 1.7212691723441422 Test: 1.065572497151006\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.836312255976313 Test: 1.0968337310994096\n",
      "Epoch: 768\n",
      "Loss: \n",
      "Training: 1.7005832952467705 Test: 1.041599987997565\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8304600635080661 Test: 1.090387710035784\n",
      "Epoch: 769\n",
      "Loss: \n",
      "Training: 1.6651210354921873 Test: 1.001938288606843\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8084255562636915 Test: 1.0914179142868867\n",
      "Epoch: 770\n",
      "Loss: \n",
      "Training: 1.7106403346363845 Test: 1.071159436008893\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7895006877182056 Test: 1.077925105400165\n",
      "Epoch: 771\n",
      "Loss: \n",
      "Training: 1.6136406939781514 Test: 1.0619599640180268\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.752285314935951 Test: 1.0747129830886573\n",
      "Epoch: 772\n",
      "Loss: \n",
      "Training: 1.9623669975358726 Test: 1.0943878018906685\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.751298859593201 Test: 1.0693265275602168\n",
      "Epoch: 773\n",
      "Loss: \n",
      "Training: 1.6847818191259103 Test: 1.0538926381742926\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.786399946280214 Test: 1.067777930839261\n",
      "Epoch: 774\n",
      "Loss: \n",
      "Training: 1.5974899974421874 Test: 1.0832752335112437\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.77533965668388 Test: 1.05945289398899\n",
      "Epoch: 775\n",
      "Loss: \n",
      "Training: 1.9742530473916953 Test: 1.039413589530252\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7505342392616767 Test: 1.059942339322344\n",
      "Epoch: 776\n",
      "Loss: \n",
      "Training: 1.9228508327030795 Test: 1.0984983253643281\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.748117331617425 Test: 1.058791912153766\n",
      "Epoch: 777\n",
      "Loss: \n",
      "Training: 1.7185931063842212 Test: 1.0767460202864694\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.755299722589638 Test: 1.0611697762253118\n",
      "Epoch: 778\n",
      "Loss: \n",
      "Training: 1.6748159933211477 Test: 1.0623664215311523\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.755032115993646 Test: 1.0622871285388584\n",
      "Epoch: 779\n",
      "Loss: \n",
      "Training: 2.080205964353197 Test: 1.143888489075126\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7524553858010836 Test: 1.064363771892217\n",
      "Epoch: 780\n",
      "Loss: \n",
      "Training: 1.5861517585264981 Test: 1.0797048277965413\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7939638786871845 Test: 1.0785587919390451\n",
      "Epoch: 781\n",
      "Loss: \n",
      "Training: 1.9344566836386885 Test: 1.0513167275787674\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.781515021076196 Test: 1.07941333111781\n",
      "Epoch: 782\n",
      "Loss: \n",
      "Training: 1.8449855993795112 Test: 1.0634448746136471\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8135966200422498 Test: 1.0783490074738842\n",
      "Epoch: 783\n",
      "Loss: \n",
      "Training: 1.6967947374832342 Test: 1.0751723445638586\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.801858480226614 Test: 1.075254714746182\n",
      "Epoch: 784\n",
      "Loss: \n",
      "Training: 1.5999548319268948 Test: 1.1275336330280556\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8030597720623458 Test: 1.0773826853851385\n",
      "Epoch: 785\n",
      "Loss: \n",
      "Training: 1.874467146885213 Test: 1.0603196610241061\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8033062555108166 Test: 1.08180852533682\n",
      "Epoch: 786\n",
      "Loss: \n",
      "Training: 1.941899648712656 Test: 1.0730975310929525\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7933276654601684 Test: 1.0838991324862053\n",
      "Epoch: 787\n",
      "Loss: \n",
      "Training: 1.7622553289780798 Test: 1.08202295267659\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7952325470611261 Test: 1.0813590530590678\n",
      "Epoch: 788\n",
      "Loss: \n",
      "Training: 1.8601476044060832 Test: 1.121088461862459\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.799598769320512 Test: 1.0818867462980797\n",
      "Epoch: 789\n",
      "Loss: \n",
      "Training: 1.9442796997566216 Test: 1.0403919577345409\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8181319304290056 Test: 1.0877589503312104\n",
      "Epoch: 790\n",
      "Loss: \n",
      "Training: 1.796579549197985 Test: 1.0813883800179782\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.804539303969348 Test: 1.0774092971971518\n",
      "Epoch: 791\n",
      "Loss: \n",
      "Training: 1.8402441154960136 Test: 1.0748851303586637\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8255820830364968 Test: 1.0775776524192957\n",
      "Epoch: 792\n",
      "Loss: \n",
      "Training: 1.716079113624888 Test: 1.0756372117741955\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8161608262222295 Test: 1.0799344926972851\n",
      "Epoch: 793\n",
      "Loss: \n",
      "Training: 1.8104469288803744 Test: 1.1250895034478188\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8032701776467672 Test: 1.0811537264133402\n",
      "Epoch: 794\n",
      "Loss: \n",
      "Training: 1.8247199916073524 Test: 1.1047944162461667\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8146353967864808 Test: 1.0861454423017363\n",
      "Epoch: 795\n",
      "Loss: \n",
      "Training: 1.6227039418115405 Test: 1.0707988791768053\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8371119127545268 Test: 1.0838715206235472\n",
      "Epoch: 796\n",
      "Loss: \n",
      "Training: 1.869229106890753 Test: 1.1047118356781584\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8119355922471592 Test: 1.084919442438817\n",
      "Epoch: 797\n",
      "Loss: \n",
      "Training: 1.7557050613297513 Test: 1.081716292858641\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8046685380649692 Test: 1.0880808728973377\n",
      "Epoch: 798\n",
      "Loss: \n",
      "Training: 1.9022299328125942 Test: 1.1160463559141562\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8040135113001365 Test: 1.0880502069155427\n",
      "Epoch: 799\n",
      "Loss: \n",
      "Training: 1.7182798839942957 Test: 1.080744274107202\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8082217441407877 Test: 1.0875459963207121\n",
      "Epoch: 800\n",
      "Loss: \n",
      "Training: 1.7454620282249098 Test: 0.9900101432664247\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.785621762564555 Test: 1.0915812279579786\n",
      "Epoch: 801\n",
      "Loss: \n",
      "Training: 1.7541948148695783 Test: 1.1164308343177904\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7805100104672473 Test: 1.0824434042828233\n",
      "Epoch: 802\n",
      "Loss: \n",
      "Training: 1.9744407498013261 Test: 1.059413707291603\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7719050804046037 Test: 1.0865979746787358\n",
      "Epoch: 803\n",
      "Loss: \n",
      "Training: 1.7693564368415429 Test: 1.1237481409622614\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7977412440222473 Test: 1.0849756242304767\n",
      "Epoch: 804\n",
      "Loss: \n",
      "Training: 1.7234026663859623 Test: 1.0689425011108942\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7936321948183642 Test: 1.0848414879819208\n",
      "Epoch: 805\n",
      "Loss: \n",
      "Training: 1.9073844361095393 Test: 1.0277270331602468\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7835004622962256 Test: 1.0812562964683936\n",
      "Epoch: 806\n",
      "Loss: \n",
      "Training: 1.911952535031336 Test: 1.077372805922512\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.811968511726025 Test: 1.0769491118667378\n",
      "Epoch: 807\n",
      "Loss: \n",
      "Training: 1.6743604291240908 Test: 1.0296878910047844\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8162408545400832 Test: 1.074215208891173\n",
      "Epoch: 808\n",
      "Loss: \n",
      "Training: 1.7980404055059236 Test: 1.1659571112363805\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8081063913195172 Test: 1.0690123687057873\n",
      "Epoch: 809\n",
      "Loss: \n",
      "Training: 1.7589452831657408 Test: 1.1329521523392356\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7976874385888504 Test: 1.0740034442380098\n",
      "Epoch: 810\n",
      "Loss: \n",
      "Training: 1.8959239552611398 Test: 1.1290795499345359\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8017539785059948 Test: 1.0792242320612133\n",
      "Epoch: 811\n",
      "Loss: \n",
      "Training: 1.7500456221188183 Test: 1.1053211905135036\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8168001712096182 Test: 1.0931311727280244\n",
      "Epoch: 812\n",
      "Loss: \n",
      "Training: 1.7662173666788057 Test: 1.0838237979118093\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8163852519345423 Test: 1.0920202083475958\n",
      "Epoch: 813\n",
      "Loss: \n",
      "Training: 1.6890536900605162 Test: 1.0602380735554335\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.79556291362229 Test: 1.0944612174096164\n",
      "Epoch: 814\n",
      "Loss: \n",
      "Training: 1.6948790216153962 Test: 1.1231762937271819\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.787532638944187 Test: 1.0881102106689335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 815\n",
      "Loss: \n",
      "Training: 1.5761710702384573 Test: 1.127057930486855\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7846802744671304 Test: 1.0935335899305625\n",
      "Epoch: 816\n",
      "Loss: \n",
      "Training: 1.7602243407856364 Test: 1.1251468830363074\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7515589378800225 Test: 1.103466679663223\n",
      "Epoch: 817\n",
      "Loss: \n",
      "Training: 1.9011899701215962 Test: 1.070567274132658\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7363861184554525 Test: 1.1082440873746027\n",
      "Epoch: 818\n",
      "Loss: \n",
      "Training: 1.8358201178241416 Test: 1.031666219810358\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7590690725552034 Test: 1.11233202568739\n",
      "Epoch: 819\n",
      "Loss: \n",
      "Training: 1.586397350145086 Test: 0.9872600309032762\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.762847043787025 Test: 1.0989029365447878\n",
      "Epoch: 820\n",
      "Loss: \n",
      "Training: 2.0051008056936084 Test: 1.0541225829977403\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7455922504849597 Test: 1.084333724401192\n",
      "Epoch: 821\n",
      "Loss: \n",
      "Training: 1.8060294129330594 Test: 1.070042438652877\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7565099355282066 Test: 1.0768380277075122\n",
      "Epoch: 822\n",
      "Loss: \n",
      "Training: 1.8951227153387973 Test: 1.033366421210386\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7621083146096304 Test: 1.0733101525214495\n",
      "Epoch: 823\n",
      "Loss: \n",
      "Training: 1.8578422412904083 Test: 0.9998809160058251\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7749988494756295 Test: 1.0682644148513072\n",
      "Epoch: 824\n",
      "Loss: \n",
      "Training: 1.6421312226993576 Test: 1.060554210317509\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7918777045986185 Test: 1.0622286990963468\n",
      "Epoch: 825\n",
      "Loss: \n",
      "Training: 1.647736749762532 Test: 1.0695152713913825\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7866029247070148 Test: 1.0559664907553794\n",
      "Epoch: 826\n",
      "Loss: \n",
      "Training: 1.921543907545411 Test: 1.068432941192378\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7937594926594222 Test: 1.0502122248458319\n",
      "Epoch: 827\n",
      "Loss: \n",
      "Training: 1.917968804322116 Test: 1.093854756239969\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8098914493353995 Test: 1.0445408306614392\n",
      "Epoch: 828\n",
      "Loss: \n",
      "Training: 1.792974035756529 Test: 1.0560353918550438\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8115693327554514 Test: 1.0468695788721702\n",
      "Epoch: 829\n",
      "Loss: \n",
      "Training: 1.5250148676283566 Test: 1.145415891771526\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.80728472454869 Test: 1.0493064960766387\n",
      "Epoch: 830\n",
      "Loss: \n",
      "Training: 1.7159222618932033 Test: 1.08389266776577\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8011464762970175 Test: 1.0651220821634637\n",
      "Epoch: 831\n",
      "Loss: \n",
      "Training: 1.749254007339928 Test: 1.1287241563806338\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7722286219169774 Test: 1.0680990906402665\n",
      "Epoch: 832\n",
      "Loss: \n",
      "Training: 1.628839272887991 Test: 1.0125939001712645\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7665510813576641 Test: 1.0739672624130425\n",
      "Epoch: 833\n",
      "Loss: \n",
      "Training: 1.7850859096209228 Test: 1.1089122867778165\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7399227371125836 Test: 1.07189001030913\n",
      "Epoch: 834\n",
      "Loss: \n",
      "Training: 2.105221188065665 Test: 1.1170752711199003\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7326471039456348 Test: 1.082793147386329\n",
      "Epoch: 835\n",
      "Loss: \n",
      "Training: 1.7855872780506068 Test: 1.1804846698968763\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7789561004822656 Test: 1.0884452534665683\n",
      "Epoch: 836\n",
      "Loss: \n",
      "Training: 1.7234613473674791 Test: 1.0835856610737984\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7927411533110729 Test: 1.0995421933171177\n",
      "Epoch: 837\n",
      "Loss: \n",
      "Training: 1.6068262603733987 Test: 1.132015219437409\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7729328972932799 Test: 1.1010574653052596\n",
      "Epoch: 838\n",
      "Loss: \n",
      "Training: 1.7351945825737927 Test: 1.1238859832471066\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.741818642898408 Test: 1.104873511625004\n",
      "Epoch: 839\n",
      "Loss: \n",
      "Training: 2.100575582346154 Test: 1.0051436186025318\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7360406975801344 Test: 1.1116585707642102\n",
      "Epoch: 840\n",
      "Loss: \n",
      "Training: 2.051399593636514 Test: 1.1254341715010374\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.793596769051914 Test: 1.0976313434473108\n",
      "Epoch: 841\n",
      "Loss: \n",
      "Training: 1.7676772500607458 Test: 1.0542636475802152\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8271445022262451 Test: 1.1017854938208376\n",
      "Epoch: 842\n",
      "Loss: \n",
      "Training: 1.7431065028162052 Test: 1.1053032467809494\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8289868264983273 Test: 1.0943394429407958\n",
      "Epoch: 843\n",
      "Loss: \n",
      "Training: 1.6329104441703892 Test: 1.1421211267483677\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8404135494911482 Test: 1.103610377601764\n",
      "Epoch: 844\n",
      "Loss: \n",
      "Training: 1.6897593692815926 Test: 1.1074750440967378\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.825196002946095 Test: 1.1069312615988192\n",
      "Epoch: 845\n",
      "Loss: \n",
      "Training: 1.8498084053009605 Test: 1.142471458111709\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7836498210676879 Test: 1.105971238896503\n",
      "Epoch: 846\n",
      "Loss: \n",
      "Training: 1.6740316223138907 Test: 1.0416325209142052\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7900719337927236 Test: 1.1021699177179862\n",
      "Epoch: 847\n",
      "Loss: \n",
      "Training: 1.670611680700888 Test: 1.1475367203105238\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7851289612873646 Test: 1.097974603702027\n",
      "Epoch: 848\n",
      "Loss: \n",
      "Training: 1.825472958276972 Test: 1.0503875749532166\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7915075033201133 Test: 1.0995267537893383\n",
      "Epoch: 849\n",
      "Loss: \n",
      "Training: 1.7885477764014304 Test: 1.047792240369664\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8005353408904312 Test: 1.0921769129599492\n",
      "Epoch: 850\n",
      "Loss: \n",
      "Training: 1.9981314931970904 Test: 1.1768468363110878\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7693325602959589 Test: 1.0964417751366624\n",
      "Epoch: 851\n",
      "Loss: \n",
      "Training: 1.7221663452606744 Test: 1.0624131505763246\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7640057502520166 Test: 1.1015830416176675\n",
      "Epoch: 852\n",
      "Loss: \n",
      "Training: 1.5703407471122797 Test: 1.1050477559430691\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7594546597720093 Test: 1.1023979919172784\n",
      "Epoch: 853\n",
      "Loss: \n",
      "Training: 1.9832458861928972 Test: 1.1530697355337556\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7421780842016168 Test: 1.1023724428334905\n",
      "Epoch: 854\n",
      "Loss: \n",
      "Training: 1.5754650298027593 Test: 1.1641679236136724\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7772116284038677 Test: 1.1034673037120293\n",
      "Epoch: 855\n",
      "Loss: \n",
      "Training: 1.984264852307437 Test: 1.0755619490115456\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7657821944559846 Test: 1.1091365916637226\n",
      "Epoch: 856\n",
      "Loss: \n",
      "Training: 1.5954668291561598 Test: 1.1134755145505346\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.779227839156632 Test: 1.1024456407537062\n",
      "Epoch: 857\n",
      "Loss: \n",
      "Training: 1.9249180962717027 Test: 1.1077651048284616\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7713713598408585 Test: 1.109629940117339\n",
      "Epoch: 858\n",
      "Loss: \n",
      "Training: 1.8182190357728596 Test: 1.1076374825234374\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7968020013979402 Test: 1.1056527785691332\n",
      "Epoch: 859\n",
      "Loss: \n",
      "Training: 1.698620995447524 Test: 1.096240307498372\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7960766091475289 Test: 1.111377769326155\n",
      "Epoch: 860\n",
      "Loss: \n",
      "Training: 2.004987362065382 Test: 1.0810727640249238\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7870839310521383 Test: 1.116222576039026\n",
      "Epoch: 861\n",
      "Loss: \n",
      "Training: 1.5230096287231312 Test: 1.0632074109497613\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7877695179389677 Test: 1.1066451688104095\n",
      "Epoch: 862\n",
      "Loss: \n",
      "Training: 1.6185976516986567 Test: 1.1626389958854164\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7678538462852131 Test: 1.1067245948477535\n",
      "Epoch: 863\n",
      "Loss: \n",
      "Training: 1.8572472511518965 Test: 1.0656417564110903\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7726795367438508 Test: 1.1124837188419883\n",
      "Epoch: 864\n",
      "Loss: \n",
      "Training: 1.636211142572093 Test: 1.0258242957117059\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7600796732397508 Test: 1.1037409209297215\n",
      "Epoch: 865\n",
      "Loss: \n",
      "Training: 1.9499354575826062 Test: 1.1241720237260577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7661542845166842 Test: 1.0899065581395249\n",
      "Epoch: 866\n",
      "Loss: \n",
      "Training: 1.7595440374373659 Test: 1.0404320674318293\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.762721345044201 Test: 1.094767565610976\n",
      "Epoch: 867\n",
      "Loss: \n",
      "Training: 1.7274653685063819 Test: 1.0522356452170676\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7791290658723216 Test: 1.0874632208991055\n",
      "Epoch: 868\n",
      "Loss: \n",
      "Training: 1.8899015275431774 Test: 1.06184860829198\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7593837930957896 Test: 1.081910274937966\n",
      "Epoch: 869\n",
      "Loss: \n",
      "Training: 1.7651332492077692 Test: 1.0577398139407688\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7665520422728214 Test: 1.0773313875148205\n",
      "Epoch: 870\n",
      "Loss: \n",
      "Training: 1.8785058612400958 Test: 1.1617428135021337\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7732032676488458 Test: 1.0734813381590602\n",
      "Epoch: 871\n",
      "Loss: \n",
      "Training: 1.767185163244882 Test: 1.1321317844721734\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7605551175663172 Test: 1.0815483431067812\n",
      "Epoch: 872\n",
      "Loss: \n",
      "Training: 1.8536643695210004 Test: 1.02402265566923\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7849726710184926 Test: 1.0884407804590224\n",
      "Epoch: 873\n",
      "Loss: \n",
      "Training: 1.6799226327792112 Test: 1.1269599084268214\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8084793428007266 Test: 1.0745791464374037\n",
      "Epoch: 874\n",
      "Loss: \n",
      "Training: 1.6999960948481891 Test: 1.133223531931723\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.790746880963458 Test: 1.0807109616389767\n",
      "Epoch: 875\n",
      "Loss: \n",
      "Training: 1.7395684023687534 Test: 1.1535882605329344\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7971253761910677 Test: 1.0914508852609786\n",
      "Epoch: 876\n",
      "Loss: \n",
      "Training: 1.903872351630346 Test: 1.0980204327112273\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7760886706696826 Test: 1.0943925089416662\n",
      "Epoch: 877\n",
      "Loss: \n",
      "Training: 1.600342441438772 Test: 1.0275712488573125\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7905215020889806 Test: 1.100151345469606\n",
      "Epoch: 878\n",
      "Loss: \n",
      "Training: 1.8330180890793677 Test: 1.0540801203155858\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.77780920938222 Test: 1.0976849058336302\n",
      "Epoch: 879\n",
      "Loss: \n",
      "Training: 1.8766559391252637 Test: 1.0056269459670364\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7721208655358385 Test: 1.096908057035991\n",
      "Epoch: 880\n",
      "Loss: \n",
      "Training: 1.764313660061573 Test: 1.025604483332283\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7832731345275878 Test: 1.0916967702386176\n",
      "Epoch: 881\n",
      "Loss: \n",
      "Training: 1.889977776475736 Test: 1.0898297849151688\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7718539144097356 Test: 1.0780829372216325\n",
      "Epoch: 882\n",
      "Loss: \n",
      "Training: 2.003310374773391 Test: 1.0574490061230095\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7841331757328214 Test: 1.0738527372659321\n",
      "Epoch: 883\n",
      "Loss: \n",
      "Training: 2.0336537302769786 Test: 1.1442177815145538\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7990977762580602 Test: 1.0771953723113104\n",
      "Epoch: 884\n",
      "Loss: \n",
      "Training: 1.723333858904599 Test: 1.1174846107450889\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.834470886007837 Test: 1.0789211596200836\n",
      "Epoch: 885\n",
      "Loss: \n",
      "Training: 1.7357917388959614 Test: 1.0684217957771092\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8368046624134782 Test: 1.0773472675014202\n",
      "Epoch: 886\n",
      "Loss: \n",
      "Training: 1.849148478976481 Test: 1.0736705978822174\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.836426996066199 Test: 1.0688306210258376\n",
      "Epoch: 887\n",
      "Loss: \n",
      "Training: 1.8517716609641666 Test: 1.0864008712426347\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8309546088008122 Test: 1.0663956375429364\n",
      "Epoch: 888\n",
      "Loss: \n",
      "Training: 1.6763073344985864 Test: 1.071254214717647\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.856097530753352 Test: 1.072278599781469\n",
      "Epoch: 889\n",
      "Loss: \n",
      "Training: 1.9517293184548907 Test: 1.1842238169234098\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8404264552952736 Test: 1.0739960092216747\n",
      "Epoch: 890\n",
      "Loss: \n",
      "Training: 1.9318615740095821 Test: 1.0309369634342906\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8479337932282363 Test: 1.0918556963173125\n",
      "Epoch: 891\n",
      "Loss: \n",
      "Training: 1.5630147742982676 Test: 1.121341239312862\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8646885846230372 Test: 1.092388944327513\n",
      "Epoch: 892\n",
      "Loss: \n",
      "Training: 1.6640692755558133 Test: 1.0798864767197525\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8319922844052905 Test: 1.0955400897672825\n",
      "Epoch: 893\n",
      "Loss: \n",
      "Training: 2.017533304192042 Test: 1.0714337454776355\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.798068174483533 Test: 1.0977838368269566\n",
      "Epoch: 894\n",
      "Loss: \n",
      "Training: 1.8347792284689413 Test: 1.1138074557878277\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7964561318750392 Test: 1.0905054332232649\n",
      "Epoch: 895\n",
      "Loss: \n",
      "Training: 1.6915876600616904 Test: 1.098795039277623\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8076006688314734 Test: 1.0901377177275386\n",
      "Epoch: 896\n",
      "Loss: \n",
      "Training: 1.9052961221526785 Test: 1.1282234824434418\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.803180260948046 Test: 1.0931750420775903\n",
      "Epoch: 897\n",
      "Loss: \n",
      "Training: 1.9130286910567624 Test: 1.071848090808593\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8087950252656657 Test: 1.0986303305337124\n",
      "Epoch: 898\n",
      "Loss: \n",
      "Training: 1.7203556983754416 Test: 1.092520531344607\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8149207282749251 Test: 1.0971750524903083\n",
      "Epoch: 899\n",
      "Loss: \n",
      "Training: 1.5936804719719369 Test: 1.1765203460306812\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.819325564662611 Test: 1.0993016841530043\n",
      "Epoch: 900\n",
      "Loss: \n",
      "Training: 1.9540513367144896 Test: 1.132942713736113\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7835206800143155 Test: 1.0985313370637315\n",
      "Epoch: 901\n",
      "Loss: \n",
      "Training: 1.7940186639739073 Test: 1.1303800447174663\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7857396562848062 Test: 1.1087319120939136\n",
      "Epoch: 902\n",
      "Loss: \n",
      "Training: 1.8249388595880902 Test: 1.1447352303006413\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8088400452523703 Test: 1.109635792634374\n",
      "Epoch: 903\n",
      "Loss: \n",
      "Training: 1.7818477354597282 Test: 1.0278735794533995\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.824927003655598 Test: 1.1161206679924631\n",
      "Epoch: 904\n",
      "Loss: \n",
      "Training: 1.647428318068815 Test: 1.0501713242222568\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8013584467823667 Test: 1.1117646513900392\n",
      "Epoch: 905\n",
      "Loss: \n",
      "Training: 1.7381854659392928 Test: 1.0971057493322336\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7826233557423539 Test: 1.1054010382334822\n",
      "Epoch: 906\n",
      "Loss: \n",
      "Training: 1.6716695409465003 Test: 1.1013875766491759\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7872831363301143 Test: 1.1052321092389434\n",
      "Epoch: 907\n",
      "Loss: \n",
      "Training: 1.9676168009145285 Test: 1.1036402017984048\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7639204782094964 Test: 1.1025485186595168\n",
      "Epoch: 908\n",
      "Loss: \n",
      "Training: 1.747776637527998 Test: 1.119044297924997\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7693792891952729 Test: 1.1057277297584978\n",
      "Epoch: 909\n",
      "Loss: \n",
      "Training: 1.8005051312336144 Test: 1.0491944122230266\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7721213831105285 Test: 1.1083801064165368\n",
      "Epoch: 910\n",
      "Loss: \n",
      "Training: 1.876670737042823 Test: 1.1387027616075507\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7928038490366962 Test: 1.0956475130357715\n",
      "Epoch: 911\n",
      "Loss: \n",
      "Training: 1.8231731654680712 Test: 1.1141847678673467\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7850657890695296 Test: 1.0962235178229152\n",
      "Epoch: 912\n",
      "Loss: \n",
      "Training: 1.9714282342146014 Test: 1.0423739650235537\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.787981239218946 Test: 1.0946039901379032\n",
      "Epoch: 913\n",
      "Loss: \n",
      "Training: 1.8178538892247138 Test: 1.0288717107704224\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8026301766815973 Test: 1.0843678636101945\n",
      "Epoch: 914\n",
      "Loss: \n",
      "Training: 1.7382656106055827 Test: 1.0003201191411297\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.806230792058096 Test: 1.0844676767418968\n",
      "Epoch: 915\n",
      "Loss: \n",
      "Training: 1.7044560482786741 Test: 1.1675548494151167\n",
      "Rolling mean of Loss (Window is 10): \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 1.8153145213117727 Test: 1.079482556233784\n",
      "Epoch: 916\n",
      "Loss: \n",
      "Training: 1.5489484802901257 Test: 1.0460316289588514\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8119415795457112 Test: 1.0865274662420723\n",
      "Epoch: 917\n",
      "Loss: \n",
      "Training: 1.8105741851016974 Test: 1.0429456039133742\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7996694734800731 Test: 1.08099187147304\n",
      "Epoch: 918\n",
      "Loss: \n",
      "Training: 1.919502550511254 Test: 1.1024770094851355\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7839652118987899 Test: 1.0749224116845368\n",
      "Epoch: 919\n",
      "Loss: \n",
      "Training: 1.8846674254590183 Test: 1.1354743677878696\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.8011378031971155 Test: 1.0732656828405507\n",
      "Epoch: 920\n",
      "Loss: \n",
      "Training: 1.7869291329187318 Test: 1.1003842235268346\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.809554032619656 Test: 1.081893678397035\n",
      "Epoch: 921\n",
      "Loss: \n",
      "Training: 1.5883653098653643 Test: 1.1089191055429373\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.800579872207247 Test: 1.0780618245889635\n",
      "Epoch: 922\n",
      "Loss: \n",
      "Training: 1.881734226703181 Test: 1.0609853885371392\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7770990866469762 Test: 1.0775352583565225\n",
      "Epoch: 923\n",
      "Loss: \n",
      "Training: 1.7383743987478306 Test: 1.013890061777259\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7681296858958344 Test: 1.0793964007078811\n",
      "Epoch: 924\n",
      "Loss: \n",
      "Training: 1.6170679206317513 Test: 1.0568743145367672\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7601817368481463 Test: 1.0778982358085645\n",
      "Epoch: 925\n",
      "Loss: \n",
      "Training: 2.033502728774131 Test: 1.046295677256298\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.748061967850763 Test: 1.0835536553481284\n",
      "Epoch: 926\n",
      "Loss: \n",
      "Training: 1.875197035768856 Test: 1.1020834250921803\n",
      "Rolling mean of Loss (Window is 10): \n",
      "Training: 1.7809666359003085 Test: 1.0714277381322466\n",
      "Interrupt.\n",
      "Encoder's best params are saved.\n",
      "Decoder's best params are saved.\n",
      "end. \n"
     ]
    }
   ],
   "source": [
    "auto_encoder.learn(observed_arr=observed_arr, target_arr=observed_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "_ = plt.figure(figsize=(20, 10))\n",
    "plt.plot(auto_encoder.verificatable_result.logs_df.train_loss.values, label=\"Train errors.\")\n",
    "plt.plot(auto_encoder.verificatable_result.logs_df.test_loss.values, label=\"Test errors.\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"MSE\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
